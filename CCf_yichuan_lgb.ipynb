{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from random import randint\n",
    "# from xgboost.sklearn import XGBClassifiers\n",
    " \n",
    " #%%\n",
    "'''\n",
    "群体大小，一般取20~100；终止进化代数，一般取100~500；交叉概率，一般取0.4~0.99；变异概率，一般取0.0001~0.1。\n",
    "'''\n",
    "# generations = 400   # 繁殖代数 100\n",
    "pop_size = 500      # 种群数量  500\n",
    "# max_value = 10      # 基因中允许出现的最大值 （可防止离散变量数目达不到2的幂的情况出现，限制最大值，此处不用） \n",
    "chrom_length = 16    # 染色体长度  \n",
    "pc = 0.6            # 交配概率  \n",
    "pm = 0.01           # 变异概率  \n",
    "results = []      # 存储每一代的最优解，N个三元组（auc最高值, n_estimators, max_depth）  \n",
    "fit_value = []      # 个体适应度  \n",
    "fit_mean = []       # 平均适应度 \n",
    "# pop = [[0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0] for i in range(pop_size)] # 初始化种群中所有个体的基因初始序列\n",
    " \n",
    "random_seed = 20\n",
    "cons_value = 0.19 / 31 # (0.20-0.01）/ (32 - 1)\n",
    " \n",
    " #%%\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "'''要调试的参数有：（参考：http://xgboost.readthedocs.io/en/latest/parameter.html）\n",
    "   tree_num：基树的棵数   ----------------（要调的参数）\n",
    "   eta: 学习率（learning_rate），默认值为0.3，范围[0,1]  ----------------（要调的参数）\n",
    "   max_depth: 最大树深，默认值为6   ----------------（要调的参数）\n",
    "   min_child_weight：默认值为1，范围[0, 正无穷]，该参数值越小，越容易 overfitting，当它的值较大时，可以避免模型学习到局部的特殊样本。 ----------（要调的参数）\n",
    "   gamma：默认值为0，min_split_loss，范围[0, 正无穷]\n",
    "   subsample：选择数据集百分之多少来训练，可以防止过拟合。默认值1，范围(0, 1]，理想值0.8\n",
    "   colsample_bytree：subsample ratio of columns when constructing each tree，默认值1，范围(0, 1]，理想值0.8，太小的值会造成欠拟合\n",
    "   lambda：L2 regularization term on weights, increase this value will make model more conservative.参数值越大，模型越不容易过拟合\n",
    "   alpha：L1 regularization term on weights, increase this value will make model more conservative.参数值越大，模型越不容易过拟合\n",
    "   上述参数，要调的有4个，其他的采用理想值就可以\n",
    "   tree_num: [10、 20、 30、......150、160] 用4位二进制, 0000代表10\n",
    "   eta: [0.01, 0.02, 0.03, 0.04, 0.05, ...... 0.19, 0.20]   0.2/0.01=20份，用5位二进制表示足够（2的4次方<20<2的5次方）\n",
    "       00000 -----> 0.01\n",
    "       11111 -----> 0.20\n",
    "       0.01 + 对应十进制*（0.20-0.01）/ (2的5次方-1)\n",
    "   max_depth:[3、4、5、6、7、8、9、10]   用4位二进制   lgb num_leave [1  16] 20+[4 64] [5,80]\n",
    "   min_child_weight: [1, 2, 3, 4, 5, 6, 7, 8]  用3位二进制\n",
    "   示例：   0010,         01001,               010,      110  （共15位）\n",
    "         tree_num         eta               max_depth  min_child_weight\n",
    "        (1+2)*10=30  0.01+9*0.005939=0.06       3+2=5      1+6=7\n",
    "'''\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def xgboostModel(tree_num, eta, max_depth, min_child_weight):\n",
    "    train_xy = loadFile(\"../../Data/train-gao.csv\")\n",
    "    train_xy = train_xy.drop('ID', axis=1)  # 删除训练集的ID\n",
    "    # 将训练集划分成8:2（训练集与验证集比例）的比例\n",
    "    train, val = train_test_split(\n",
    "        train_xy, test_size=0.2, random_state=80)\n",
    " \n",
    "    train_y = train.Kind\n",
    "    train_x = train.drop('Kind', axis=1)\n",
    "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    " \n",
    "    val_y = val.Kind\n",
    "    val_x = val.drop('Kind', axis=1)\n",
    "    dval = xgb.DMatrix(val_x)\n",
    " \n",
    "    params = {\n",
    "        'booster': 'gbtree',  # gbtree used\n",
    "        'objective': 'binary:logistic',\n",
    "        'early_stopping_rounds': 100,\n",
    "        # 'scale_pos_weight': 0.13,  # 正样本权重\n",
    "        'eval_metric': 'auc',\n",
    "        'eta': eta,  # 0.02\n",
    "        \n",
    "        'max_depth': max_depth, # 8\n",
    "        'min_child_weight': min_child_weight, # 3\n",
    "        'gamma': 0.1,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'lambda': 550,\n",
    "        'alpha': 19,\n",
    "        'seed': randint(1,10000),\n",
    "        'nthread': 3,\n",
    "        'silent': 1\n",
    "    }\n",
    "    model = xgb.train(params, dtrain, num_boost_round=tree_num)\n",
    "    predict_y = model.predict(dval, ntree_limit=model.best_ntree_limit)\n",
    "    roc_auc = metrics.roc_auc_score(val_y, predict_y)\n",
    "    return roc_auc\n",
    " \n",
    " \n",
    " \n",
    "def loadFile(filePath):\n",
    "    fileData = pd.read_csv(filePath)\n",
    "    return fileData\n",
    " \n",
    " \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def lgbModel(tree_num, eta=0.02, num_leave=31, min_child_weight=3):    \n",
    "    params = {\n",
    "        'booster': 'gbdt',  # gbtree used\n",
    "        # 'objective': \"regression\",\n",
    "        'early_stopping_rounds': 10, #0\n",
    "        # 'scale_pos_weight': 0.13,  # 正样本权重\n",
    "        # 'metric': 'auc',\n",
    "        \"num_iterations\":1000,\n",
    "        'learning_rate': eta,  # 0.02\n",
    "        'num_leaves': num_leave, # 31\n",
    "        'min_child_weight': min_child_weight, # 3\n",
    "        'num_boost_round':tree_num,\n",
    "        # 'min_split_gain': 0.1,\n",
    "        # 'subsample': 0.8,\n",
    "        # 'feature_fraction': 0.8,\n",
    "        # # 'lambda': 550,\n",
    "        # 'lambda_l2':550,\n",
    "        # # 'alpha': 19,\n",
    "        #  'lambda_l1':19,        \n",
    "        # 'bagging_seed':randint(1,10000),\n",
    "        # 'num_threads': 3,\n",
    "        'reg_lambda':0.01,\n",
    "        \"subsample_freq\":1,\n",
    "        'colsample_bytree':0.7,\n",
    "        'subsample':0.7,\n",
    "        'n_estimators':1000,\n",
    "        'objective':'mse',\n",
    "        'metric':'mae'\n",
    "        #'silent': 1\n",
    "    }\n",
    "\n",
    "    dtrain = lgb.DMatrix(train_x, label=train_y)\n",
    "    dval = lgb.DMatrix(test_x)\n",
    "    \n",
    "    model = lgb.train(params, dtrain, num_boost_round=tree_num)\n",
    "    predict_y = model.predict(dval, ntree_limit=model.best_ntree_limit)\n",
    "    roc_auc = metrics.roc_auc_score(test_y, predict_y)\n",
    "    return roc_auc\n",
    " \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 1 : 对参数进行编码（用于初始化基因序列，可以选择初始化基因序列，本函数省略）\n",
    "def geneEncoding(pop_size, chrom_length):  \n",
    "    pop = [[]]\n",
    "    for i in range(pop_size):\n",
    "        temp = []\n",
    "        for j in range(chrom_length):\n",
    "            temp.append(random.randint(0, 1))\n",
    "        pop.append(temp)\n",
    "    return pop[1:]\n",
    " \n",
    "# Step 2 : 计算个体的目标函数值\n",
    "def cal_obj_value(pop):\n",
    "    objvalue = []\n",
    "    variable = decodechrom(pop)\n",
    "    for i in range(len(variable)):\n",
    "        tempVar = variable[i]\n",
    " \n",
    "        tree_num_value = (tempVar[0] + 1)* 10\n",
    "        eta_value = 0.01 + tempVar[1] * cons_value\n",
    "      #xgb:  max_depth_value = 3 + tempVar[2]\n",
    "        num_leave_value = 20+5*tempVar[2]\n",
    "        min_child_weight_value = 1 + tempVar[3]\n",
    " \n",
    "        aucValue = xgboostModel(tree_num_value, eta_value, num_leave_value, min_child_weight_value, random_seed)\n",
    "        objvalue.append(aucValue)\n",
    "    return objvalue #目标函数值objvalue[m] 与个体基因 pop[m] 对应 \n",
    " \n",
    " \n",
    "# 对每个个体进行解码，并拆分成单个变量，返回 tree_num（4）、eta（5）、num_leave（3）、min_child_weight（3）\n",
    "def decodechrom(pop):\n",
    "    variable = []\n",
    "    for i in range(len(pop)):\n",
    "        res = []\n",
    "        \n",
    "        # 计算第一个变量值，即 0101->10(逆转)\n",
    "        temp1 = pop[i][0:4]\n",
    "        v1 = 0\n",
    "        for i1 in range(4):\n",
    "            v1 += temp1[i1] * (math.pow(2, i1))\n",
    "        res.append(int(v1))\n",
    "        \n",
    "        # 计算第二个变量值\n",
    "        temp2 = pop[i][4:9]\n",
    "        v2 = 0\n",
    "        for i2 in range(5):\n",
    "            v2 += temp2[i2] * (math.pow(2, i2))\n",
    "        res.append(int(v2))\n",
    " \n",
    "        # 计算第三个变量值\n",
    "        temp3 = pop[i][9:13]\n",
    "        v3 = 0\n",
    "        for i3 in range(3):\n",
    "            v3 += temp3[i3] * (math.pow(2, i3))\n",
    "        res.append(int(v3))\n",
    " \n",
    "        # 计算第四个变量值\n",
    "        temp4 = pop[i][13:16]\n",
    "        v4 = 0\n",
    "        for i4 in range(3):\n",
    "            v4 += temp4[i4] * (math.pow(2, i4))\n",
    "        res.append(int(v4))\n",
    " \n",
    "        variable.append(res)\n",
    "    return variable\n",
    " \n",
    " \n",
    "# Step 3: 计算个体的适应值（计算最大值，于是就淘汰负值就好了）\n",
    "def calfitvalue(obj_value):\n",
    "    fit_value = []\n",
    "    temp = 0.0\n",
    "    Cmin = 0\n",
    "    for i in range(len(obj_value)):\n",
    "        if(obj_value[i] + Cmin > 0):\n",
    "            temp = Cmin + obj_value[i]\n",
    "        else:\n",
    "            temp = 0.0\n",
    "        fit_value.append(temp)\n",
    "    return fit_value\n",
    " \n",
    " \n",
    "# Step 4: 找出适应函数值中最大值，和对应的个体\n",
    "def best(pop, fit_value):\n",
    "    best_individual = pop[0]\n",
    "    best_fit = fit_value[0]\n",
    "    for i in range(1, len(pop)):\n",
    "        if(fit_value[i] > best_fit):\n",
    "            best_fit = fit_value[i]\n",
    "            best_individual = pop[i]\n",
    "    return [best_individual, best_fit]\n",
    " \n",
    " \n",
    "# Step 5: 每次繁殖，将最好的结果记录下来(将二进制转化为十进制)\n",
    "def b2d(best_individual):\n",
    "    # 计算第一个变量值\n",
    "    temp1 = best_individual[0:4]\n",
    "    v1 = 0\n",
    "    for i1 in range(4):\n",
    "        v1 += temp1[i1] * (math.pow(2, i1))\n",
    "    v1 = (v1 + 1) * 10\n",
    "    \n",
    "    # 计算第二个变量值\n",
    "    temp2 = best_individual[4:9]\n",
    "    v2 = 0\n",
    "    for i2 in range(5):\n",
    "        v2 += temp2[i2] * (math.pow(2, i2))\n",
    "    v2 = 0.01 + v2 * cons_value\n",
    " \n",
    "    # 计算第三个变量值\n",
    "    temp3 = best_individual[9:12]\n",
    "    v3 = 0\n",
    "    for i3 in range(3):\n",
    "        v3 += temp3[i3] * (math.pow(2, i3))\n",
    "    v3 = 3 + v3\n",
    " \n",
    "    # 计算第四个变量值\n",
    "    temp4 = best_individual[12:15]\n",
    "    v4 = 0\n",
    "    for i4 in range(3):\n",
    "        v4 += temp4[i4] * (math.pow(2, i4))\n",
    "    v4 = 1 + v4\n",
    " \n",
    "    return int(v1), float(v2), int(v3), int(v4)\n",
    " \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " \n",
    "# Step 6: 自然选择（轮盘赌算法）\n",
    "def selection(pop, fit_value):\n",
    "    # 计算每个适应值的概率\n",
    "    new_fit_value = []\n",
    "    total_fit = sum(fit_value)\n",
    "    for i in range(len(fit_value)):\n",
    "        new_fit_value.append(fit_value[i] / total_fit)\n",
    "    # 计算每个适应值的累积概率\n",
    "    cumsum(new_fit_value)\n",
    "    # 生成随机浮点数序列\n",
    "    ms = []\n",
    "    pop_len = len(pop)\n",
    "    for i in range(pop_len):\n",
    "        ms.append(random.random())\n",
    "    # 对生成的随机浮点数序列进行排序\n",
    "    ms.sort()\n",
    "    # 轮盘赌算法（选中的个体成为下一轮，没有被选中的直接淘汰，被选中的个体代替）\n",
    "    fitin = 0\n",
    "    newin = 0\n",
    "    newpop = pop\n",
    "    while newin < pop_len:\n",
    "        if(ms[newin] < new_fit_value[fitin]):\n",
    "            newpop[newin] = pop[fitin]\n",
    "            newin = newin + 1\n",
    "        else:\n",
    "            fitin = fitin + 1\n",
    "    pop = newpop\n",
    " \n",
    "# 求适应值的总和\n",
    "def sum(fit_value):\n",
    "    total = 0\n",
    "    for i in range(len(fit_value)):\n",
    "        total += fit_value[i]\n",
    "    return total\n",
    " \n",
    "# 计算累积概率\n",
    "def cumsum(fit_value):\n",
    "    temp=[]\n",
    "    for i in range(len(fit_value)):\n",
    "        t = 0\n",
    "        j = 0\n",
    "        while(j <= i):\n",
    "            t += fit_value[j]\n",
    "            j = j + 1\n",
    "        temp.append(t)\n",
    "    for i in range(len(fit_value)):\n",
    "        fit_value[i]=temp[i]\n",
    " \n",
    "# Step 7: 交叉繁殖\n",
    "def crossover(pop, pc): #个体间交叉，实现基因交换\n",
    "    poplen = len(pop)\n",
    "    for i in range(poplen - 1):\n",
    "        if(random.random() < pc):\n",
    "            cpoint = random.randint(0,len(pop[0]))\n",
    "            temp1 = []\n",
    "            temp2 = []\n",
    "            temp1.extend(pop[i][0 : cpoint])\n",
    "            temp1.extend(pop[i+1][cpoint : len(pop[i])])\n",
    "            temp2.extend(pop[i+1][0 : cpoint])\n",
    "            temp2.extend(pop[i][cpoint : len(pop[i])])\n",
    "            pop[i] = temp1\n",
    "            pop[i+1] = temp2\n",
    " \n",
    " \n",
    "# Step 8: 基因突变\n",
    "def mutation(pop, pm):\n",
    "    px = len(pop)\n",
    "    py = len(pop[0])\n",
    "    for i in range(px):\n",
    "        if(random.random() < pm):\n",
    "            mpoint = random.randint(0, py-1)\n",
    "            if(pop[i][mpoint] == 1):\n",
    "                pop[i][mpoint] = 0\n",
    "            else:\n",
    "                pop[i][mpoint] = 1\n",
    " \n",
    " \n",
    "def writeToFile(var, w_path):\n",
    "    f=file(w_path,\"a+\")\n",
    "    for item in var:\n",
    "        f.write(str(item) + \"\\r\\n\")\n",
    "    f.close()\n",
    " \n",
    " \n",
    "def generAlgo(generations):\n",
    "    pop = geneEncoding(pop_size, chrom_length)\n",
    "    print(str(generations)+\" start...\")\n",
    "    for i in range(generations):\n",
    "        # print(\"第 \" + str(i) + \" 代开始繁殖......\")\n",
    "        obj_value = cal_obj_value(pop) # 计算目标函数值\n",
    "        # print(obj_value)\n",
    "        fit_value = calfitvalue(obj_value) #计算个体的适应值\n",
    "        # print(fit_value)\n",
    "        [best_individual, best_fit] = best(pop, fit_value) #选出最好的个体和最好的函数值\n",
    "        # print(\"best_individual: \"+ str(best_individual))\n",
    "        v1, v2, v3, v4 = b2d(best_individual)\n",
    "        results.append([best_fit, v1, v2, v3, v4]) #每次繁殖，将最好的结果记录下来\n",
    "        # print(str(best_individual) + \" \" + str(best_fit))\n",
    "        selection(pop, fit_value) #自然选择，淘汰掉一部分适应性低的个体\n",
    "        crossover(pop, pc) #交叉繁殖\n",
    "        mutation(pop, pc) #基因突变\n",
    "    # print(results)\n",
    "    results.sort()\n",
    "    # wirte results to file\n",
    "    writeToFile(results, \"generation_\" + str(generations) + \".txt\")\n",
    "    print(results[-1])\n",
    "    # print(xgboostModel(100, 12))\n",
    " \n",
    " \n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_cgb=pd.read_csv('H:/pythonchengx_u/CCFchengche/Date/train_test_o.csv')\n",
    "data=data_cgb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data=data_cgb\n",
    "num_feat = ['regMonth', 'regYear', 'popularity', 'carCommentVolum', 'newsReplyVolum']\n",
    "# cate_feat = ['bodyType', 'model', 'province']\n",
    "cate_feat = ['adcode', 'model']\n",
    "# for i in have_null:\n",
    "#     data[i] = data[i].astype('str')\n",
    "\n",
    "for i in cate_feat:\n",
    "    data[i] = data[i].astype('category')\n",
    "features = num_feat + cate_feat\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "n_splits=5\n",
    "random_state=2018\n",
    "label='label'\n",
    "if 'sample_weight' not in data.keys():\n",
    "    data['sample_weight'] = 1\n",
    "# model.random_state = random_state\n",
    "predict_label = 'predict_' + label\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "data[predict_label] = 0\n",
    "test_index = (data[label].isnull()) | (data[label] == -1)\n",
    "#~：逐位取反\n",
    "train_data = data[~test_index].reset_index(drop=True)\n",
    "test_data = data[test_index]\n",
    "for train_idx, val_idx in kfold.split(train_data):\n",
    "    random_state = random_state + 1\n",
    "\n",
    "    train_x = train_data.loc[train_idx][features]\n",
    "    train_y = train_data.loc[train_idx][label]\n",
    "\n",
    "    test_x = train_data.loc[val_idx][features]\n",
    "    test_y = train_data.loc[val_idx][label]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    gen = [100, 200, 300, 400, 500]\n",
    "    for g in gen:\n",
    "        generAlgo(int(g))\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}