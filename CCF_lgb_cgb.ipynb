{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_predict_w(model, data, label='label', feature=[], cate_feature=[], random_state=2018, n_splits=5,\n",
    "                  model_type='lgb'):\n",
    "    if 'sample_weight' not in data.keys():\n",
    "        data['sample_weight'] = 1\n",
    "    model.random_state = random_state\n",
    "    predict_label = 'predict_' + label\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    data[predict_label] = 0\n",
    "    test_index = (data[label].isnull()) | (data[label] == -1)\n",
    "    #~：逐位取反\n",
    "    train_data = data[~test_index].reset_index(drop=True)\n",
    "    test_data = data[test_index]\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(train_data):\n",
    "        model.random_state = model.random_state + 1\n",
    "\n",
    "        train_x = train_data.loc[train_idx][feature]\n",
    "        train_y = train_data.loc[train_idx][label]\n",
    "\n",
    "        test_x = train_data.loc[val_idx][feature]\n",
    "        test_y = train_data.loc[val_idx][label]\n",
    "        if model_type == 'lgb':\n",
    "            try:\n",
    "                model.fit(train_x, train_y, eval_set=[(test_x, test_y)], early_stopping_rounds=100,\n",
    "                          eval_metric='mae',\n",
    "                          # callbacks=[lgb.reset_parameter(learning_rate=lambda iter: max(0.005, 0.5 * (0.99 ** iter)))],\n",
    "                          categorical_feature=cate_feature,\n",
    "                          sample_weight=train_data.loc[train_idx]['sample_weight'],\n",
    "                          verbose=100)\n",
    "            except:\n",
    "                model.fit(train_x, train_y, eval_set=[(test_x, test_y)], early_stopping_rounds=100,\n",
    "                          eval_metric='mae',\n",
    "                          # callbacks=[lgb.reset_parameter(learning_rate=lambda iter: max(0.005, 0.5 * (0.99 ** iter)))],\n",
    "                          # categorical_feature=cate_feature,\n",
    "                          sample_weight=train_data.loc[train_idx]['sample_weight'],\n",
    "                          verbose=100)\n",
    "        elif model_type == 'ctb':\n",
    "            model.fit(train_x, train_y, eval_set=[(test_x, test_y)], early_stopping_rounds=100,\n",
    "                      # eval_metric='mae',\n",
    "                      # callbacks=[lgb.reset_parameter(learning_rate=lambda iter: max(0.005, 0.5 * (0.99 ** iter)))],\n",
    "                      cat_features=cate_feature,\n",
    "                      sample_weight=train_data.loc[train_idx]['sample_weight'],\n",
    "                      verbose=100)\n",
    "            \n",
    "            \n",
    "        train_data.loc[val_idx, predict_label] = model.predict(test_x)\n",
    "        if len(test_data) != 0:\n",
    "            test_data[predict_label] = test_data[predict_label] + model.predict(test_data[feature])\n",
    "    test_data[predict_label] = test_data[predict_label] / n_splits\n",
    "    # print(mse(train_data[label], train_data[predict_label]) * 5, train_data[predict_label].mean(),\n",
    "    #       test_data[predict_label].mean())\n",
    "\n",
    "    return pd.concat([train_data, test_data], sort=True, ignore_index=True), test_data\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_cgb=pd.read_csv('H:/pythonchengx_u/CCFchengche/Date/train_test_o.csv')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 36960 entries, 0 to 36959\nData columns (total 8 columns):\nadcode             36960 non-null int64\ncarCommentVolum    36960 non-null float64\nmodel              36960 non-null object\nnewsReplyVolum     36960 non-null float64\npopularity         36960 non-null float64\nregMonth           36960 non-null int64\nregYear            36960 non-null int64\nlabel              31680 non-null float64\ndtypes: float64(4), int64(3), object(1)\nmemory usage: 2.3+ MB\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "data_cgb.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   adcode  carCommentVolum             model  newsReplyVolum  popularity  \\\n0  310000             11.0  3c974920a76ac9c1           106.0      1479.0   \n1  530000             11.0  3c974920a76ac9c1           106.0      1594.0   \n2  150000             11.0  3c974920a76ac9c1           106.0      1479.0   \n3  110000             11.0  3c974920a76ac9c1           106.0      2370.0   \n4  510000             11.0  3c974920a76ac9c1           106.0      3562.0   \n\n   regMonth  regYear  label  \n0         1     2016  292.0  \n1         1     2016  466.0  \n2         1     2016  257.0  \n3         1     2016  408.0  \n4         1     2016  610.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>adcode</th>\n      <th>carCommentVolum</th>\n      <th>model</th>\n      <th>newsReplyVolum</th>\n      <th>popularity</th>\n      <th>regMonth</th>\n      <th>regYear</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310000</td>\n      <td>11.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1479.0</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>292.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>530000</td>\n      <td>11.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1594.0</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>466.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150000</td>\n      <td>11.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1479.0</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>257.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>110000</td>\n      <td>11.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2370.0</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>408.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>510000</td>\n      <td>11.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3562.0</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>610.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "data_cgb.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['adcode', 'carCommentVolum', 'model', 'newsReplyVolum', 'popularity',\n       'regMonth', 'regYear', 'label'],\n      dtype='object')"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "data_cgb.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "adcode                0\ncarCommentVolum       0\nmodel                 0\nnewsReplyVolum        0\npopularity            0\nregMonth              0\nregYear               0\nlabel              5280\ndtype: int64"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "data_cgb.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "features=list(data_cgb.columns)[:-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "['adcode',\n 'carCommentVolum',\n 'model',\n 'newsReplyVolum',\n 'popularity',\n 'regMonth',\n 'regYear']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "features\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data=data_cgb\n",
    "num_feat = ['regMonth', 'regYear', 'popularity', 'carCommentVolum', 'newsReplyVolum']\n",
    "# cate_feat = ['bodyType', 'model', 'province']\n",
    "cate_feat = ['adcode', 'model']\n",
    "# for i in have_null:\n",
    "#     data[i] = data[i].astype('str')\n",
    "\n",
    "for i in cate_feat:\n",
    "    data[i] = data[i].astype('category')\n",
    "features = num_feat + cate_feat\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "random_state=2018\n",
    "if 'sample_weight' not in data.keys():\n",
    "    data['sample_weight'] = 1\n",
    "label='label'\n",
    "predict_label = 'predict_' + label\n",
    "data[predict_label] = 0\n",
    "test_index = (data[label].isnull()) | (data[label] == -1)\n",
    "#~：逐位取反\n",
    "train_data = data[~test_index].reset_index(drop=True)\n",
    "test_data = data[test_index]\n",
    "train_y = train_data.label\n",
    "train_x = train_data.drop('label', axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 3780 candidates, totalling 18900 fits",
      "\n",
      "{'learning_rate ': 0.03, 'max_depth': 8, 'min_data_in_leaf': 30, 'num_leaves': 230}",
      "\n",
      "-108571.08001906337",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 376 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=4)]: Done 876 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=4)]: Done 1576 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=4)]: Done 2476 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 3576 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 4876 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 6376 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done 8076 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=4)]: Done 9976 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=4)]: Done 12076 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=4)]: Done 14376 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=4)]: Done 16876 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=4)]: Done 18900 out of 18900 | elapsed: 10.8min finished\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=50,\n",
    "                              learning_rate=0.1, n_estimators=43, max_depth=6,\n",
    "                              metric='mse', bagging_fraction = 0.8,feature_fraction = 0.8)\n",
    "\n",
    "params_test1={ 'max_depth': range(3,9,1),  'num_leaves':range(50, 300, 30),'learning_rate ':np.linspace(0.03, 0.3, 10),'min_data_in_leaf':range(10, 150, 20)}\n",
    "gsearch1 = GridSearchCV(estimator=model_lgb, param_grid=params_test1, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=4)\n",
    "gsearch1.fit(train_x, train_y)\n",
    "print(gsearch1.best_params_)\n",
    "print(gsearch1.best_score_)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 3120 candidates, totalling 15600 fits",
      "\n",
      "{'learning_rate ': 0.01, 'max_depth': 8, 'min_data_in_leaf': 20, 'num_leaves': 170}",
      "\n",
      "-107687.08374737418",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:   56.9s\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=4)]: Done 8442 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=4)]: Done 9792 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=4)]: Done 11242 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=4)]: Done 12792 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=4)]: Done 14442 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=4)]: Done 15600 out of 15600 | elapsed: 11.8min finished\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=50,\n",
    "                              learning_rate=0.1, n_estimators=43, max_depth=6,\n",
    "                              metric='mse', bagging_fraction = 0.8,feature_fraction = 0.8)\n",
    "\n",
    "params_test1={ 'max_depth': range(6,9,1),  'num_leaves':range(50, 300, 20),'learning_rate ':np.linspace(0.01, 0.5, 10),'min_data_in_leaf':range(10, 90, 10)}\n",
    "gsearch2 = GridSearchCV(estimator=model_lgb, param_grid=params_test1, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=4)\n",
    "gsearch2.fit(train_x, train_y)\n",
    "print(gsearch2.best_params_)\n",
    "print(gsearch2.best_score_)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 192.508",
      "\n",
      "[200]\tvalid_0's l1: 148.641",
      "\n",
      "[300]\tvalid_0's l1: 129.325",
      "\n",
      "[400]\tvalid_0's l1: 116.826",
      "\n",
      "[500]\tvalid_0's l1: 110.223",
      "\n",
      "[600]\tvalid_0's l1: 105.455",
      "\n",
      "[700]\tvalid_0's l1: 101.987",
      "\n",
      "[800]\tvalid_0's l1: 99.3554",
      "\n",
      "[900]\tvalid_0's l1: 97.001",
      "\n",
      "[1000]\tvalid_0's l1: 95.469",
      "\n",
      "[1100]\tvalid_0's l1: 94.2452",
      "\n",
      "[1200]\tvalid_0's l1: 92.9931",
      "\n",
      "[1300]\tvalid_0's l1: 91.9281",
      "\n",
      "[1400]\tvalid_0's l1: 91.3764",
      "\n",
      "[1500]\tvalid_0's l1: 90.5247",
      "\n",
      "[1600]\tvalid_0's l1: 89.9381",
      "\n",
      "[1700]\tvalid_0's l1: 89.4372",
      "\n",
      "[1800]\tvalid_0's l1: 88.8513",
      "\n",
      "[1900]\tvalid_0's l1: 88.4013",
      "\n",
      "[2000]\tvalid_0's l1: 88.0501",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[2000]\tvalid_0's l1: 88.0501",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 200.598",
      "\n",
      "[200]\tvalid_0's l1: 155.185",
      "\n",
      "[300]\tvalid_0's l1: 131.929",
      "\n",
      "[400]\tvalid_0's l1: 120.797",
      "\n",
      "[500]\tvalid_0's l1: 115.168",
      "\n",
      "[600]\tvalid_0's l1: 109.5",
      "\n",
      "[700]\tvalid_0's l1: 105.91",
      "\n",
      "[800]\tvalid_0's l1: 103.584",
      "\n",
      "[900]\tvalid_0's l1: 101.583",
      "\n",
      "[1000]\tvalid_0's l1: 100.003",
      "\n",
      "[1100]\tvalid_0's l1: 98.632",
      "\n",
      "[1200]\tvalid_0's l1: 97.4043",
      "\n",
      "[1300]\tvalid_0's l1: 96.5225",
      "\n",
      "[1400]\tvalid_0's l1: 95.7009",
      "\n",
      "[1500]\tvalid_0's l1: 95.1735",
      "\n",
      "[1600]\tvalid_0's l1: 94.6187",
      "\n",
      "[1700]\tvalid_0's l1: 94.1719",
      "\n",
      "[1800]\tvalid_0's l1: 93.7648",
      "\n",
      "[1900]\tvalid_0's l1: 93.3409",
      "\n",
      "[2000]\tvalid_0's l1: 93.0031",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[2000]\tvalid_0's l1: 93.0031",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 207.271",
      "\n",
      "[200]\tvalid_0's l1: 157.67",
      "\n",
      "[300]\tvalid_0's l1: 137.121",
      "\n",
      "[400]\tvalid_0's l1: 124.508",
      "\n",
      "[500]\tvalid_0's l1: 116.641",
      "\n",
      "[600]\tvalid_0's l1: 110.851",
      "\n",
      "[700]\tvalid_0's l1: 107.121",
      "\n",
      "[800]\tvalid_0's l1: 104.419",
      "\n",
      "[900]\tvalid_0's l1: 102.164",
      "\n",
      "[1000]\tvalid_0's l1: 100.758",
      "\n",
      "[1100]\tvalid_0's l1: 99.2508",
      "\n",
      "[1200]\tvalid_0's l1: 97.6097",
      "\n",
      "[1300]\tvalid_0's l1: 96.76",
      "\n",
      "[1400]\tvalid_0's l1: 96.0438",
      "\n",
      "[1500]\tvalid_0's l1: 95.3006",
      "\n",
      "[1600]\tvalid_0's l1: 94.5466",
      "\n",
      "[1700]\tvalid_0's l1: 94.0505",
      "\n",
      "[1800]\tvalid_0's l1: 93.6144",
      "\n",
      "[1900]\tvalid_0's l1: 93.1843",
      "\n",
      "[2000]\tvalid_0's l1: 92.7478",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[2000]\tvalid_0's l1: 92.7478",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 186.007",
      "\n",
      "[200]\tvalid_0's l1: 150.611",
      "\n",
      "[300]\tvalid_0's l1: 130.244",
      "\n",
      "[400]\tvalid_0's l1: 118.922",
      "\n",
      "[500]\tvalid_0's l1: 111.204",
      "\n",
      "[600]\tvalid_0's l1: 106.892",
      "\n",
      "[700]\tvalid_0's l1: 103.358",
      "\n",
      "[800]\tvalid_0's l1: 100.812",
      "\n",
      "[900]\tvalid_0's l1: 99.2065",
      "\n",
      "[1000]\tvalid_0's l1: 97.8577",
      "\n",
      "[1100]\tvalid_0's l1: 96.6892",
      "\n",
      "[1200]\tvalid_0's l1: 95.8774",
      "\n",
      "[1300]\tvalid_0's l1: 95.0695",
      "\n",
      "[1400]\tvalid_0's l1: 94.322",
      "\n",
      "[1500]\tvalid_0's l1: 93.5806",
      "\n",
      "[1600]\tvalid_0's l1: 93.0702",
      "\n",
      "[1700]\tvalid_0's l1: 92.6065",
      "\n",
      "[1800]\tvalid_0's l1: 92.2007",
      "\n",
      "[1900]\tvalid_0's l1: 91.6736",
      "\n",
      "[2000]\tvalid_0's l1: 91.3442",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[2000]\tvalid_0's l1: 91.3442",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 200.235",
      "\n",
      "[200]\tvalid_0's l1: 152.55",
      "\n",
      "[300]\tvalid_0's l1: 135.254",
      "\n",
      "[400]\tvalid_0's l1: 122.491",
      "\n",
      "[500]\tvalid_0's l1: 114.664",
      "\n",
      "[600]\tvalid_0's l1: 109.595",
      "\n",
      "[700]\tvalid_0's l1: 106.687",
      "\n",
      "[800]\tvalid_0's l1: 104.276",
      "\n",
      "[900]\tvalid_0's l1: 101.733",
      "\n",
      "[1000]\tvalid_0's l1: 99.8535",
      "\n",
      "[1100]\tvalid_0's l1: 98.6749",
      "\n",
      "[1200]\tvalid_0's l1: 97.552",
      "\n",
      "[1300]\tvalid_0's l1: 96.5158",
      "\n",
      "[1400]\tvalid_0's l1: 95.9257",
      "\n",
      "[1500]\tvalid_0's l1: 95.298",
      "\n",
      "[1600]\tvalid_0's l1: 94.7047",
      "\n",
      "[1700]\tvalid_0's l1: 94.1338",
      "\n",
      "[1800]\tvalid_0's l1: 93.6883",
      "\n",
      "[1900]\tvalid_0's l1: 93.2522",
      "\n",
      "[2000]\tvalid_0's l1: 92.9489",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[1999]\tvalid_0's l1: 92.945",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "lgb_model = lgb.LGBMRegressor(min_data_in_leaf= 30,num_leaves=230,\n",
    "    reg_alpha=0., reg_lambda=0.01, objective='mse', metric='mae',\n",
    "    max_depth=8, learning_rate=0.03, min_child_samples=20,\n",
    "    n_estimators=1000, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,num_iterations=2000\n",
    ")\n",
    "data_lgb, predict_label = get_predict_w(lgb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019, n_splits=5)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 192.508",
      "\n",
      "[200]\tvalid_0's l1: 148.641",
      "\n",
      "[300]\tvalid_0's l1: 129.325",
      "\n",
      "[400]\tvalid_0's l1: 116.826",
      "\n",
      "[500]\tvalid_0's l1: 110.223",
      "\n",
      "[600]\tvalid_0's l1: 105.455",
      "\n",
      "[700]\tvalid_0's l1: 101.987",
      "\n",
      "[800]\tvalid_0's l1: 99.3554",
      "\n",
      "[900]\tvalid_0's l1: 97.001",
      "\n",
      "[1000]\tvalid_0's l1: 95.469",
      "\n",
      "[1100]\tvalid_0's l1: 94.2452",
      "\n",
      "[1200]\tvalid_0's l1: 92.9931",
      "\n",
      "[1300]\tvalid_0's l1: 91.9281",
      "\n",
      "[1400]\tvalid_0's l1: 91.3764",
      "\n",
      "[1500]\tvalid_0's l1: 90.5247",
      "\n",
      "[1600]\tvalid_0's l1: 89.9381",
      "\n",
      "[1700]\tvalid_0's l1: 89.4372",
      "\n",
      "[1800]\tvalid_0's l1: 88.8513",
      "\n",
      "[1900]\tvalid_0's l1: 88.4013",
      "\n",
      "[2000]\tvalid_0's l1: 88.0501",
      "\n",
      "[2100]\tvalid_0's l1: 87.5527",
      "\n",
      "[2200]\tvalid_0's l1: 87.1427",
      "\n",
      "[2300]\tvalid_0's l1: 86.8578",
      "\n",
      "[2400]\tvalid_0's l1: 86.5982",
      "\n",
      "[2500]\tvalid_0's l1: 86.3142",
      "\n",
      "[2600]\tvalid_0's l1: 86.0056",
      "\n",
      "[2700]\tvalid_0's l1: 85.7384",
      "\n",
      "[2800]\tvalid_0's l1: 85.5153",
      "\n",
      "[2900]\tvalid_0's l1: 85.1779",
      "\n",
      "[3000]\tvalid_0's l1: 84.9487",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[2999]\tvalid_0's l1: 84.9455",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 200.598",
      "\n",
      "[200]\tvalid_0's l1: 155.185",
      "\n",
      "[300]\tvalid_0's l1: 131.929",
      "\n",
      "[400]\tvalid_0's l1: 120.797",
      "\n",
      "[500]\tvalid_0's l1: 115.168",
      "\n",
      "[600]\tvalid_0's l1: 109.5",
      "\n",
      "[700]\tvalid_0's l1: 105.91",
      "\n",
      "[800]\tvalid_0's l1: 103.584",
      "\n",
      "[900]\tvalid_0's l1: 101.583",
      "\n",
      "[1000]\tvalid_0's l1: 100.003",
      "\n",
      "[1100]\tvalid_0's l1: 98.632",
      "\n",
      "[1200]\tvalid_0's l1: 97.4043",
      "\n",
      "[1300]\tvalid_0's l1: 96.5225",
      "\n",
      "[1400]\tvalid_0's l1: 95.7009",
      "\n",
      "[1500]\tvalid_0's l1: 95.1735",
      "\n",
      "[1600]\tvalid_0's l1: 94.6187",
      "\n",
      "[1700]\tvalid_0's l1: 94.1719",
      "\n",
      "[1800]\tvalid_0's l1: 93.7648",
      "\n",
      "[1900]\tvalid_0's l1: 93.3409",
      "\n",
      "[2000]\tvalid_0's l1: 93.0031",
      "\n",
      "[2100]\tvalid_0's l1: 92.6348",
      "\n",
      "[2200]\tvalid_0's l1: 92.2757",
      "\n",
      "[2300]\tvalid_0's l1: 92.0194",
      "\n",
      "[2400]\tvalid_0's l1: 91.7067",
      "\n",
      "[2500]\tvalid_0's l1: 91.497",
      "\n",
      "[2600]\tvalid_0's l1: 91.238",
      "\n",
      "[2700]\tvalid_0's l1: 91.0526",
      "\n",
      "[2800]\tvalid_0's l1: 90.8864",
      "\n",
      "[2900]\tvalid_0's l1: 90.7782",
      "\n",
      "[3000]\tvalid_0's l1: 90.5265",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[3000]\tvalid_0's l1: 90.5265",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 207.271",
      "\n",
      "[200]\tvalid_0's l1: 157.67",
      "\n",
      "[300]\tvalid_0's l1: 137.121",
      "\n",
      "[400]\tvalid_0's l1: 124.508",
      "\n",
      "[500]\tvalid_0's l1: 116.641",
      "\n",
      "[600]\tvalid_0's l1: 110.851",
      "\n",
      "[700]\tvalid_0's l1: 107.121",
      "\n",
      "[800]\tvalid_0's l1: 104.419",
      "\n",
      "[900]\tvalid_0's l1: 102.164",
      "\n",
      "[1000]\tvalid_0's l1: 100.758",
      "\n",
      "[1100]\tvalid_0's l1: 99.2508",
      "\n",
      "[1200]\tvalid_0's l1: 97.6097",
      "\n",
      "[1300]\tvalid_0's l1: 96.76",
      "\n",
      "[1400]\tvalid_0's l1: 96.0438",
      "\n",
      "[1500]\tvalid_0's l1: 95.3006",
      "\n",
      "[1600]\tvalid_0's l1: 94.5466",
      "\n",
      "[1700]\tvalid_0's l1: 94.0505",
      "\n",
      "[1800]\tvalid_0's l1: 93.6144",
      "\n",
      "[1900]\tvalid_0's l1: 93.1843",
      "\n",
      "[2000]\tvalid_0's l1: 92.7478",
      "\n",
      "[2100]\tvalid_0's l1: 92.4273",
      "\n",
      "[2200]\tvalid_0's l1: 92.0591",
      "\n",
      "[2300]\tvalid_0's l1: 91.8209",
      "\n",
      "[2400]\tvalid_0's l1: 91.5852",
      "\n",
      "[2500]\tvalid_0's l1: 91.3513",
      "\n",
      "[2600]\tvalid_0's l1: 91.0506",
      "\n",
      "[2700]\tvalid_0's l1: 90.9125",
      "\n",
      "[2800]\tvalid_0's l1: 90.6457",
      "\n",
      "[2900]\tvalid_0's l1: 90.5055",
      "\n",
      "[3000]\tvalid_0's l1: 90.3524",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[3000]\tvalid_0's l1: 90.3524",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 186.007",
      "\n",
      "[200]\tvalid_0's l1: 150.611",
      "\n",
      "[300]\tvalid_0's l1: 130.244",
      "\n",
      "[400]\tvalid_0's l1: 118.922",
      "\n",
      "[500]\tvalid_0's l1: 111.204",
      "\n",
      "[600]\tvalid_0's l1: 106.892",
      "\n",
      "[700]\tvalid_0's l1: 103.358",
      "\n",
      "[800]\tvalid_0's l1: 100.812",
      "\n",
      "[900]\tvalid_0's l1: 99.2065",
      "\n",
      "[1000]\tvalid_0's l1: 97.8577",
      "\n",
      "[1100]\tvalid_0's l1: 96.6892",
      "\n",
      "[1200]\tvalid_0's l1: 95.8774",
      "\n",
      "[1300]\tvalid_0's l1: 95.0695",
      "\n",
      "[1400]\tvalid_0's l1: 94.322",
      "\n",
      "[1500]\tvalid_0's l1: 93.5806",
      "\n",
      "[1600]\tvalid_0's l1: 93.0702",
      "\n",
      "[1700]\tvalid_0's l1: 92.6065",
      "\n",
      "[1800]\tvalid_0's l1: 92.2007",
      "\n",
      "[1900]\tvalid_0's l1: 91.6736",
      "\n",
      "[2000]\tvalid_0's l1: 91.3442",
      "\n",
      "[2100]\tvalid_0's l1: 91.0252",
      "\n",
      "[2200]\tvalid_0's l1: 90.6793",
      "\n",
      "[2300]\tvalid_0's l1: 90.3597",
      "\n",
      "[2400]\tvalid_0's l1: 90.1097",
      "\n",
      "[2500]\tvalid_0's l1: 89.853",
      "\n",
      "[2600]\tvalid_0's l1: 89.7201",
      "\n",
      "[2700]\tvalid_0's l1: 89.5584",
      "\n",
      "[2800]\tvalid_0's l1: 89.3057",
      "\n",
      "[2900]\tvalid_0's l1: 89.1094",
      "\n",
      "[3000]\tvalid_0's l1: 88.928",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[2999]\tvalid_0's l1: 88.9271",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 200.235",
      "\n",
      "[200]\tvalid_0's l1: 152.55",
      "\n",
      "[300]\tvalid_0's l1: 135.254",
      "\n",
      "[400]\tvalid_0's l1: 122.491",
      "\n",
      "[500]\tvalid_0's l1: 114.664",
      "\n",
      "[600]\tvalid_0's l1: 109.595",
      "\n",
      "[700]\tvalid_0's l1: 106.687",
      "\n",
      "[800]\tvalid_0's l1: 104.276",
      "\n",
      "[900]\tvalid_0's l1: 101.733",
      "\n",
      "[1000]\tvalid_0's l1: 99.8535",
      "\n",
      "[1100]\tvalid_0's l1: 98.6749",
      "\n",
      "[1200]\tvalid_0's l1: 97.552",
      "\n",
      "[1300]\tvalid_0's l1: 96.5158",
      "\n",
      "[1400]\tvalid_0's l1: 95.9257",
      "\n",
      "[1500]\tvalid_0's l1: 95.298",
      "\n",
      "[1600]\tvalid_0's l1: 94.7047",
      "\n",
      "[1700]\tvalid_0's l1: 94.1338",
      "\n",
      "[1800]\tvalid_0's l1: 93.6883",
      "\n",
      "[1900]\tvalid_0's l1: 93.2522",
      "\n",
      "[2000]\tvalid_0's l1: 92.9489",
      "\n",
      "[2100]\tvalid_0's l1: 92.5809",
      "\n",
      "[2200]\tvalid_0's l1: 92.1646",
      "\n",
      "[2300]\tvalid_0's l1: 91.8245",
      "\n",
      "[2400]\tvalid_0's l1: 91.6526",
      "\n",
      "[2500]\tvalid_0's l1: 91.4305",
      "\n",
      "[2600]\tvalid_0's l1: 91.1751",
      "\n",
      "[2700]\tvalid_0's l1: 90.9021",
      "\n",
      "[2800]\tvalid_0's l1: 90.5863",
      "\n",
      "[2900]\tvalid_0's l1: 90.3819",
      "\n",
      "[3000]\tvalid_0's l1: 90.1922",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[2996]\tvalid_0's l1: 90.1918",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMRegressor(min_data_in_leaf= 30,num_leaves=230,\n",
    "    reg_alpha=0., reg_lambda=0.01, objective='mse', metric='mae',\n",
    "    max_depth=8, learning_rate=0.03, min_child_samples=20,\n",
    "    n_estimators=1000, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,num_iterations=3000\n",
    ")\n",
    "data_lgb, predict_label = get_predict_w(lgb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019, n_splits=5)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 192.508",
      "\n",
      "[200]\tvalid_0's l1: 148.641",
      "\n",
      "[300]\tvalid_0's l1: 129.325",
      "\n",
      "[400]\tvalid_0's l1: 116.826",
      "\n",
      "[500]\tvalid_0's l1: 110.223",
      "\n",
      "[600]\tvalid_0's l1: 105.455",
      "\n",
      "[700]\tvalid_0's l1: 101.987",
      "\n",
      "[800]\tvalid_0's l1: 99.3554",
      "\n",
      "[900]\tvalid_0's l1: 97.001",
      "\n",
      "[1000]\tvalid_0's l1: 95.469",
      "\n",
      "[1100]\tvalid_0's l1: 94.2452",
      "\n",
      "[1200]\tvalid_0's l1: 92.9931",
      "\n",
      "[1300]\tvalid_0's l1: 91.9281",
      "\n",
      "[1400]\tvalid_0's l1: 91.3764",
      "\n",
      "[1500]\tvalid_0's l1: 90.5247",
      "\n",
      "[1600]\tvalid_0's l1: 89.9381",
      "\n",
      "[1700]\tvalid_0's l1: 89.4372",
      "\n",
      "[1800]\tvalid_0's l1: 88.8513",
      "\n",
      "[1900]\tvalid_0's l1: 88.4013",
      "\n",
      "[2000]\tvalid_0's l1: 88.0501",
      "\n",
      "[2100]\tvalid_0's l1: 87.5527",
      "\n",
      "[2200]\tvalid_0's l1: 87.1427",
      "\n",
      "[2300]\tvalid_0's l1: 86.8578",
      "\n",
      "[2400]\tvalid_0's l1: 86.5982",
      "\n",
      "[2500]\tvalid_0's l1: 86.3142",
      "\n",
      "[2600]\tvalid_0's l1: 86.0056",
      "\n",
      "[2700]\tvalid_0's l1: 85.7384",
      "\n",
      "[2800]\tvalid_0's l1: 85.5153",
      "\n",
      "[2900]\tvalid_0's l1: 85.1779",
      "\n",
      "[3000]\tvalid_0's l1: 84.9487",
      "\n",
      "[3100]\tvalid_0's l1: 84.7872",
      "\n",
      "[3200]\tvalid_0's l1: 84.6499",
      "\n",
      "[3300]\tvalid_0's l1: 84.5318",
      "\n",
      "[3400]\tvalid_0's l1: 84.4014",
      "\n",
      "[3500]\tvalid_0's l1: 84.2266",
      "\n",
      "[3600]\tvalid_0's l1: 84.1012",
      "\n",
      "[3700]\tvalid_0's l1: 84.0118",
      "\n",
      "[3800]\tvalid_0's l1: 83.9223",
      "\n",
      "[3900]\tvalid_0's l1: 83.8566",
      "\n",
      "[4000]\tvalid_0's l1: 83.7795",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[4000]\tvalid_0's l1: 83.7795",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 200.598",
      "\n",
      "[200]\tvalid_0's l1: 155.185",
      "\n",
      "[300]\tvalid_0's l1: 131.929",
      "\n",
      "[400]\tvalid_0's l1: 120.797",
      "\n",
      "[500]\tvalid_0's l1: 115.168",
      "\n",
      "[600]\tvalid_0's l1: 109.5",
      "\n",
      "[700]\tvalid_0's l1: 105.91",
      "\n",
      "[800]\tvalid_0's l1: 103.584",
      "\n",
      "[900]\tvalid_0's l1: 101.583",
      "\n",
      "[1000]\tvalid_0's l1: 100.003",
      "\n",
      "[1100]\tvalid_0's l1: 98.632",
      "\n",
      "[1200]\tvalid_0's l1: 97.4043",
      "\n",
      "[1300]\tvalid_0's l1: 96.5225",
      "\n",
      "[1400]\tvalid_0's l1: 95.7009",
      "\n",
      "[1500]\tvalid_0's l1: 95.1735",
      "\n",
      "[1600]\tvalid_0's l1: 94.6187",
      "\n",
      "[1700]\tvalid_0's l1: 94.1719",
      "\n",
      "[1800]\tvalid_0's l1: 93.7648",
      "\n",
      "[1900]\tvalid_0's l1: 93.3409",
      "\n",
      "[2000]\tvalid_0's l1: 93.0031",
      "\n",
      "[2100]\tvalid_0's l1: 92.6348",
      "\n",
      "[2200]\tvalid_0's l1: 92.2757",
      "\n",
      "[2300]\tvalid_0's l1: 92.0194",
      "\n",
      "[2400]\tvalid_0's l1: 91.7067",
      "\n",
      "[2500]\tvalid_0's l1: 91.497",
      "\n",
      "[2600]\tvalid_0's l1: 91.238",
      "\n",
      "[2700]\tvalid_0's l1: 91.0526",
      "\n",
      "[2800]\tvalid_0's l1: 90.8864",
      "\n",
      "[2900]\tvalid_0's l1: 90.7782",
      "\n",
      "[3000]\tvalid_0's l1: 90.5265",
      "\n",
      "[3100]\tvalid_0's l1: 90.4266",
      "\n",
      "[3200]\tvalid_0's l1: 90.2529",
      "\n",
      "[3300]\tvalid_0's l1: 90.1353",
      "\n",
      "[3400]\tvalid_0's l1: 90.0112",
      "\n",
      "[3500]\tvalid_0's l1: 89.8851",
      "\n",
      "[3600]\tvalid_0's l1: 89.7293",
      "\n",
      "[3700]\tvalid_0's l1: 89.6552",
      "\n",
      "[3800]\tvalid_0's l1: 89.5235",
      "\n",
      "[3900]\tvalid_0's l1: 89.4249",
      "\n",
      "[4000]\tvalid_0's l1: 89.3468",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[3992]\tvalid_0's l1: 89.3373",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 207.271",
      "\n",
      "[200]\tvalid_0's l1: 157.67",
      "\n",
      "[300]\tvalid_0's l1: 137.121",
      "\n",
      "[400]\tvalid_0's l1: 124.508",
      "\n",
      "[500]\tvalid_0's l1: 116.641",
      "\n",
      "[600]\tvalid_0's l1: 110.851",
      "\n",
      "[700]\tvalid_0's l1: 107.121",
      "\n",
      "[800]\tvalid_0's l1: 104.419",
      "\n",
      "[900]\tvalid_0's l1: 102.164",
      "\n",
      "[1000]\tvalid_0's l1: 100.758",
      "\n",
      "[1100]\tvalid_0's l1: 99.2508",
      "\n",
      "[1200]\tvalid_0's l1: 97.6097",
      "\n",
      "[1300]\tvalid_0's l1: 96.76",
      "\n",
      "[1400]\tvalid_0's l1: 96.0438",
      "\n",
      "[1500]\tvalid_0's l1: 95.3006",
      "\n",
      "[1600]\tvalid_0's l1: 94.5466",
      "\n",
      "[1700]\tvalid_0's l1: 94.0505",
      "\n",
      "[1800]\tvalid_0's l1: 93.6144",
      "\n",
      "[1900]\tvalid_0's l1: 93.1843",
      "\n",
      "[2000]\tvalid_0's l1: 92.7478",
      "\n",
      "[2100]\tvalid_0's l1: 92.4273",
      "\n",
      "[2200]\tvalid_0's l1: 92.0591",
      "\n",
      "[2300]\tvalid_0's l1: 91.8209",
      "\n",
      "[2400]\tvalid_0's l1: 91.5852",
      "\n",
      "[2500]\tvalid_0's l1: 91.3513",
      "\n",
      "[2600]\tvalid_0's l1: 91.0506",
      "\n",
      "[2700]\tvalid_0's l1: 90.9125",
      "\n",
      "[2800]\tvalid_0's l1: 90.6457",
      "\n",
      "[2900]\tvalid_0's l1: 90.5055",
      "\n",
      "[3000]\tvalid_0's l1: 90.3524",
      "\n",
      "[3100]\tvalid_0's l1: 90.2157",
      "\n",
      "[3200]\tvalid_0's l1: 90.0485",
      "\n",
      "[3300]\tvalid_0's l1: 89.8332",
      "\n",
      "[3400]\tvalid_0's l1: 89.7306",
      "\n",
      "[3500]\tvalid_0's l1: 89.6715",
      "\n",
      "[3600]\tvalid_0's l1: 89.6055",
      "\n",
      "[3700]\tvalid_0's l1: 89.4885",
      "\n",
      "[3800]\tvalid_0's l1: 89.405",
      "\n",
      "[3900]\tvalid_0's l1: 89.2767",
      "\n",
      "[4000]\tvalid_0's l1: 89.1623",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[3995]\tvalid_0's l1: 89.1553",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 186.007",
      "\n",
      "[200]\tvalid_0's l1: 150.611",
      "\n",
      "[300]\tvalid_0's l1: 130.244",
      "\n",
      "[400]\tvalid_0's l1: 118.922",
      "\n",
      "[500]\tvalid_0's l1: 111.204",
      "\n",
      "[600]\tvalid_0's l1: 106.892",
      "\n",
      "[700]\tvalid_0's l1: 103.358",
      "\n",
      "[800]\tvalid_0's l1: 100.812",
      "\n",
      "[900]\tvalid_0's l1: 99.2065",
      "\n",
      "[1000]\tvalid_0's l1: 97.8577",
      "\n",
      "[1100]\tvalid_0's l1: 96.6892",
      "\n",
      "[1200]\tvalid_0's l1: 95.8774",
      "\n",
      "[1300]\tvalid_0's l1: 95.0695",
      "\n",
      "[1400]\tvalid_0's l1: 94.322",
      "\n",
      "[1500]\tvalid_0's l1: 93.5806",
      "\n",
      "[1600]\tvalid_0's l1: 93.0702",
      "\n",
      "[1700]\tvalid_0's l1: 92.6065",
      "\n",
      "[1800]\tvalid_0's l1: 92.2007",
      "\n",
      "[1900]\tvalid_0's l1: 91.6736",
      "\n",
      "[2000]\tvalid_0's l1: 91.3442",
      "\n",
      "[2100]\tvalid_0's l1: 91.0252",
      "\n",
      "[2200]\tvalid_0's l1: 90.6793",
      "\n",
      "[2300]\tvalid_0's l1: 90.3597",
      "\n",
      "[2400]\tvalid_0's l1: 90.1097",
      "\n",
      "[2500]\tvalid_0's l1: 89.853",
      "\n",
      "[2600]\tvalid_0's l1: 89.7201",
      "\n",
      "[2700]\tvalid_0's l1: 89.5584",
      "\n",
      "[2800]\tvalid_0's l1: 89.3057",
      "\n",
      "[2900]\tvalid_0's l1: 89.1094",
      "\n",
      "[3000]\tvalid_0's l1: 88.928",
      "\n",
      "[3100]\tvalid_0's l1: 88.7766",
      "\n",
      "[3200]\tvalid_0's l1: 88.6802",
      "\n",
      "[3300]\tvalid_0's l1: 88.5554",
      "\n",
      "[3400]\tvalid_0's l1: 88.3493",
      "\n",
      "[3500]\tvalid_0's l1: 88.2071",
      "\n",
      "[3600]\tvalid_0's l1: 88.1463",
      "\n",
      "[3700]\tvalid_0's l1: 88.0668",
      "\n",
      "[3800]\tvalid_0's l1: 87.9879",
      "\n",
      "[3900]\tvalid_0's l1: 87.8317",
      "\n",
      "[4000]\tvalid_0's l1: 87.6981",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[3999]\tvalid_0's l1: 87.6976",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 200.235",
      "\n",
      "[200]\tvalid_0's l1: 152.55",
      "\n",
      "[300]\tvalid_0's l1: 135.254",
      "\n",
      "[400]\tvalid_0's l1: 122.491",
      "\n",
      "[500]\tvalid_0's l1: 114.664",
      "\n",
      "[600]\tvalid_0's l1: 109.595",
      "\n",
      "[700]\tvalid_0's l1: 106.687",
      "\n",
      "[800]\tvalid_0's l1: 104.276",
      "\n",
      "[900]\tvalid_0's l1: 101.733",
      "\n",
      "[1000]\tvalid_0's l1: 99.8535",
      "\n",
      "[1100]\tvalid_0's l1: 98.6749",
      "\n",
      "[1200]\tvalid_0's l1: 97.552",
      "\n",
      "[1300]\tvalid_0's l1: 96.5158",
      "\n",
      "[1400]\tvalid_0's l1: 95.9257",
      "\n",
      "[1500]\tvalid_0's l1: 95.298",
      "\n",
      "[1600]\tvalid_0's l1: 94.7047",
      "\n",
      "[1700]\tvalid_0's l1: 94.1338",
      "\n",
      "[1800]\tvalid_0's l1: 93.6883",
      "\n",
      "[1900]\tvalid_0's l1: 93.2522",
      "\n",
      "[2000]\tvalid_0's l1: 92.9489",
      "\n",
      "[2100]\tvalid_0's l1: 92.5809",
      "\n",
      "[2200]\tvalid_0's l1: 92.1646",
      "\n",
      "[2300]\tvalid_0's l1: 91.8245",
      "\n",
      "[2400]\tvalid_0's l1: 91.6526",
      "\n",
      "[2500]\tvalid_0's l1: 91.4305",
      "\n",
      "[2600]\tvalid_0's l1: 91.1751",
      "\n",
      "[2700]\tvalid_0's l1: 90.9021",
      "\n",
      "[2800]\tvalid_0's l1: 90.5863",
      "\n",
      "[2900]\tvalid_0's l1: 90.3819",
      "\n",
      "[3000]\tvalid_0's l1: 90.1922",
      "\n",
      "[3100]\tvalid_0's l1: 89.9902",
      "\n",
      "[3200]\tvalid_0's l1: 89.7326",
      "\n",
      "[3300]\tvalid_0's l1: 89.56",
      "\n",
      "[3400]\tvalid_0's l1: 89.4962",
      "\n",
      "[3500]\tvalid_0's l1: 89.2823",
      "\n",
      "[3600]\tvalid_0's l1: 89.2054",
      "\n",
      "[3700]\tvalid_0's l1: 89.0384",
      "\n",
      "[3800]\tvalid_0's l1: 88.9231",
      "\n",
      "[3900]\tvalid_0's l1: 88.77",
      "\n",
      "[4000]\tvalid_0's l1: 88.6838",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[3998]\tvalid_0's l1: 88.681",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMRegressor(min_data_in_leaf= 30,num_leaves=230,\n",
    "    reg_alpha=0., reg_lambda=0.01, objective='mse', metric='mae',\n",
    "    max_depth=8, learning_rate=0.03, min_child_samples=20,\n",
    "    n_estimators=1000, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,num_iterations=4000\n",
    ")\n",
    "data_lgb, predict_label = get_predict_w(lgb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019, n_splits=5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 192.508",
      "\n",
      "[200]\tvalid_0's l1: 148.641",
      "\n",
      "[300]\tvalid_0's l1: 129.325",
      "\n",
      "[400]\tvalid_0's l1: 116.826",
      "\n",
      "[500]\tvalid_0's l1: 110.223",
      "\n",
      "[600]\tvalid_0's l1: 105.455",
      "\n",
      "[700]\tvalid_0's l1: 101.987",
      "\n",
      "[800]\tvalid_0's l1: 99.3554",
      "\n",
      "[900]\tvalid_0's l1: 97.001",
      "\n",
      "[1000]\tvalid_0's l1: 95.469",
      "\n",
      "[1100]\tvalid_0's l1: 94.2452",
      "\n",
      "[1200]\tvalid_0's l1: 92.9931",
      "\n",
      "[1300]\tvalid_0's l1: 91.9281",
      "\n",
      "[1400]\tvalid_0's l1: 91.3764",
      "\n",
      "[1500]\tvalid_0's l1: 90.5247",
      "\n",
      "[1600]\tvalid_0's l1: 89.9381",
      "\n",
      "[1700]\tvalid_0's l1: 89.4372",
      "\n",
      "[1800]\tvalid_0's l1: 88.8513",
      "\n",
      "[1900]\tvalid_0's l1: 88.4013",
      "\n",
      "[2000]\tvalid_0's l1: 88.0501",
      "\n",
      "[2100]\tvalid_0's l1: 87.5527",
      "\n",
      "[2200]\tvalid_0's l1: 87.1427",
      "\n",
      "[2300]\tvalid_0's l1: 86.8578",
      "\n",
      "[2400]\tvalid_0's l1: 86.5982",
      "\n",
      "[2500]\tvalid_0's l1: 86.3142",
      "\n",
      "[2600]\tvalid_0's l1: 86.0056",
      "\n",
      "[2700]\tvalid_0's l1: 85.7384",
      "\n",
      "[2800]\tvalid_0's l1: 85.5153",
      "\n",
      "[2900]\tvalid_0's l1: 85.1779",
      "\n",
      "[3000]\tvalid_0's l1: 84.9487",
      "\n",
      "[3100]\tvalid_0's l1: 84.7872",
      "\n",
      "[3200]\tvalid_0's l1: 84.6499",
      "\n",
      "[3300]\tvalid_0's l1: 84.5318",
      "\n",
      "[3400]\tvalid_0's l1: 84.4014",
      "\n",
      "[3500]\tvalid_0's l1: 84.2266",
      "\n",
      "[3600]\tvalid_0's l1: 84.1012",
      "\n",
      "[3700]\tvalid_0's l1: 84.0118",
      "\n",
      "[3800]\tvalid_0's l1: 83.9223",
      "\n",
      "[3900]\tvalid_0's l1: 83.8566",
      "\n",
      "[4000]\tvalid_0's l1: 83.7795",
      "\n",
      "[4100]\tvalid_0's l1: 83.7286",
      "\n",
      "[4200]\tvalid_0's l1: 83.6396",
      "\n",
      "[4300]\tvalid_0's l1: 83.5825",
      "\n",
      "[4400]\tvalid_0's l1: 83.5296",
      "\n",
      "[4500]\tvalid_0's l1: 83.4025",
      "\n",
      "[4600]\tvalid_0's l1: 83.3367",
      "\n",
      "[4700]\tvalid_0's l1: 83.2389",
      "\n",
      "[4800]\tvalid_0's l1: 83.1707",
      "\n",
      "[4900]\tvalid_0's l1: 83.1242",
      "\n",
      "[5000]\tvalid_0's l1: 83.031",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[4997]\tvalid_0's l1: 83.0264",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 200.598",
      "\n",
      "[200]\tvalid_0's l1: 155.185",
      "\n",
      "[300]\tvalid_0's l1: 131.929",
      "\n",
      "[400]\tvalid_0's l1: 120.797",
      "\n",
      "[500]\tvalid_0's l1: 115.168",
      "\n",
      "[600]\tvalid_0's l1: 109.5",
      "\n",
      "[700]\tvalid_0's l1: 105.91",
      "\n",
      "[800]\tvalid_0's l1: 103.584",
      "\n",
      "[900]\tvalid_0's l1: 101.583",
      "\n",
      "[1000]\tvalid_0's l1: 100.003",
      "\n",
      "[1100]\tvalid_0's l1: 98.632",
      "\n",
      "[1200]\tvalid_0's l1: 97.4043",
      "\n",
      "[1300]\tvalid_0's l1: 96.5225",
      "\n",
      "[1400]\tvalid_0's l1: 95.7009",
      "\n",
      "[1500]\tvalid_0's l1: 95.1735",
      "\n",
      "[1600]\tvalid_0's l1: 94.6187",
      "\n",
      "[1700]\tvalid_0's l1: 94.1719",
      "\n",
      "[1800]\tvalid_0's l1: 93.7648",
      "\n",
      "[1900]\tvalid_0's l1: 93.3409",
      "\n",
      "[2000]\tvalid_0's l1: 93.0031",
      "\n",
      "[2100]\tvalid_0's l1: 92.6348",
      "\n",
      "[2200]\tvalid_0's l1: 92.2757",
      "\n",
      "[2300]\tvalid_0's l1: 92.0194",
      "\n",
      "[2400]\tvalid_0's l1: 91.7067",
      "\n",
      "[2500]\tvalid_0's l1: 91.497",
      "\n",
      "[2600]\tvalid_0's l1: 91.238",
      "\n",
      "[2700]\tvalid_0's l1: 91.0526",
      "\n",
      "[2800]\tvalid_0's l1: 90.8864",
      "\n",
      "[2900]\tvalid_0's l1: 90.7782",
      "\n",
      "[3000]\tvalid_0's l1: 90.5265",
      "\n",
      "[3100]\tvalid_0's l1: 90.4266",
      "\n",
      "[3200]\tvalid_0's l1: 90.2529",
      "\n",
      "[3300]\tvalid_0's l1: 90.1353",
      "\n",
      "[3400]\tvalid_0's l1: 90.0112",
      "\n",
      "[3500]\tvalid_0's l1: 89.8851",
      "\n",
      "[3600]\tvalid_0's l1: 89.7293",
      "\n",
      "[3700]\tvalid_0's l1: 89.6552",
      "\n",
      "[3800]\tvalid_0's l1: 89.5235",
      "\n",
      "[3900]\tvalid_0's l1: 89.4249",
      "\n",
      "[4000]\tvalid_0's l1: 89.3468",
      "\n",
      "[4100]\tvalid_0's l1: 89.279",
      "\n",
      "[4200]\tvalid_0's l1: 89.1882",
      "\n",
      "[4300]\tvalid_0's l1: 89.1428",
      "\n",
      "[4400]\tvalid_0's l1: 89.0844",
      "\n",
      "[4500]\tvalid_0's l1: 89.0378",
      "\n",
      "[4600]\tvalid_0's l1: 88.9174",
      "\n",
      "[4700]\tvalid_0's l1: 88.8794",
      "\n",
      "[4800]\tvalid_0's l1: 88.8267",
      "\n",
      "[4900]\tvalid_0's l1: 88.7758",
      "\n",
      "[5000]\tvalid_0's l1: 88.6391",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[5000]\tvalid_0's l1: 88.6391",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 207.271",
      "\n",
      "[200]\tvalid_0's l1: 157.67",
      "\n",
      "[300]\tvalid_0's l1: 137.121",
      "\n",
      "[400]\tvalid_0's l1: 124.508",
      "\n",
      "[500]\tvalid_0's l1: 116.641",
      "\n",
      "[600]\tvalid_0's l1: 110.851",
      "\n",
      "[700]\tvalid_0's l1: 107.121",
      "\n",
      "[800]\tvalid_0's l1: 104.419",
      "\n",
      "[900]\tvalid_0's l1: 102.164",
      "\n",
      "[1000]\tvalid_0's l1: 100.758",
      "\n",
      "[1100]\tvalid_0's l1: 99.2508",
      "\n",
      "[1200]\tvalid_0's l1: 97.6097",
      "\n",
      "[1300]\tvalid_0's l1: 96.76",
      "\n",
      "[1400]\tvalid_0's l1: 96.0438",
      "\n",
      "[1500]\tvalid_0's l1: 95.3006",
      "\n",
      "[1600]\tvalid_0's l1: 94.5466",
      "\n",
      "[1700]\tvalid_0's l1: 94.0505",
      "\n",
      "[1800]\tvalid_0's l1: 93.6144",
      "\n",
      "[1900]\tvalid_0's l1: 93.1843",
      "\n",
      "[2000]\tvalid_0's l1: 92.7478",
      "\n",
      "[2100]\tvalid_0's l1: 92.4273",
      "\n",
      "[2200]\tvalid_0's l1: 92.0591",
      "\n",
      "[2300]\tvalid_0's l1: 91.8209",
      "\n",
      "[2400]\tvalid_0's l1: 91.5852",
      "\n",
      "[2500]\tvalid_0's l1: 91.3513",
      "\n",
      "[2600]\tvalid_0's l1: 91.0506",
      "\n",
      "[2700]\tvalid_0's l1: 90.9125",
      "\n",
      "[2800]\tvalid_0's l1: 90.6457",
      "\n",
      "[2900]\tvalid_0's l1: 90.5055",
      "\n",
      "[3000]\tvalid_0's l1: 90.3524",
      "\n",
      "[3100]\tvalid_0's l1: 90.2157",
      "\n",
      "[3200]\tvalid_0's l1: 90.0485",
      "\n",
      "[3300]\tvalid_0's l1: 89.8332",
      "\n",
      "[3400]\tvalid_0's l1: 89.7306",
      "\n",
      "[3500]\tvalid_0's l1: 89.6715",
      "\n",
      "[3600]\tvalid_0's l1: 89.6055",
      "\n",
      "[3700]\tvalid_0's l1: 89.4885",
      "\n",
      "[3800]\tvalid_0's l1: 89.405",
      "\n",
      "[3900]\tvalid_0's l1: 89.2767",
      "\n",
      "[4000]\tvalid_0's l1: 89.1623",
      "\n",
      "[4100]\tvalid_0's l1: 89.1136",
      "\n",
      "[4200]\tvalid_0's l1: 89.0221",
      "\n",
      "[4300]\tvalid_0's l1: 88.968",
      "\n",
      "[4400]\tvalid_0's l1: 88.8642",
      "\n",
      "[4500]\tvalid_0's l1: 88.7962",
      "\n",
      "[4600]\tvalid_0's l1: 88.7397",
      "\n",
      "[4700]\tvalid_0's l1: 88.6878",
      "\n",
      "[4800]\tvalid_0's l1: 88.5835",
      "\n",
      "[4900]\tvalid_0's l1: 88.5028",
      "\n",
      "[5000]\tvalid_0's l1: 88.4322",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[4997]\tvalid_0's l1: 88.4261",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 186.007",
      "\n",
      "[200]\tvalid_0's l1: 150.611",
      "\n",
      "[300]\tvalid_0's l1: 130.244",
      "\n",
      "[400]\tvalid_0's l1: 118.922",
      "\n",
      "[500]\tvalid_0's l1: 111.204",
      "\n",
      "[600]\tvalid_0's l1: 106.892",
      "\n",
      "[700]\tvalid_0's l1: 103.358",
      "\n",
      "[800]\tvalid_0's l1: 100.812",
      "\n",
      "[900]\tvalid_0's l1: 99.2065",
      "\n",
      "[1000]\tvalid_0's l1: 97.8577",
      "\n",
      "[1100]\tvalid_0's l1: 96.6892",
      "\n",
      "[1200]\tvalid_0's l1: 95.8774",
      "\n",
      "[1300]\tvalid_0's l1: 95.0695",
      "\n",
      "[1400]\tvalid_0's l1: 94.322",
      "\n",
      "[1500]\tvalid_0's l1: 93.5806",
      "\n",
      "[1600]\tvalid_0's l1: 93.0702",
      "\n",
      "[1700]\tvalid_0's l1: 92.6065",
      "\n",
      "[1800]\tvalid_0's l1: 92.2007",
      "\n",
      "[1900]\tvalid_0's l1: 91.6736",
      "\n",
      "[2000]\tvalid_0's l1: 91.3442",
      "\n",
      "[2100]\tvalid_0's l1: 91.0252",
      "\n",
      "[2200]\tvalid_0's l1: 90.6793",
      "\n",
      "[2300]\tvalid_0's l1: 90.3597",
      "\n",
      "[2400]\tvalid_0's l1: 90.1097",
      "\n",
      "[2500]\tvalid_0's l1: 89.853",
      "\n",
      "[2600]\tvalid_0's l1: 89.7201",
      "\n",
      "[2700]\tvalid_0's l1: 89.5584",
      "\n",
      "[2800]\tvalid_0's l1: 89.3057",
      "\n",
      "[2900]\tvalid_0's l1: 89.1094",
      "\n",
      "[3000]\tvalid_0's l1: 88.928",
      "\n",
      "[3100]\tvalid_0's l1: 88.7766",
      "\n",
      "[3200]\tvalid_0's l1: 88.6802",
      "\n",
      "[3300]\tvalid_0's l1: 88.5554",
      "\n",
      "[3400]\tvalid_0's l1: 88.3493",
      "\n",
      "[3500]\tvalid_0's l1: 88.2071",
      "\n",
      "[3600]\tvalid_0's l1: 88.1463",
      "\n",
      "[3700]\tvalid_0's l1: 88.0668",
      "\n",
      "[3800]\tvalid_0's l1: 87.9879",
      "\n",
      "[3900]\tvalid_0's l1: 87.8317",
      "\n",
      "[4000]\tvalid_0's l1: 87.6981",
      "\n",
      "[4100]\tvalid_0's l1: 87.6538",
      "\n",
      "[4200]\tvalid_0's l1: 87.5744",
      "\n",
      "[4300]\tvalid_0's l1: 87.475",
      "\n",
      "[4400]\tvalid_0's l1: 87.3899",
      "\n",
      "[4500]\tvalid_0's l1: 87.3481",
      "\n",
      "[4600]\tvalid_0's l1: 87.2596",
      "\n",
      "[4700]\tvalid_0's l1: 87.1623",
      "\n",
      "[4800]\tvalid_0's l1: 87.1343",
      "\n",
      "[4900]\tvalid_0's l1: 87.0229",
      "\n",
      "[5000]\tvalid_0's l1: 86.9815",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[5000]\tvalid_0's l1: 86.9815",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 200.235",
      "\n",
      "[200]\tvalid_0's l1: 152.55",
      "\n",
      "[300]\tvalid_0's l1: 135.254",
      "\n",
      "[400]\tvalid_0's l1: 122.491",
      "\n",
      "[500]\tvalid_0's l1: 114.664",
      "\n",
      "[600]\tvalid_0's l1: 109.595",
      "\n",
      "[700]\tvalid_0's l1: 106.687",
      "\n",
      "[800]\tvalid_0's l1: 104.276",
      "\n",
      "[900]\tvalid_0's l1: 101.733",
      "\n",
      "[1000]\tvalid_0's l1: 99.8535",
      "\n",
      "[1100]\tvalid_0's l1: 98.6749",
      "\n",
      "[1200]\tvalid_0's l1: 97.552",
      "\n",
      "[1300]\tvalid_0's l1: 96.5158",
      "\n",
      "[1400]\tvalid_0's l1: 95.9257",
      "\n",
      "[1500]\tvalid_0's l1: 95.298",
      "\n",
      "[1600]\tvalid_0's l1: 94.7047",
      "\n",
      "[1700]\tvalid_0's l1: 94.1338",
      "\n",
      "[1800]\tvalid_0's l1: 93.6883",
      "\n",
      "[1900]\tvalid_0's l1: 93.2522",
      "\n",
      "[2000]\tvalid_0's l1: 92.9489",
      "\n",
      "[2100]\tvalid_0's l1: 92.5809",
      "\n",
      "[2200]\tvalid_0's l1: 92.1646",
      "\n",
      "[2300]\tvalid_0's l1: 91.8245",
      "\n",
      "[2400]\tvalid_0's l1: 91.6526",
      "\n",
      "[2500]\tvalid_0's l1: 91.4305",
      "\n",
      "[2600]\tvalid_0's l1: 91.1751",
      "\n",
      "[2700]\tvalid_0's l1: 90.9021",
      "\n",
      "[2800]\tvalid_0's l1: 90.5863",
      "\n",
      "[2900]\tvalid_0's l1: 90.3819",
      "\n",
      "[3000]\tvalid_0's l1: 90.1922",
      "\n",
      "[3100]\tvalid_0's l1: 89.9902",
      "\n",
      "[3200]\tvalid_0's l1: 89.7326",
      "\n",
      "[3300]\tvalid_0's l1: 89.56",
      "\n",
      "[3400]\tvalid_0's l1: 89.4962",
      "\n",
      "[3500]\tvalid_0's l1: 89.2823",
      "\n",
      "[3600]\tvalid_0's l1: 89.2054",
      "\n",
      "[3700]\tvalid_0's l1: 89.0384",
      "\n",
      "[3800]\tvalid_0's l1: 88.9231",
      "\n",
      "[3900]\tvalid_0's l1: 88.77",
      "\n",
      "[4000]\tvalid_0's l1: 88.6838",
      "\n",
      "[4100]\tvalid_0's l1: 88.5461",
      "\n",
      "[4200]\tvalid_0's l1: 88.45",
      "\n",
      "[4300]\tvalid_0's l1: 88.3275",
      "\n",
      "[4400]\tvalid_0's l1: 88.2035",
      "\n",
      "[4500]\tvalid_0's l1: 88.1248",
      "\n",
      "[4600]\tvalid_0's l1: 88.0551",
      "\n",
      "[4700]\tvalid_0's l1: 88.0091",
      "\n",
      "[4800]\tvalid_0's l1: 87.9383",
      "\n",
      "[4900]\tvalid_0's l1: 87.9105",
      "\n",
      "[5000]\tvalid_0's l1: 87.8679",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[4978]\tvalid_0's l1: 87.8537",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMRegressor(min_data_in_leaf= 30,num_leaves=230,\n",
    "    reg_alpha=0., reg_lambda=0.01, objective='mse', metric='mae',\n",
    "    max_depth=8, learning_rate=0.03, min_child_samples=20,\n",
    "    n_estimators=1000, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,num_iterations=5000\n",
    ")\n",
    "data_lgb, predict_label = get_predict_w(lgb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019, n_splits=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 192.508",
      "\n",
      "[200]\tvalid_0's l1: 148.641",
      "\n",
      "[300]\tvalid_0's l1: 129.325",
      "\n",
      "[400]\tvalid_0's l1: 116.826",
      "\n",
      "[500]\tvalid_0's l1: 110.223",
      "\n",
      "[600]\tvalid_0's l1: 105.455",
      "\n",
      "[700]\tvalid_0's l1: 101.987",
      "\n",
      "[800]\tvalid_0's l1: 99.3554",
      "\n",
      "[900]\tvalid_0's l1: 97.001",
      "\n",
      "[1000]\tvalid_0's l1: 95.469",
      "\n",
      "[1100]\tvalid_0's l1: 94.2452",
      "\n",
      "[1200]\tvalid_0's l1: 92.9931",
      "\n",
      "[1300]\tvalid_0's l1: 91.9281",
      "\n",
      "[1400]\tvalid_0's l1: 91.3764",
      "\n",
      "[1500]\tvalid_0's l1: 90.5247",
      "\n",
      "[1600]\tvalid_0's l1: 89.9381",
      "\n",
      "[1700]\tvalid_0's l1: 89.4372",
      "\n",
      "[1800]\tvalid_0's l1: 88.8513",
      "\n",
      "[1900]\tvalid_0's l1: 88.4013",
      "\n",
      "[2000]\tvalid_0's l1: 88.0501",
      "\n",
      "[2100]\tvalid_0's l1: 87.5527",
      "\n",
      "[2200]\tvalid_0's l1: 87.1427",
      "\n",
      "[2300]\tvalid_0's l1: 86.8578",
      "\n",
      "[2400]\tvalid_0's l1: 86.5982",
      "\n",
      "[2500]\tvalid_0's l1: 86.3142",
      "\n",
      "[2600]\tvalid_0's l1: 86.0056",
      "\n",
      "[2700]\tvalid_0's l1: 85.7384",
      "\n",
      "[2800]\tvalid_0's l1: 85.5153",
      "\n",
      "[2900]\tvalid_0's l1: 85.1779",
      "\n",
      "[3000]\tvalid_0's l1: 84.9487",
      "\n",
      "[3100]\tvalid_0's l1: 84.7872",
      "\n",
      "[3200]\tvalid_0's l1: 84.6499",
      "\n",
      "[3300]\tvalid_0's l1: 84.5318",
      "\n",
      "[3400]\tvalid_0's l1: 84.4014",
      "\n",
      "[3500]\tvalid_0's l1: 84.2266",
      "\n",
      "[3600]\tvalid_0's l1: 84.1012",
      "\n",
      "[3700]\tvalid_0's l1: 84.0118",
      "\n",
      "[3800]\tvalid_0's l1: 83.9223",
      "\n",
      "[3900]\tvalid_0's l1: 83.8566",
      "\n",
      "[4000]\tvalid_0's l1: 83.7795",
      "\n",
      "[4100]\tvalid_0's l1: 83.7286",
      "\n",
      "[4200]\tvalid_0's l1: 83.6396",
      "\n",
      "[4300]\tvalid_0's l1: 83.5825",
      "\n",
      "[4400]\tvalid_0's l1: 83.5296",
      "\n",
      "[4500]\tvalid_0's l1: 83.4025",
      "\n",
      "[4600]\tvalid_0's l1: 83.3367",
      "\n",
      "[4700]\tvalid_0's l1: 83.2389",
      "\n",
      "[4800]\tvalid_0's l1: 83.1707",
      "\n",
      "[4900]\tvalid_0's l1: 83.1242",
      "\n",
      "[5000]\tvalid_0's l1: 83.031",
      "\n",
      "[5100]\tvalid_0's l1: 82.954",
      "\n",
      "[5200]\tvalid_0's l1: 82.9135",
      "\n",
      "[5300]\tvalid_0's l1: 82.8793",
      "\n",
      "[5400]\tvalid_0's l1: 82.8205",
      "\n",
      "[5500]\tvalid_0's l1: 82.7417",
      "\n",
      "[5600]\tvalid_0's l1: 82.6687",
      "\n",
      "[5700]\tvalid_0's l1: 82.6426",
      "\n",
      "[5800]\tvalid_0's l1: 82.6096",
      "\n",
      "[5900]\tvalid_0's l1: 82.5862",
      "\n",
      "[6000]\tvalid_0's l1: 82.567",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[5974]\tvalid_0's l1: 82.5574",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 200.598",
      "\n",
      "[200]\tvalid_0's l1: 155.185",
      "\n",
      "[300]\tvalid_0's l1: 131.929",
      "\n",
      "[400]\tvalid_0's l1: 120.797",
      "\n",
      "[500]\tvalid_0's l1: 115.168",
      "\n",
      "[600]\tvalid_0's l1: 109.5",
      "\n",
      "[700]\tvalid_0's l1: 105.91",
      "\n",
      "[800]\tvalid_0's l1: 103.584",
      "\n",
      "[900]\tvalid_0's l1: 101.583",
      "\n",
      "[1000]\tvalid_0's l1: 100.003",
      "\n",
      "[1100]\tvalid_0's l1: 98.632",
      "\n",
      "[1200]\tvalid_0's l1: 97.4043",
      "\n",
      "[1300]\tvalid_0's l1: 96.5225",
      "\n",
      "[1400]\tvalid_0's l1: 95.7009",
      "\n",
      "[1500]\tvalid_0's l1: 95.1735",
      "\n",
      "[1600]\tvalid_0's l1: 94.6187",
      "\n",
      "[1700]\tvalid_0's l1: 94.1719",
      "\n",
      "[1800]\tvalid_0's l1: 93.7648",
      "\n",
      "[1900]\tvalid_0's l1: 93.3409",
      "\n",
      "[2000]\tvalid_0's l1: 93.0031",
      "\n",
      "[2100]\tvalid_0's l1: 92.6348",
      "\n",
      "[2200]\tvalid_0's l1: 92.2757",
      "\n",
      "[2300]\tvalid_0's l1: 92.0194",
      "\n",
      "[2400]\tvalid_0's l1: 91.7067",
      "\n",
      "[2500]\tvalid_0's l1: 91.497",
      "\n",
      "[2600]\tvalid_0's l1: 91.238",
      "\n",
      "[2700]\tvalid_0's l1: 91.0526",
      "\n",
      "[2800]\tvalid_0's l1: 90.8864",
      "\n",
      "[2900]\tvalid_0's l1: 90.7782",
      "\n",
      "[3000]\tvalid_0's l1: 90.5265",
      "\n",
      "[3100]\tvalid_0's l1: 90.4266",
      "\n",
      "[3200]\tvalid_0's l1: 90.2529",
      "\n",
      "[3300]\tvalid_0's l1: 90.1353",
      "\n",
      "[3400]\tvalid_0's l1: 90.0112",
      "\n",
      "[3500]\tvalid_0's l1: 89.8851",
      "\n",
      "[3600]\tvalid_0's l1: 89.7293",
      "\n",
      "[3700]\tvalid_0's l1: 89.6552",
      "\n",
      "[3800]\tvalid_0's l1: 89.5235",
      "\n",
      "[3900]\tvalid_0's l1: 89.4249",
      "\n",
      "[4000]\tvalid_0's l1: 89.3468",
      "\n",
      "[4100]\tvalid_0's l1: 89.279",
      "\n",
      "[4200]\tvalid_0's l1: 89.1882",
      "\n",
      "[4300]\tvalid_0's l1: 89.1428",
      "\n",
      "[4400]\tvalid_0's l1: 89.0844",
      "\n",
      "[4500]\tvalid_0's l1: 89.0378",
      "\n",
      "[4600]\tvalid_0's l1: 88.9174",
      "\n",
      "[4700]\tvalid_0's l1: 88.8794",
      "\n",
      "[4800]\tvalid_0's l1: 88.8267",
      "\n",
      "[4900]\tvalid_0's l1: 88.7758",
      "\n",
      "[5000]\tvalid_0's l1: 88.6391",
      "\n",
      "[5100]\tvalid_0's l1: 88.5844",
      "\n",
      "[5200]\tvalid_0's l1: 88.5332",
      "\n",
      "[5300]\tvalid_0's l1: 88.4277",
      "\n",
      "[5400]\tvalid_0's l1: 88.3941",
      "\n",
      "[5500]\tvalid_0's l1: 88.352",
      "\n",
      "[5600]\tvalid_0's l1: 88.3056",
      "\n",
      "[5700]\tvalid_0's l1: 88.261",
      "\n",
      "[5800]\tvalid_0's l1: 88.2133",
      "\n",
      "[5900]\tvalid_0's l1: 88.1652",
      "\n",
      "[6000]\tvalid_0's l1: 88.1347",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[5992]\tvalid_0's l1: 88.131",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 207.271",
      "\n",
      "[200]\tvalid_0's l1: 157.67",
      "\n",
      "[300]\tvalid_0's l1: 137.121",
      "\n",
      "[400]\tvalid_0's l1: 124.508",
      "\n",
      "[500]\tvalid_0's l1: 116.641",
      "\n",
      "[600]\tvalid_0's l1: 110.851",
      "\n",
      "[700]\tvalid_0's l1: 107.121",
      "\n",
      "[800]\tvalid_0's l1: 104.419",
      "\n",
      "[900]\tvalid_0's l1: 102.164",
      "\n",
      "[1000]\tvalid_0's l1: 100.758",
      "\n",
      "[1100]\tvalid_0's l1: 99.2508",
      "\n",
      "[1200]\tvalid_0's l1: 97.6097",
      "\n",
      "[1300]\tvalid_0's l1: 96.76",
      "\n",
      "[1400]\tvalid_0's l1: 96.0438",
      "\n",
      "[1500]\tvalid_0's l1: 95.3006",
      "\n",
      "[1600]\tvalid_0's l1: 94.5466",
      "\n",
      "[1700]\tvalid_0's l1: 94.0505",
      "\n",
      "[1800]\tvalid_0's l1: 93.6144",
      "\n",
      "[1900]\tvalid_0's l1: 93.1843",
      "\n",
      "[2000]\tvalid_0's l1: 92.7478",
      "\n",
      "[2100]\tvalid_0's l1: 92.4273",
      "\n",
      "[2200]\tvalid_0's l1: 92.0591",
      "\n",
      "[2300]\tvalid_0's l1: 91.8209",
      "\n",
      "[2400]\tvalid_0's l1: 91.5852",
      "\n",
      "[2500]\tvalid_0's l1: 91.3513",
      "\n",
      "[2600]\tvalid_0's l1: 91.0506",
      "\n",
      "[2700]\tvalid_0's l1: 90.9125",
      "\n",
      "[2800]\tvalid_0's l1: 90.6457",
      "\n",
      "[2900]\tvalid_0's l1: 90.5055",
      "\n",
      "[3000]\tvalid_0's l1: 90.3524",
      "\n",
      "[3100]\tvalid_0's l1: 90.2157",
      "\n",
      "[3200]\tvalid_0's l1: 90.0485",
      "\n",
      "[3300]\tvalid_0's l1: 89.8332",
      "\n",
      "[3400]\tvalid_0's l1: 89.7306",
      "\n",
      "[3500]\tvalid_0's l1: 89.6715",
      "\n",
      "[3600]\tvalid_0's l1: 89.6055",
      "\n",
      "[3700]\tvalid_0's l1: 89.4885",
      "\n",
      "[3800]\tvalid_0's l1: 89.405",
      "\n",
      "[3900]\tvalid_0's l1: 89.2767",
      "\n",
      "[4000]\tvalid_0's l1: 89.1623",
      "\n",
      "[4100]\tvalid_0's l1: 89.1136",
      "\n",
      "[4200]\tvalid_0's l1: 89.0221",
      "\n",
      "[4300]\tvalid_0's l1: 88.968",
      "\n",
      "[4400]\tvalid_0's l1: 88.8642",
      "\n",
      "[4500]\tvalid_0's l1: 88.7962",
      "\n",
      "[4600]\tvalid_0's l1: 88.7397",
      "\n",
      "[4700]\tvalid_0's l1: 88.6878",
      "\n",
      "[4800]\tvalid_0's l1: 88.5835",
      "\n",
      "[4900]\tvalid_0's l1: 88.5028",
      "\n",
      "[5000]\tvalid_0's l1: 88.4322",
      "\n",
      "[5100]\tvalid_0's l1: 88.38",
      "\n",
      "[5200]\tvalid_0's l1: 88.2989",
      "\n",
      "[5300]\tvalid_0's l1: 88.2174",
      "\n",
      "[5400]\tvalid_0's l1: 88.2363",
      "\n",
      "Early stopping, best iteration is:\n[5305]\tvalid_0's l1: 88.213",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 186.007",
      "\n",
      "[200]\tvalid_0's l1: 150.611",
      "\n",
      "[300]\tvalid_0's l1: 130.244",
      "\n",
      "[400]\tvalid_0's l1: 118.922",
      "\n",
      "[500]\tvalid_0's l1: 111.204",
      "\n",
      "[600]\tvalid_0's l1: 106.892",
      "\n",
      "[700]\tvalid_0's l1: 103.358",
      "\n",
      "[800]\tvalid_0's l1: 100.812",
      "\n",
      "[900]\tvalid_0's l1: 99.2065",
      "\n",
      "[1000]\tvalid_0's l1: 97.8577",
      "\n",
      "[1100]\tvalid_0's l1: 96.6892",
      "\n",
      "[1200]\tvalid_0's l1: 95.8774",
      "\n",
      "[1300]\tvalid_0's l1: 95.0695",
      "\n",
      "[1400]\tvalid_0's l1: 94.322",
      "\n",
      "[1500]\tvalid_0's l1: 93.5806",
      "\n",
      "[1600]\tvalid_0's l1: 93.0702",
      "\n",
      "[1700]\tvalid_0's l1: 92.6065",
      "\n",
      "[1800]\tvalid_0's l1: 92.2007",
      "\n",
      "[1900]\tvalid_0's l1: 91.6736",
      "\n",
      "[2000]\tvalid_0's l1: 91.3442",
      "\n",
      "[2100]\tvalid_0's l1: 91.0252",
      "\n",
      "[2200]\tvalid_0's l1: 90.6793",
      "\n",
      "[2300]\tvalid_0's l1: 90.3597",
      "\n",
      "[2400]\tvalid_0's l1: 90.1097",
      "\n",
      "[2500]\tvalid_0's l1: 89.853",
      "\n",
      "[2600]\tvalid_0's l1: 89.7201",
      "\n",
      "[2700]\tvalid_0's l1: 89.5584",
      "\n",
      "[2800]\tvalid_0's l1: 89.3057",
      "\n",
      "[2900]\tvalid_0's l1: 89.1094",
      "\n",
      "[3000]\tvalid_0's l1: 88.928",
      "\n",
      "[3100]\tvalid_0's l1: 88.7766",
      "\n",
      "[3200]\tvalid_0's l1: 88.6802",
      "\n",
      "[3300]\tvalid_0's l1: 88.5554",
      "\n",
      "[3400]\tvalid_0's l1: 88.3493",
      "\n",
      "[3500]\tvalid_0's l1: 88.2071",
      "\n",
      "[3600]\tvalid_0's l1: 88.1463",
      "\n",
      "[3700]\tvalid_0's l1: 88.0668",
      "\n",
      "[3800]\tvalid_0's l1: 87.9879",
      "\n",
      "[3900]\tvalid_0's l1: 87.8317",
      "\n",
      "[4000]\tvalid_0's l1: 87.6981",
      "\n",
      "[4100]\tvalid_0's l1: 87.6538",
      "\n",
      "[4200]\tvalid_0's l1: 87.5744",
      "\n",
      "[4300]\tvalid_0's l1: 87.475",
      "\n",
      "[4400]\tvalid_0's l1: 87.3899",
      "\n",
      "[4500]\tvalid_0's l1: 87.3481",
      "\n",
      "[4600]\tvalid_0's l1: 87.2596",
      "\n",
      "[4700]\tvalid_0's l1: 87.1623",
      "\n",
      "[4800]\tvalid_0's l1: 87.1343",
      "\n",
      "[4900]\tvalid_0's l1: 87.0229",
      "\n",
      "[5000]\tvalid_0's l1: 86.9815",
      "\n",
      "[5100]\tvalid_0's l1: 86.9225",
      "\n",
      "[5200]\tvalid_0's l1: 86.8869",
      "\n",
      "[5300]\tvalid_0's l1: 86.8369",
      "\n",
      "[5400]\tvalid_0's l1: 86.8478",
      "\n",
      "Early stopping, best iteration is:\n[5322]\tvalid_0's l1: 86.8181",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 200.235",
      "\n",
      "[200]\tvalid_0's l1: 152.55",
      "\n",
      "[300]\tvalid_0's l1: 135.254",
      "\n",
      "[400]\tvalid_0's l1: 122.491",
      "\n",
      "[500]\tvalid_0's l1: 114.664",
      "\n",
      "[600]\tvalid_0's l1: 109.595",
      "\n",
      "[700]\tvalid_0's l1: 106.687",
      "\n",
      "[800]\tvalid_0's l1: 104.276",
      "\n",
      "[900]\tvalid_0's l1: 101.733",
      "\n",
      "[1000]\tvalid_0's l1: 99.8535",
      "\n",
      "[1100]\tvalid_0's l1: 98.6749",
      "\n",
      "[1200]\tvalid_0's l1: 97.552",
      "\n",
      "[1300]\tvalid_0's l1: 96.5158",
      "\n",
      "[1400]\tvalid_0's l1: 95.9257",
      "\n",
      "[1500]\tvalid_0's l1: 95.298",
      "\n",
      "[1600]\tvalid_0's l1: 94.7047",
      "\n",
      "[1700]\tvalid_0's l1: 94.1338",
      "\n",
      "[1800]\tvalid_0's l1: 93.6883",
      "\n",
      "[1900]\tvalid_0's l1: 93.2522",
      "\n",
      "[2000]\tvalid_0's l1: 92.9489",
      "\n",
      "[2100]\tvalid_0's l1: 92.5809",
      "\n",
      "[2200]\tvalid_0's l1: 92.1646",
      "\n",
      "[2300]\tvalid_0's l1: 91.8245",
      "\n",
      "[2400]\tvalid_0's l1: 91.6526",
      "\n",
      "[2500]\tvalid_0's l1: 91.4305",
      "\n",
      "[2600]\tvalid_0's l1: 91.1751",
      "\n",
      "[2700]\tvalid_0's l1: 90.9021",
      "\n",
      "[2800]\tvalid_0's l1: 90.5863",
      "\n",
      "[2900]\tvalid_0's l1: 90.3819",
      "\n",
      "[3000]\tvalid_0's l1: 90.1922",
      "\n",
      "[3100]\tvalid_0's l1: 89.9902",
      "\n",
      "[3200]\tvalid_0's l1: 89.7326",
      "\n",
      "[3300]\tvalid_0's l1: 89.56",
      "\n",
      "[3400]\tvalid_0's l1: 89.4962",
      "\n",
      "[3500]\tvalid_0's l1: 89.2823",
      "\n",
      "[3600]\tvalid_0's l1: 89.2054",
      "\n",
      "[3700]\tvalid_0's l1: 89.0384",
      "\n",
      "[3800]\tvalid_0's l1: 88.9231",
      "\n",
      "[3900]\tvalid_0's l1: 88.77",
      "\n",
      "[4000]\tvalid_0's l1: 88.6838",
      "\n",
      "[4100]\tvalid_0's l1: 88.5461",
      "\n",
      "[4200]\tvalid_0's l1: 88.45",
      "\n",
      "[4300]\tvalid_0's l1: 88.3275",
      "\n",
      "[4400]\tvalid_0's l1: 88.2035",
      "\n",
      "[4500]\tvalid_0's l1: 88.1248",
      "\n",
      "[4600]\tvalid_0's l1: 88.0551",
      "\n",
      "[4700]\tvalid_0's l1: 88.0091",
      "\n",
      "[4800]\tvalid_0's l1: 87.9383",
      "\n",
      "[4900]\tvalid_0's l1: 87.9105",
      "\n",
      "[5000]\tvalid_0's l1: 87.8679",
      "\n",
      "[5100]\tvalid_0's l1: 87.809",
      "\n",
      "[5200]\tvalid_0's l1: 87.7587",
      "\n",
      "[5300]\tvalid_0's l1: 87.738",
      "\n",
      "[5400]\tvalid_0's l1: 87.6726",
      "\n",
      "[5500]\tvalid_0's l1: 87.6538",
      "\n",
      "[5600]\tvalid_0's l1: 87.6085",
      "\n",
      "[5700]\tvalid_0's l1: 87.5685",
      "\n",
      "[5800]\tvalid_0's l1: 87.551",
      "\n",
      "[5900]\tvalid_0's l1: 87.5111",
      "\n",
      "[6000]\tvalid_0's l1: 87.4574",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[5999]\tvalid_0's l1: 87.4556",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMRegressor(min_data_in_leaf= 30,num_leaves=230,\n",
    "    reg_alpha=0., reg_lambda=0.01, objective='mse', metric='mae',\n",
    "    max_depth=8, learning_rate=0.03, min_child_samples=20,\n",
    "    n_estimators=1000, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,num_iterations=6000\n",
    ")\n",
    "data_lgb, predict_label = get_predict_w(lgb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019, n_splits=5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 192.508",
      "\n",
      "[200]\tvalid_0's l1: 148.641",
      "\n",
      "[300]\tvalid_0's l1: 129.325",
      "\n",
      "[400]\tvalid_0's l1: 116.826",
      "\n",
      "[500]\tvalid_0's l1: 110.223",
      "\n",
      "[600]\tvalid_0's l1: 105.455",
      "\n",
      "[700]\tvalid_0's l1: 101.987",
      "\n",
      "[800]\tvalid_0's l1: 99.3554",
      "\n",
      "[900]\tvalid_0's l1: 97.001",
      "\n",
      "[1000]\tvalid_0's l1: 95.469",
      "\n",
      "[1100]\tvalid_0's l1: 94.2452",
      "\n",
      "[1200]\tvalid_0's l1: 92.9931",
      "\n",
      "[1300]\tvalid_0's l1: 91.9281",
      "\n",
      "[1400]\tvalid_0's l1: 91.3764",
      "\n",
      "[1500]\tvalid_0's l1: 90.5247",
      "\n",
      "[1600]\tvalid_0's l1: 89.9381",
      "\n",
      "[1700]\tvalid_0's l1: 89.4372",
      "\n",
      "[1800]\tvalid_0's l1: 88.8513",
      "\n",
      "[1900]\tvalid_0's l1: 88.4013",
      "\n",
      "[2000]\tvalid_0's l1: 88.0501",
      "\n",
      "[2100]\tvalid_0's l1: 87.5527",
      "\n",
      "[2200]\tvalid_0's l1: 87.1427",
      "\n",
      "[2300]\tvalid_0's l1: 86.8578",
      "\n",
      "[2400]\tvalid_0's l1: 86.5982",
      "\n",
      "[2500]\tvalid_0's l1: 86.3142",
      "\n",
      "[2600]\tvalid_0's l1: 86.0056",
      "\n",
      "[2700]\tvalid_0's l1: 85.7384",
      "\n",
      "[2800]\tvalid_0's l1: 85.5153",
      "\n",
      "[2900]\tvalid_0's l1: 85.1779",
      "\n",
      "[3000]\tvalid_0's l1: 84.9487",
      "\n",
      "[3100]\tvalid_0's l1: 84.7872",
      "\n",
      "[3200]\tvalid_0's l1: 84.6499",
      "\n",
      "[3300]\tvalid_0's l1: 84.5318",
      "\n",
      "[3400]\tvalid_0's l1: 84.4014",
      "\n",
      "[3500]\tvalid_0's l1: 84.2266",
      "\n",
      "[3600]\tvalid_0's l1: 84.1012",
      "\n",
      "[3700]\tvalid_0's l1: 84.0118",
      "\n",
      "[3800]\tvalid_0's l1: 83.9223",
      "\n",
      "[3900]\tvalid_0's l1: 83.8566",
      "\n",
      "[4000]\tvalid_0's l1: 83.7795",
      "\n",
      "[4100]\tvalid_0's l1: 83.7286",
      "\n",
      "[4200]\tvalid_0's l1: 83.6396",
      "\n",
      "[4300]\tvalid_0's l1: 83.5825",
      "\n",
      "[4400]\tvalid_0's l1: 83.5296",
      "\n",
      "[4500]\tvalid_0's l1: 83.4025",
      "\n",
      "[4600]\tvalid_0's l1: 83.3367",
      "\n",
      "[4700]\tvalid_0's l1: 83.2389",
      "\n",
      "[4800]\tvalid_0's l1: 83.1707",
      "\n",
      "[4900]\tvalid_0's l1: 83.1242",
      "\n",
      "[5000]\tvalid_0's l1: 83.031",
      "\n",
      "[5100]\tvalid_0's l1: 82.954",
      "\n",
      "[5200]\tvalid_0's l1: 82.9135",
      "\n",
      "[5300]\tvalid_0's l1: 82.8793",
      "\n",
      "[5400]\tvalid_0's l1: 82.8205",
      "\n",
      "[5500]\tvalid_0's l1: 82.7417",
      "\n",
      "[5600]\tvalid_0's l1: 82.6687",
      "\n",
      "[5700]\tvalid_0's l1: 82.6426",
      "\n",
      "[5800]\tvalid_0's l1: 82.6096",
      "\n",
      "[5900]\tvalid_0's l1: 82.5862",
      "\n",
      "[6000]\tvalid_0's l1: 82.567",
      "\n",
      "[6100]\tvalid_0's l1: 82.5357",
      "\n",
      "[6200]\tvalid_0's l1: 82.4865",
      "\n",
      "[6300]\tvalid_0's l1: 82.4449",
      "\n",
      "[6400]\tvalid_0's l1: 82.3969",
      "\n",
      "[6500]\tvalid_0's l1: 82.3742",
      "\n",
      "[6600]\tvalid_0's l1: 82.3309",
      "\n",
      "[6700]\tvalid_0's l1: 82.2799",
      "\n",
      "[6800]\tvalid_0's l1: 82.2609",
      "\n",
      "Early stopping, best iteration is:\n[6766]\tvalid_0's l1: 82.2534",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 200.598",
      "\n",
      "[200]\tvalid_0's l1: 155.185",
      "\n",
      "[300]\tvalid_0's l1: 131.929",
      "\n",
      "[400]\tvalid_0's l1: 120.797",
      "\n",
      "[500]\tvalid_0's l1: 115.168",
      "\n",
      "[600]\tvalid_0's l1: 109.5",
      "\n",
      "[700]\tvalid_0's l1: 105.91",
      "\n",
      "[800]\tvalid_0's l1: 103.584",
      "\n",
      "[900]\tvalid_0's l1: 101.583",
      "\n",
      "[1000]\tvalid_0's l1: 100.003",
      "\n",
      "[1100]\tvalid_0's l1: 98.632",
      "\n",
      "[1200]\tvalid_0's l1: 97.4043",
      "\n",
      "[1300]\tvalid_0's l1: 96.5225",
      "\n",
      "[1400]\tvalid_0's l1: 95.7009",
      "\n",
      "[1500]\tvalid_0's l1: 95.1735",
      "\n",
      "[1600]\tvalid_0's l1: 94.6187",
      "\n",
      "[1700]\tvalid_0's l1: 94.1719",
      "\n",
      "[1800]\tvalid_0's l1: 93.7648",
      "\n",
      "[1900]\tvalid_0's l1: 93.3409",
      "\n",
      "[2000]\tvalid_0's l1: 93.0031",
      "\n",
      "[2100]\tvalid_0's l1: 92.6348",
      "\n",
      "[2200]\tvalid_0's l1: 92.2757",
      "\n",
      "[2300]\tvalid_0's l1: 92.0194",
      "\n",
      "[2400]\tvalid_0's l1: 91.7067",
      "\n",
      "[2500]\tvalid_0's l1: 91.497",
      "\n",
      "[2600]\tvalid_0's l1: 91.238",
      "\n",
      "[2700]\tvalid_0's l1: 91.0526",
      "\n",
      "[2800]\tvalid_0's l1: 90.8864",
      "\n",
      "[2900]\tvalid_0's l1: 90.7782",
      "\n",
      "[3000]\tvalid_0's l1: 90.5265",
      "\n",
      "[3100]\tvalid_0's l1: 90.4266",
      "\n",
      "[3200]\tvalid_0's l1: 90.2529",
      "\n",
      "[3300]\tvalid_0's l1: 90.1353",
      "\n",
      "[3400]\tvalid_0's l1: 90.0112",
      "\n",
      "[3500]\tvalid_0's l1: 89.8851",
      "\n",
      "[3600]\tvalid_0's l1: 89.7293",
      "\n",
      "[3700]\tvalid_0's l1: 89.6552",
      "\n",
      "[3800]\tvalid_0's l1: 89.5235",
      "\n",
      "[3900]\tvalid_0's l1: 89.4249",
      "\n",
      "[4000]\tvalid_0's l1: 89.3468",
      "\n",
      "[4100]\tvalid_0's l1: 89.279",
      "\n",
      "[4200]\tvalid_0's l1: 89.1882",
      "\n",
      "[4300]\tvalid_0's l1: 89.1428",
      "\n",
      "[4400]\tvalid_0's l1: 89.0844",
      "\n",
      "[4500]\tvalid_0's l1: 89.0378",
      "\n",
      "[4600]\tvalid_0's l1: 88.9174",
      "\n",
      "[4700]\tvalid_0's l1: 88.8794",
      "\n",
      "[4800]\tvalid_0's l1: 88.8267",
      "\n",
      "[4900]\tvalid_0's l1: 88.7758",
      "\n",
      "[5000]\tvalid_0's l1: 88.6391",
      "\n",
      "[5100]\tvalid_0's l1: 88.5844",
      "\n",
      "[5200]\tvalid_0's l1: 88.5332",
      "\n",
      "[5300]\tvalid_0's l1: 88.4277",
      "\n",
      "[5400]\tvalid_0's l1: 88.3941",
      "\n",
      "[5500]\tvalid_0's l1: 88.352",
      "\n",
      "[5600]\tvalid_0's l1: 88.3056",
      "\n",
      "[5700]\tvalid_0's l1: 88.261",
      "\n",
      "[5800]\tvalid_0's l1: 88.2133",
      "\n",
      "[5900]\tvalid_0's l1: 88.1652",
      "\n",
      "[6000]\tvalid_0's l1: 88.1347",
      "\n",
      "[6100]\tvalid_0's l1: 88.0829",
      "\n",
      "[6200]\tvalid_0's l1: 88.0272",
      "\n",
      "[6300]\tvalid_0's l1: 88.0189",
      "\n",
      "[6400]\tvalid_0's l1: 87.9996",
      "\n",
      "[6500]\tvalid_0's l1: 87.9522",
      "\n",
      "[6600]\tvalid_0's l1: 87.9457",
      "\n",
      "[6700]\tvalid_0's l1: 87.9384",
      "\n",
      "[6800]\tvalid_0's l1: 87.9474",
      "\n",
      "Early stopping, best iteration is:\n[6719]\tvalid_0's l1: 87.9298",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 207.271",
      "\n",
      "[200]\tvalid_0's l1: 157.67",
      "\n",
      "[300]\tvalid_0's l1: 137.121",
      "\n",
      "[400]\tvalid_0's l1: 124.508",
      "\n",
      "[500]\tvalid_0's l1: 116.641",
      "\n",
      "[600]\tvalid_0's l1: 110.851",
      "\n",
      "[700]\tvalid_0's l1: 107.121",
      "\n",
      "[800]\tvalid_0's l1: 104.419",
      "\n",
      "[900]\tvalid_0's l1: 102.164",
      "\n",
      "[1000]\tvalid_0's l1: 100.758",
      "\n",
      "[1100]\tvalid_0's l1: 99.2508",
      "\n",
      "[1200]\tvalid_0's l1: 97.6097",
      "\n",
      "[1300]\tvalid_0's l1: 96.76",
      "\n",
      "[1400]\tvalid_0's l1: 96.0438",
      "\n",
      "[1500]\tvalid_0's l1: 95.3006",
      "\n",
      "[1600]\tvalid_0's l1: 94.5466",
      "\n",
      "[1700]\tvalid_0's l1: 94.0505",
      "\n",
      "[1800]\tvalid_0's l1: 93.6144",
      "\n",
      "[1900]\tvalid_0's l1: 93.1843",
      "\n",
      "[2000]\tvalid_0's l1: 92.7478",
      "\n",
      "[2100]\tvalid_0's l1: 92.4273",
      "\n",
      "[2200]\tvalid_0's l1: 92.0591",
      "\n",
      "[2300]\tvalid_0's l1: 91.8209",
      "\n",
      "[2400]\tvalid_0's l1: 91.5852",
      "\n",
      "[2500]\tvalid_0's l1: 91.3513",
      "\n",
      "[2600]\tvalid_0's l1: 91.0506",
      "\n",
      "[2700]\tvalid_0's l1: 90.9125",
      "\n",
      "[2800]\tvalid_0's l1: 90.6457",
      "\n",
      "[2900]\tvalid_0's l1: 90.5055",
      "\n",
      "[3000]\tvalid_0's l1: 90.3524",
      "\n",
      "[3100]\tvalid_0's l1: 90.2157",
      "\n",
      "[3200]\tvalid_0's l1: 90.0485",
      "\n",
      "[3300]\tvalid_0's l1: 89.8332",
      "\n",
      "[3400]\tvalid_0's l1: 89.7306",
      "\n",
      "[3500]\tvalid_0's l1: 89.6715",
      "\n",
      "[3600]\tvalid_0's l1: 89.6055",
      "\n",
      "[3700]\tvalid_0's l1: 89.4885",
      "\n",
      "[3800]\tvalid_0's l1: 89.405",
      "\n",
      "[3900]\tvalid_0's l1: 89.2767",
      "\n",
      "[4000]\tvalid_0's l1: 89.1623",
      "\n",
      "[4100]\tvalid_0's l1: 89.1136",
      "\n",
      "[4200]\tvalid_0's l1: 89.0221",
      "\n",
      "[4300]\tvalid_0's l1: 88.968",
      "\n",
      "[4400]\tvalid_0's l1: 88.8642",
      "\n",
      "[4500]\tvalid_0's l1: 88.7962",
      "\n",
      "[4600]\tvalid_0's l1: 88.7397",
      "\n",
      "[4700]\tvalid_0's l1: 88.6878",
      "\n",
      "[4800]\tvalid_0's l1: 88.5835",
      "\n",
      "[4900]\tvalid_0's l1: 88.5028",
      "\n",
      "[5000]\tvalid_0's l1: 88.4322",
      "\n",
      "[5100]\tvalid_0's l1: 88.38",
      "\n",
      "[5200]\tvalid_0's l1: 88.2989",
      "\n",
      "[5300]\tvalid_0's l1: 88.2174",
      "\n",
      "[5400]\tvalid_0's l1: 88.2363",
      "\n",
      "Early stopping, best iteration is:\n[5305]\tvalid_0's l1: 88.213",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 186.007",
      "\n",
      "[200]\tvalid_0's l1: 150.611",
      "\n",
      "[300]\tvalid_0's l1: 130.244",
      "\n",
      "[400]\tvalid_0's l1: 118.922",
      "\n",
      "[500]\tvalid_0's l1: 111.204",
      "\n",
      "[600]\tvalid_0's l1: 106.892",
      "\n",
      "[700]\tvalid_0's l1: 103.358",
      "\n",
      "[800]\tvalid_0's l1: 100.812",
      "\n",
      "[900]\tvalid_0's l1: 99.2065",
      "\n",
      "[1000]\tvalid_0's l1: 97.8577",
      "\n",
      "[1100]\tvalid_0's l1: 96.6892",
      "\n",
      "[1200]\tvalid_0's l1: 95.8774",
      "\n",
      "[1300]\tvalid_0's l1: 95.0695",
      "\n",
      "[1400]\tvalid_0's l1: 94.322",
      "\n",
      "[1500]\tvalid_0's l1: 93.5806",
      "\n",
      "[1600]\tvalid_0's l1: 93.0702",
      "\n",
      "[1700]\tvalid_0's l1: 92.6065",
      "\n",
      "[1800]\tvalid_0's l1: 92.2007",
      "\n",
      "[1900]\tvalid_0's l1: 91.6736",
      "\n",
      "[2000]\tvalid_0's l1: 91.3442",
      "\n",
      "[2100]\tvalid_0's l1: 91.0252",
      "\n",
      "[2200]\tvalid_0's l1: 90.6793",
      "\n",
      "[2300]\tvalid_0's l1: 90.3597",
      "\n",
      "[2400]\tvalid_0's l1: 90.1097",
      "\n",
      "[2500]\tvalid_0's l1: 89.853",
      "\n",
      "[2600]\tvalid_0's l1: 89.7201",
      "\n",
      "[2700]\tvalid_0's l1: 89.5584",
      "\n",
      "[2800]\tvalid_0's l1: 89.3057",
      "\n",
      "[2900]\tvalid_0's l1: 89.1094",
      "\n",
      "[3000]\tvalid_0's l1: 88.928",
      "\n",
      "[3100]\tvalid_0's l1: 88.7766",
      "\n",
      "[3200]\tvalid_0's l1: 88.6802",
      "\n",
      "[3300]\tvalid_0's l1: 88.5554",
      "\n",
      "[3400]\tvalid_0's l1: 88.3493",
      "\n",
      "[3500]\tvalid_0's l1: 88.2071",
      "\n",
      "[3600]\tvalid_0's l1: 88.1463",
      "\n",
      "[3700]\tvalid_0's l1: 88.0668",
      "\n",
      "[3800]\tvalid_0's l1: 87.9879",
      "\n",
      "[3900]\tvalid_0's l1: 87.8317",
      "\n",
      "[4000]\tvalid_0's l1: 87.6981",
      "\n",
      "[4100]\tvalid_0's l1: 87.6538",
      "\n",
      "[4200]\tvalid_0's l1: 87.5744",
      "\n",
      "[4300]\tvalid_0's l1: 87.475",
      "\n",
      "[4400]\tvalid_0's l1: 87.3899",
      "\n",
      "[4500]\tvalid_0's l1: 87.3481",
      "\n",
      "[4600]\tvalid_0's l1: 87.2596",
      "\n",
      "[4700]\tvalid_0's l1: 87.1623",
      "\n",
      "[4800]\tvalid_0's l1: 87.1343",
      "\n",
      "[4900]\tvalid_0's l1: 87.0229",
      "\n",
      "[5000]\tvalid_0's l1: 86.9815",
      "\n",
      "[5100]\tvalid_0's l1: 86.9225",
      "\n",
      "[5200]\tvalid_0's l1: 86.8869",
      "\n",
      "[5300]\tvalid_0's l1: 86.8369",
      "\n",
      "[5400]\tvalid_0's l1: 86.8478",
      "\n",
      "Early stopping, best iteration is:\n[5322]\tvalid_0's l1: 86.8181",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 200.235",
      "\n",
      "[200]\tvalid_0's l1: 152.55",
      "\n",
      "[300]\tvalid_0's l1: 135.254",
      "\n",
      "[400]\tvalid_0's l1: 122.491",
      "\n",
      "[500]\tvalid_0's l1: 114.664",
      "\n",
      "[600]\tvalid_0's l1: 109.595",
      "\n",
      "[700]\tvalid_0's l1: 106.687",
      "\n",
      "[800]\tvalid_0's l1: 104.276",
      "\n",
      "[900]\tvalid_0's l1: 101.733",
      "\n",
      "[1000]\tvalid_0's l1: 99.8535",
      "\n",
      "[1100]\tvalid_0's l1: 98.6749",
      "\n",
      "[1200]\tvalid_0's l1: 97.552",
      "\n",
      "[1300]\tvalid_0's l1: 96.5158",
      "\n",
      "[1400]\tvalid_0's l1: 95.9257",
      "\n",
      "[1500]\tvalid_0's l1: 95.298",
      "\n",
      "[1600]\tvalid_0's l1: 94.7047",
      "\n",
      "[1700]\tvalid_0's l1: 94.1338",
      "\n",
      "[1800]\tvalid_0's l1: 93.6883",
      "\n",
      "[1900]\tvalid_0's l1: 93.2522",
      "\n",
      "[2000]\tvalid_0's l1: 92.9489",
      "\n",
      "[2100]\tvalid_0's l1: 92.5809",
      "\n",
      "[2200]\tvalid_0's l1: 92.1646",
      "\n",
      "[2300]\tvalid_0's l1: 91.8245",
      "\n",
      "[2400]\tvalid_0's l1: 91.6526",
      "\n",
      "[2500]\tvalid_0's l1: 91.4305",
      "\n",
      "[2600]\tvalid_0's l1: 91.1751",
      "\n",
      "[2700]\tvalid_0's l1: 90.9021",
      "\n",
      "[2800]\tvalid_0's l1: 90.5863",
      "\n",
      "[2900]\tvalid_0's l1: 90.3819",
      "\n",
      "[3000]\tvalid_0's l1: 90.1922",
      "\n",
      "[3100]\tvalid_0's l1: 89.9902",
      "\n",
      "[3200]\tvalid_0's l1: 89.7326",
      "\n",
      "[3300]\tvalid_0's l1: 89.56",
      "\n",
      "[3400]\tvalid_0's l1: 89.4962",
      "\n",
      "[3500]\tvalid_0's l1: 89.2823",
      "\n",
      "[3600]\tvalid_0's l1: 89.2054",
      "\n",
      "[3700]\tvalid_0's l1: 89.0384",
      "\n",
      "[3800]\tvalid_0's l1: 88.9231",
      "\n",
      "[3900]\tvalid_0's l1: 88.77",
      "\n",
      "[4000]\tvalid_0's l1: 88.6838",
      "\n",
      "[4100]\tvalid_0's l1: 88.5461",
      "\n",
      "[4200]\tvalid_0's l1: 88.45",
      "\n",
      "[4300]\tvalid_0's l1: 88.3275",
      "\n",
      "[4400]\tvalid_0's l1: 88.2035",
      "\n",
      "[4500]\tvalid_0's l1: 88.1248",
      "\n",
      "[4600]\tvalid_0's l1: 88.0551",
      "\n",
      "[4700]\tvalid_0's l1: 88.0091",
      "\n",
      "[4800]\tvalid_0's l1: 87.9383",
      "\n",
      "[4900]\tvalid_0's l1: 87.9105",
      "\n",
      "[5000]\tvalid_0's l1: 87.8679",
      "\n",
      "[5100]\tvalid_0's l1: 87.809",
      "\n",
      "[5200]\tvalid_0's l1: 87.7587",
      "\n",
      "[5300]\tvalid_0's l1: 87.738",
      "\n",
      "[5400]\tvalid_0's l1: 87.6726",
      "\n",
      "[5500]\tvalid_0's l1: 87.6538",
      "\n",
      "[5600]\tvalid_0's l1: 87.6085",
      "\n",
      "[5700]\tvalid_0's l1: 87.5685",
      "\n",
      "[5800]\tvalid_0's l1: 87.551",
      "\n",
      "[5900]\tvalid_0's l1: 87.5111",
      "\n",
      "[6000]\tvalid_0's l1: 87.4574",
      "\n",
      "[6100]\tvalid_0's l1: 87.4535",
      "\n",
      "[6200]\tvalid_0's l1: 87.4335",
      "\n",
      "[6300]\tvalid_0's l1: 87.3965",
      "\n",
      "[6400]\tvalid_0's l1: 87.3777",
      "\n",
      "[6500]\tvalid_0's l1: 87.3575",
      "\n",
      "[6600]\tvalid_0's l1: 87.2979",
      "\n",
      "Early stopping, best iteration is:\n[6597]\tvalid_0's l1: 87.2962",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#最优\n",
    "lgb_model = lgb.LGBMRegressor(min_data_in_leaf= 30,num_leaves=230,\n",
    "    reg_alpha=0., reg_lambda=0.01, objective='mse', metric='mae',\n",
    "    max_depth=8, learning_rate=0.03, min_child_samples=20,\n",
    "    n_estimators=1000, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,num_iterations=8000\n",
    ")\n",
    "data_lgb, predict_label = get_predict_w(lgb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019, n_splits=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "data_lgb.to_csv(\"lgb_302300038000.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 289.58",
      "\n",
      "[200]\tvalid_0's l1: 218.663",
      "\n",
      "[300]\tvalid_0's l1: 187.054",
      "\n",
      "[400]\tvalid_0's l1: 167.299",
      "\n",
      "[500]\tvalid_0's l1: 155.817",
      "\n",
      "[600]\tvalid_0's l1: 146.332",
      "\n",
      "[700]\tvalid_0's l1: 139.155",
      "\n",
      "[800]\tvalid_0's l1: 132.694",
      "\n",
      "[900]\tvalid_0's l1: 126.263",
      "\n",
      "[1000]\tvalid_0's l1: 121.853",
      "\n",
      "[1100]\tvalid_0's l1: 118.227",
      "\n",
      "[1200]\tvalid_0's l1: 114.218",
      "\n",
      "[1300]\tvalid_0's l1: 111.035",
      "\n",
      "[1400]\tvalid_0's l1: 109.149",
      "\n",
      "[1500]\tvalid_0's l1: 106.61",
      "\n",
      "[1600]\tvalid_0's l1: 104.938",
      "\n",
      "[1700]\tvalid_0's l1: 103.276",
      "\n",
      "[1800]\tvalid_0's l1: 101.73",
      "\n",
      "[1900]\tvalid_0's l1: 100.413",
      "\n",
      "[2000]\tvalid_0's l1: 99.2943",
      "\n",
      "[2100]\tvalid_0's l1: 98.1729",
      "\n",
      "[2200]\tvalid_0's l1: 97.1806",
      "\n",
      "[2300]\tvalid_0's l1: 96.4091",
      "\n",
      "[2400]\tvalid_0's l1: 95.7046",
      "\n",
      "[2500]\tvalid_0's l1: 94.9208",
      "\n",
      "[2600]\tvalid_0's l1: 94.2496",
      "\n",
      "[2700]\tvalid_0's l1: 93.5496",
      "\n",
      "[2800]\tvalid_0's l1: 92.9653",
      "\n",
      "[2900]\tvalid_0's l1: 92.3164",
      "\n",
      "[3000]\tvalid_0's l1: 91.7224",
      "\n",
      "[3100]\tvalid_0's l1: 91.2736",
      "\n",
      "[3200]\tvalid_0's l1: 90.8463",
      "\n",
      "[3300]\tvalid_0's l1: 90.46",
      "\n",
      "[3400]\tvalid_0's l1: 90.0925",
      "\n",
      "[3500]\tvalid_0's l1: 89.8058",
      "\n",
      "[3600]\tvalid_0's l1: 89.3826",
      "\n",
      "[3700]\tvalid_0's l1: 89.0616",
      "\n",
      "[3800]\tvalid_0's l1: 88.759",
      "\n",
      "[3900]\tvalid_0's l1: 88.5127",
      "\n",
      "[4000]\tvalid_0's l1: 88.2506",
      "\n",
      "[4100]\tvalid_0's l1: 88.0019",
      "\n",
      "[4200]\tvalid_0's l1: 87.7224",
      "\n",
      "[4300]\tvalid_0's l1: 87.5322",
      "\n",
      "[4400]\tvalid_0's l1: 87.3357",
      "\n",
      "[4500]\tvalid_0's l1: 87.1743",
      "\n",
      "[4600]\tvalid_0's l1: 87.0295",
      "\n",
      "[4700]\tvalid_0's l1: 86.7997",
      "\n",
      "[4800]\tvalid_0's l1: 86.5733",
      "\n",
      "[4900]\tvalid_0's l1: 86.4363",
      "\n",
      "[5000]\tvalid_0's l1: 86.2462",
      "\n",
      "[5100]\tvalid_0's l1: 86.0656",
      "\n",
      "[5200]\tvalid_0's l1: 85.888",
      "\n",
      "[5300]\tvalid_0's l1: 85.7294",
      "\n",
      "[5400]\tvalid_0's l1: 85.5752",
      "\n",
      "[5500]\tvalid_0's l1: 85.4393",
      "\n",
      "[5600]\tvalid_0's l1: 85.3236",
      "\n",
      "[5700]\tvalid_0's l1: 85.2044",
      "\n",
      "[5800]\tvalid_0's l1: 85.0559",
      "\n",
      "[5900]\tvalid_0's l1: 84.9316",
      "\n",
      "[6000]\tvalid_0's l1: 84.8471",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[5998]\tvalid_0's l1: 84.8455",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 300.921",
      "\n",
      "[200]\tvalid_0's l1: 227.338",
      "\n",
      "[300]\tvalid_0's l1: 191.742",
      "\n",
      "[400]\tvalid_0's l1: 172.218",
      "\n",
      "[500]\tvalid_0's l1: 160.965",
      "\n",
      "[600]\tvalid_0's l1: 149.417",
      "\n",
      "[700]\tvalid_0's l1: 139.77",
      "\n",
      "[800]\tvalid_0's l1: 133.288",
      "\n",
      "[900]\tvalid_0's l1: 127.925",
      "\n",
      "[1000]\tvalid_0's l1: 123.351",
      "\n",
      "[1100]\tvalid_0's l1: 119.359",
      "\n",
      "[1200]\tvalid_0's l1: 116.068",
      "\n",
      "[1300]\tvalid_0's l1: 113.328",
      "\n",
      "[1400]\tvalid_0's l1: 111.316",
      "\n",
      "[1500]\tvalid_0's l1: 109.715",
      "\n",
      "[1600]\tvalid_0's l1: 107.991",
      "\n",
      "[1700]\tvalid_0's l1: 106.592",
      "\n",
      "[1800]\tvalid_0's l1: 105.339",
      "\n",
      "[1900]\tvalid_0's l1: 104.245",
      "\n",
      "[2000]\tvalid_0's l1: 103.286",
      "\n",
      "[2100]\tvalid_0's l1: 102.394",
      "\n",
      "[2200]\tvalid_0's l1: 101.386",
      "\n",
      "[2300]\tvalid_0's l1: 100.577",
      "\n",
      "[2400]\tvalid_0's l1: 99.7896",
      "\n",
      "[2500]\tvalid_0's l1: 99.1365",
      "\n",
      "[2600]\tvalid_0's l1: 98.5931",
      "\n",
      "[2700]\tvalid_0's l1: 98.0443",
      "\n",
      "[2800]\tvalid_0's l1: 97.5628",
      "\n",
      "[2900]\tvalid_0's l1: 97.0787",
      "\n",
      "[3000]\tvalid_0's l1: 96.4778",
      "\n",
      "[3100]\tvalid_0's l1: 96.0712",
      "\n",
      "[3200]\tvalid_0's l1: 95.6874",
      "\n",
      "[3300]\tvalid_0's l1: 95.3015",
      "\n",
      "[3400]\tvalid_0's l1: 94.9634",
      "\n",
      "[3500]\tvalid_0's l1: 94.6489",
      "\n",
      "[3600]\tvalid_0's l1: 94.3281",
      "\n",
      "[3700]\tvalid_0's l1: 94.0566",
      "\n",
      "[3800]\tvalid_0's l1: 93.7397",
      "\n",
      "[3900]\tvalid_0's l1: 93.515",
      "\n",
      "[4000]\tvalid_0's l1: 93.2201",
      "\n",
      "[4100]\tvalid_0's l1: 92.9601",
      "\n",
      "[4200]\tvalid_0's l1: 92.7193",
      "\n",
      "[4300]\tvalid_0's l1: 92.5363",
      "\n",
      "[4400]\tvalid_0's l1: 92.314",
      "\n",
      "[4500]\tvalid_0's l1: 92.0931",
      "\n",
      "[4600]\tvalid_0's l1: 91.8812",
      "\n",
      "[4700]\tvalid_0's l1: 91.6988",
      "\n",
      "[4800]\tvalid_0's l1: 91.5406",
      "\n",
      "[4900]\tvalid_0's l1: 91.3802",
      "\n",
      "[5000]\tvalid_0's l1: 91.1741",
      "\n",
      "[5100]\tvalid_0's l1: 90.9968",
      "\n",
      "[5200]\tvalid_0's l1: 90.847",
      "\n",
      "[5300]\tvalid_0's l1: 90.694",
      "\n",
      "[5400]\tvalid_0's l1: 90.5594",
      "\n",
      "[5500]\tvalid_0's l1: 90.4229",
      "\n",
      "[5600]\tvalid_0's l1: 90.2798",
      "\n",
      "[5700]\tvalid_0's l1: 90.1319",
      "\n",
      "[5800]\tvalid_0's l1: 90.0466",
      "\n",
      "[5900]\tvalid_0's l1: 89.9105",
      "\n",
      "[6000]\tvalid_0's l1: 89.7672",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[5999]\tvalid_0's l1: 89.7665",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 309.912",
      "\n",
      "[200]\tvalid_0's l1: 235.771",
      "\n",
      "[300]\tvalid_0's l1: 201.834",
      "\n",
      "[400]\tvalid_0's l1: 180.491",
      "\n",
      "[500]\tvalid_0's l1: 166.317",
      "\n",
      "[600]\tvalid_0's l1: 153.992",
      "\n",
      "[700]\tvalid_0's l1: 144.637",
      "\n",
      "[800]\tvalid_0's l1: 138.114",
      "\n",
      "[900]\tvalid_0's l1: 132.156",
      "\n",
      "[1000]\tvalid_0's l1: 127.999",
      "\n",
      "[1100]\tvalid_0's l1: 123.648",
      "\n",
      "[1200]\tvalid_0's l1: 119.446",
      "\n",
      "[1300]\tvalid_0's l1: 116.669",
      "\n",
      "[1400]\tvalid_0's l1: 114.463",
      "\n",
      "[1500]\tvalid_0's l1: 112.055",
      "\n",
      "[1600]\tvalid_0's l1: 110.079",
      "\n",
      "[1700]\tvalid_0's l1: 108.374",
      "\n",
      "[1800]\tvalid_0's l1: 106.919",
      "\n",
      "[1900]\tvalid_0's l1: 105.709",
      "\n",
      "[2000]\tvalid_0's l1: 104.379",
      "\n",
      "[2100]\tvalid_0's l1: 103.436",
      "\n",
      "[2200]\tvalid_0's l1: 102.56",
      "\n",
      "[2300]\tvalid_0's l1: 101.706",
      "\n",
      "[2400]\tvalid_0's l1: 101.052",
      "\n",
      "[2500]\tvalid_0's l1: 100.466",
      "\n",
      "[2600]\tvalid_0's l1: 99.6903",
      "\n",
      "[2700]\tvalid_0's l1: 99.0702",
      "\n",
      "[2800]\tvalid_0's l1: 98.3964",
      "\n",
      "[2900]\tvalid_0's l1: 97.9513",
      "\n",
      "[3000]\tvalid_0's l1: 97.5113",
      "\n",
      "[3100]\tvalid_0's l1: 97.0842",
      "\n",
      "[3200]\tvalid_0's l1: 96.6699",
      "\n",
      "[3300]\tvalid_0's l1: 96.3148",
      "\n",
      "[3400]\tvalid_0's l1: 95.9706",
      "\n",
      "[3500]\tvalid_0's l1: 95.6636",
      "\n",
      "[3600]\tvalid_0's l1: 95.3863",
      "\n",
      "[3700]\tvalid_0's l1: 95.0201",
      "\n",
      "[3800]\tvalid_0's l1: 94.7447",
      "\n",
      "[3900]\tvalid_0's l1: 94.4411",
      "\n",
      "[4000]\tvalid_0's l1: 94.1661",
      "\n",
      "[4100]\tvalid_0's l1: 93.8864",
      "\n",
      "[4200]\tvalid_0's l1: 93.6154",
      "\n",
      "[4300]\tvalid_0's l1: 93.4291",
      "\n",
      "[4400]\tvalid_0's l1: 93.1959",
      "\n",
      "[4500]\tvalid_0's l1: 92.9315",
      "\n",
      "[4600]\tvalid_0's l1: 92.7633",
      "\n",
      "[4700]\tvalid_0's l1: 92.5663",
      "\n",
      "[4800]\tvalid_0's l1: 92.3416",
      "\n",
      "[4900]\tvalid_0's l1: 92.1449",
      "\n",
      "[5000]\tvalid_0's l1: 91.9346",
      "\n",
      "[5100]\tvalid_0's l1: 91.7643",
      "\n",
      "[5200]\tvalid_0's l1: 91.6065",
      "\n",
      "[5300]\tvalid_0's l1: 91.4898",
      "\n",
      "[5400]\tvalid_0's l1: 91.3471",
      "\n",
      "[5500]\tvalid_0's l1: 91.2192",
      "\n",
      "[5600]\tvalid_0's l1: 91.1278",
      "\n",
      "[5700]\tvalid_0's l1: 91.0038",
      "\n",
      "[5800]\tvalid_0's l1: 90.891",
      "\n",
      "[5900]\tvalid_0's l1: 90.7969",
      "\n",
      "[6000]\tvalid_0's l1: 90.6557",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[6000]\tvalid_0's l1: 90.6557",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 282.34",
      "\n",
      "[200]\tvalid_0's l1: 218.767",
      "\n",
      "[300]\tvalid_0's l1: 185.504",
      "\n",
      "[400]\tvalid_0's l1: 167.509",
      "\n",
      "[500]\tvalid_0's l1: 153.673",
      "\n",
      "[600]\tvalid_0's l1: 144.127",
      "\n",
      "[700]\tvalid_0's l1: 136.147",
      "\n",
      "[800]\tvalid_0's l1: 129.702",
      "\n",
      "[900]\tvalid_0's l1: 124.699",
      "\n",
      "[1000]\tvalid_0's l1: 121.016",
      "\n",
      "[1100]\tvalid_0's l1: 117.47",
      "\n",
      "[1200]\tvalid_0's l1: 114.829",
      "\n",
      "[1300]\tvalid_0's l1: 112.477",
      "\n",
      "[1400]\tvalid_0's l1: 110.345",
      "\n",
      "[1500]\tvalid_0's l1: 108.589",
      "\n",
      "[1600]\tvalid_0's l1: 106.872",
      "\n",
      "[1700]\tvalid_0's l1: 105.458",
      "\n",
      "[1800]\tvalid_0's l1: 104.219",
      "\n",
      "[1900]\tvalid_0's l1: 102.849",
      "\n",
      "[2000]\tvalid_0's l1: 101.73",
      "\n",
      "[2100]\tvalid_0's l1: 100.793",
      "\n",
      "[2200]\tvalid_0's l1: 100.007",
      "\n",
      "[2300]\tvalid_0's l1: 99.2106",
      "\n",
      "[2400]\tvalid_0's l1: 98.4836",
      "\n",
      "[2500]\tvalid_0's l1: 97.807",
      "\n",
      "[2600]\tvalid_0's l1: 97.266",
      "\n",
      "[2700]\tvalid_0's l1: 96.7421",
      "\n",
      "[2800]\tvalid_0's l1: 96.2274",
      "\n",
      "[2900]\tvalid_0's l1: 95.6938",
      "\n",
      "[3000]\tvalid_0's l1: 95.2577",
      "\n",
      "[3100]\tvalid_0's l1: 94.8015",
      "\n",
      "[3200]\tvalid_0's l1: 94.374",
      "\n",
      "[3300]\tvalid_0's l1: 94.0462",
      "\n",
      "[3400]\tvalid_0's l1: 93.5984",
      "\n",
      "[3500]\tvalid_0's l1: 93.3207",
      "\n",
      "[3600]\tvalid_0's l1: 93.0753",
      "\n",
      "[3700]\tvalid_0's l1: 92.8225",
      "\n",
      "[3800]\tvalid_0's l1: 92.559",
      "\n",
      "[3900]\tvalid_0's l1: 92.2977",
      "\n",
      "[4000]\tvalid_0's l1: 92.0227",
      "\n",
      "[4100]\tvalid_0's l1: 91.7983",
      "\n",
      "[4200]\tvalid_0's l1: 91.5993",
      "\n",
      "[4300]\tvalid_0's l1: 91.4012",
      "\n",
      "[4400]\tvalid_0's l1: 91.1759",
      "\n",
      "[4500]\tvalid_0's l1: 91.0178",
      "\n",
      "[4600]\tvalid_0's l1: 90.8375",
      "\n",
      "[4700]\tvalid_0's l1: 90.6624",
      "\n",
      "[4800]\tvalid_0's l1: 90.5182",
      "\n",
      "[4900]\tvalid_0's l1: 90.3342",
      "\n",
      "[5000]\tvalid_0's l1: 90.1988",
      "\n",
      "[5100]\tvalid_0's l1: 90.1029",
      "\n",
      "[5200]\tvalid_0's l1: 89.9419",
      "\n",
      "[5300]\tvalid_0's l1: 89.7907",
      "\n",
      "[5400]\tvalid_0's l1: 89.6782",
      "\n",
      "[5500]\tvalid_0's l1: 89.5344",
      "\n",
      "[5600]\tvalid_0's l1: 89.4163",
      "\n",
      "[5700]\tvalid_0's l1: 89.3063",
      "\n",
      "[5800]\tvalid_0's l1: 89.1567",
      "\n",
      "[5900]\tvalid_0's l1: 89.0279",
      "\n",
      "[6000]\tvalid_0's l1: 88.8972",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[6000]\tvalid_0's l1: 88.8972",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 302.754",
      "\n",
      "[200]\tvalid_0's l1: 226.863",
      "\n",
      "[300]\tvalid_0's l1: 193.861",
      "\n",
      "[400]\tvalid_0's l1: 173.532",
      "\n",
      "[500]\tvalid_0's l1: 159.314",
      "\n",
      "[600]\tvalid_0's l1: 148.605",
      "\n",
      "[700]\tvalid_0's l1: 142.152",
      "\n",
      "[800]\tvalid_0's l1: 135.701",
      "\n",
      "[900]\tvalid_0's l1: 129.691",
      "\n",
      "[1000]\tvalid_0's l1: 125.004",
      "\n",
      "[1100]\tvalid_0's l1: 121.439",
      "\n",
      "[1200]\tvalid_0's l1: 118.201",
      "\n",
      "[1300]\tvalid_0's l1: 115.286",
      "\n",
      "[1400]\tvalid_0's l1: 113.355",
      "\n",
      "[1500]\tvalid_0's l1: 111.416",
      "\n",
      "[1600]\tvalid_0's l1: 109.842",
      "\n",
      "[1700]\tvalid_0's l1: 108.176",
      "\n",
      "[1800]\tvalid_0's l1: 106.92",
      "\n",
      "[1900]\tvalid_0's l1: 105.53",
      "\n",
      "[2000]\tvalid_0's l1: 104.56",
      "\n",
      "[2100]\tvalid_0's l1: 103.446",
      "\n",
      "[2200]\tvalid_0's l1: 102.392",
      "\n",
      "[2300]\tvalid_0's l1: 101.361",
      "\n",
      "[2400]\tvalid_0's l1: 100.839",
      "\n",
      "[2500]\tvalid_0's l1: 100.234",
      "\n",
      "[2600]\tvalid_0's l1: 99.4606",
      "\n",
      "[2700]\tvalid_0's l1: 98.8368",
      "\n",
      "[2800]\tvalid_0's l1: 98.0949",
      "\n",
      "[2900]\tvalid_0's l1: 97.5603",
      "\n",
      "[3000]\tvalid_0's l1: 97.0936",
      "\n",
      "[3100]\tvalid_0's l1: 96.7108",
      "\n",
      "[3200]\tvalid_0's l1: 96.1581",
      "\n",
      "[3300]\tvalid_0's l1: 95.7199",
      "\n",
      "[3400]\tvalid_0's l1: 95.4136",
      "\n",
      "[3500]\tvalid_0's l1: 95.0083",
      "\n",
      "[3600]\tvalid_0's l1: 94.6912",
      "\n",
      "[3700]\tvalid_0's l1: 94.4204",
      "\n",
      "[3800]\tvalid_0's l1: 94.1482",
      "\n",
      "[3900]\tvalid_0's l1: 93.8628",
      "\n",
      "[4000]\tvalid_0's l1: 93.5798",
      "\n",
      "[4100]\tvalid_0's l1: 93.3235",
      "\n",
      "[4200]\tvalid_0's l1: 93.0781",
      "\n",
      "[4300]\tvalid_0's l1: 92.7824",
      "\n",
      "[4400]\tvalid_0's l1: 92.5164",
      "\n",
      "[4500]\tvalid_0's l1: 92.3228",
      "\n",
      "[4600]\tvalid_0's l1: 92.1153",
      "\n",
      "[4700]\tvalid_0's l1: 91.9169",
      "\n",
      "[4800]\tvalid_0's l1: 91.7403",
      "\n",
      "[4900]\tvalid_0's l1: 91.5779",
      "\n",
      "[5000]\tvalid_0's l1: 91.4497",
      "\n",
      "[5100]\tvalid_0's l1: 91.3104",
      "\n",
      "[5200]\tvalid_0's l1: 91.103",
      "\n",
      "[5300]\tvalid_0's l1: 90.9745",
      "\n",
      "[5400]\tvalid_0's l1: 90.8277",
      "\n",
      "[5500]\tvalid_0's l1: 90.7068",
      "\n",
      "[5600]\tvalid_0's l1: 90.5842",
      "\n",
      "[5700]\tvalid_0's l1: 90.4496",
      "\n",
      "[5800]\tvalid_0's l1: 90.3343",
      "\n",
      "[5900]\tvalid_0's l1: 90.2147",
      "\n",
      "[6000]\tvalid_0's l1: 90.0856",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[5997]\tvalid_0's l1: 90.0843",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMRegressor(learning_rate=0.01,max_depth=8,min_data_in_leaf= 20,num_leaves=170,\n",
    "    reg_alpha=0., reg_lambda=0.01, objective='mse', metric='mae',\n",
    "      min_child_samples=20,\n",
    "    n_estimators=1000, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,num_iterations=6000\n",
    ")\n",
    "data_lgb, predict_label = get_predict_w(lgb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019, n_splits=5)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 289.58",
      "\n",
      "[200]\tvalid_0's l1: 218.663",
      "\n",
      "[300]\tvalid_0's l1: 187.054",
      "\n",
      "[400]\tvalid_0's l1: 167.299",
      "\n",
      "[500]\tvalid_0's l1: 155.817",
      "\n",
      "[600]\tvalid_0's l1: 146.332",
      "\n",
      "[700]\tvalid_0's l1: 139.155",
      "\n",
      "[800]\tvalid_0's l1: 132.694",
      "\n",
      "[900]\tvalid_0's l1: 126.263",
      "\n",
      "[1000]\tvalid_0's l1: 121.853",
      "\n",
      "[1100]\tvalid_0's l1: 118.227",
      "\n",
      "[1200]\tvalid_0's l1: 114.218",
      "\n",
      "[1300]\tvalid_0's l1: 111.035",
      "\n",
      "[1400]\tvalid_0's l1: 109.149",
      "\n",
      "[1500]\tvalid_0's l1: 106.61",
      "\n",
      "[1600]\tvalid_0's l1: 104.938",
      "\n",
      "[1700]\tvalid_0's l1: 103.276",
      "\n",
      "[1800]\tvalid_0's l1: 101.73",
      "\n",
      "[1900]\tvalid_0's l1: 100.413",
      "\n",
      "[2000]\tvalid_0's l1: 99.2943",
      "\n",
      "[2100]\tvalid_0's l1: 98.1729",
      "\n",
      "[2200]\tvalid_0's l1: 97.1806",
      "\n",
      "[2300]\tvalid_0's l1: 96.4091",
      "\n",
      "[2400]\tvalid_0's l1: 95.7046",
      "\n",
      "[2500]\tvalid_0's l1: 94.9208",
      "\n",
      "[2600]\tvalid_0's l1: 94.2496",
      "\n",
      "[2700]\tvalid_0's l1: 93.5496",
      "\n",
      "[2800]\tvalid_0's l1: 92.9653",
      "\n",
      "[2900]\tvalid_0's l1: 92.3164",
      "\n",
      "[3000]\tvalid_0's l1: 91.7224",
      "\n",
      "[3100]\tvalid_0's l1: 91.2736",
      "\n",
      "[3200]\tvalid_0's l1: 90.8463",
      "\n",
      "[3300]\tvalid_0's l1: 90.46",
      "\n",
      "[3400]\tvalid_0's l1: 90.0925",
      "\n",
      "[3500]\tvalid_0's l1: 89.8058",
      "\n",
      "[3600]\tvalid_0's l1: 89.3826",
      "\n",
      "[3700]\tvalid_0's l1: 89.0616",
      "\n",
      "[3800]\tvalid_0's l1: 88.759",
      "\n",
      "[3900]\tvalid_0's l1: 88.5127",
      "\n",
      "[4000]\tvalid_0's l1: 88.2506",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[4000]\tvalid_0's l1: 88.2506",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 300.921",
      "\n",
      "[200]\tvalid_0's l1: 227.338",
      "\n",
      "[300]\tvalid_0's l1: 191.742",
      "\n",
      "[400]\tvalid_0's l1: 172.218",
      "\n",
      "[500]\tvalid_0's l1: 160.965",
      "\n",
      "[600]\tvalid_0's l1: 149.417",
      "\n",
      "[700]\tvalid_0's l1: 139.77",
      "\n",
      "[800]\tvalid_0's l1: 133.288",
      "\n",
      "[900]\tvalid_0's l1: 127.925",
      "\n",
      "[1000]\tvalid_0's l1: 123.351",
      "\n",
      "[1100]\tvalid_0's l1: 119.359",
      "\n",
      "[1200]\tvalid_0's l1: 116.068",
      "\n",
      "[1300]\tvalid_0's l1: 113.328",
      "\n",
      "[1400]\tvalid_0's l1: 111.316",
      "\n",
      "[1500]\tvalid_0's l1: 109.715",
      "\n",
      "[1600]\tvalid_0's l1: 107.991",
      "\n",
      "[1700]\tvalid_0's l1: 106.592",
      "\n",
      "[1800]\tvalid_0's l1: 105.339",
      "\n",
      "[1900]\tvalid_0's l1: 104.245",
      "\n",
      "[2000]\tvalid_0's l1: 103.286",
      "\n",
      "[2100]\tvalid_0's l1: 102.394",
      "\n",
      "[2200]\tvalid_0's l1: 101.386",
      "\n",
      "[2300]\tvalid_0's l1: 100.577",
      "\n",
      "[2400]\tvalid_0's l1: 99.7896",
      "\n",
      "[2500]\tvalid_0's l1: 99.1365",
      "\n",
      "[2600]\tvalid_0's l1: 98.5931",
      "\n",
      "[2700]\tvalid_0's l1: 98.0443",
      "\n",
      "[2800]\tvalid_0's l1: 97.5628",
      "\n",
      "[2900]\tvalid_0's l1: 97.0787",
      "\n",
      "[3000]\tvalid_0's l1: 96.4778",
      "\n",
      "[3100]\tvalid_0's l1: 96.0712",
      "\n",
      "[3200]\tvalid_0's l1: 95.6874",
      "\n",
      "[3300]\tvalid_0's l1: 95.3015",
      "\n",
      "[3400]\tvalid_0's l1: 94.9634",
      "\n",
      "[3500]\tvalid_0's l1: 94.6489",
      "\n",
      "[3600]\tvalid_0's l1: 94.3281",
      "\n",
      "[3700]\tvalid_0's l1: 94.0566",
      "\n",
      "[3800]\tvalid_0's l1: 93.7397",
      "\n",
      "[3900]\tvalid_0's l1: 93.515",
      "\n",
      "[4000]\tvalid_0's l1: 93.2201",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[4000]\tvalid_0's l1: 93.2201",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 309.912",
      "\n",
      "[200]\tvalid_0's l1: 235.771",
      "\n",
      "[300]\tvalid_0's l1: 201.834",
      "\n",
      "[400]\tvalid_0's l1: 180.491",
      "\n",
      "[500]\tvalid_0's l1: 166.317",
      "\n",
      "[600]\tvalid_0's l1: 153.992",
      "\n",
      "[700]\tvalid_0's l1: 144.637",
      "\n",
      "[800]\tvalid_0's l1: 138.114",
      "\n",
      "[900]\tvalid_0's l1: 132.156",
      "\n",
      "[1000]\tvalid_0's l1: 127.999",
      "\n",
      "[1100]\tvalid_0's l1: 123.648",
      "\n",
      "[1200]\tvalid_0's l1: 119.446",
      "\n",
      "[1300]\tvalid_0's l1: 116.669",
      "\n",
      "[1400]\tvalid_0's l1: 114.463",
      "\n",
      "[1500]\tvalid_0's l1: 112.055",
      "\n",
      "[1600]\tvalid_0's l1: 110.079",
      "\n",
      "[1700]\tvalid_0's l1: 108.374",
      "\n",
      "[1800]\tvalid_0's l1: 106.919",
      "\n",
      "[1900]\tvalid_0's l1: 105.709",
      "\n",
      "[2000]\tvalid_0's l1: 104.379",
      "\n",
      "[2100]\tvalid_0's l1: 103.436",
      "\n",
      "[2200]\tvalid_0's l1: 102.56",
      "\n",
      "[2300]\tvalid_0's l1: 101.706",
      "\n",
      "[2400]\tvalid_0's l1: 101.052",
      "\n",
      "[2500]\tvalid_0's l1: 100.466",
      "\n",
      "[2600]\tvalid_0's l1: 99.6903",
      "\n",
      "[2700]\tvalid_0's l1: 99.0702",
      "\n",
      "[2800]\tvalid_0's l1: 98.3964",
      "\n",
      "[2900]\tvalid_0's l1: 97.9513",
      "\n",
      "[3000]\tvalid_0's l1: 97.5113",
      "\n",
      "[3100]\tvalid_0's l1: 97.0842",
      "\n",
      "[3200]\tvalid_0's l1: 96.6699",
      "\n",
      "[3300]\tvalid_0's l1: 96.3148",
      "\n",
      "[3400]\tvalid_0's l1: 95.9706",
      "\n",
      "[3500]\tvalid_0's l1: 95.6636",
      "\n",
      "[3600]\tvalid_0's l1: 95.3863",
      "\n",
      "[3700]\tvalid_0's l1: 95.0201",
      "\n",
      "[3800]\tvalid_0's l1: 94.7447",
      "\n",
      "[3900]\tvalid_0's l1: 94.4411",
      "\n",
      "[4000]\tvalid_0's l1: 94.1661",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[3999]\tvalid_0's l1: 94.1658",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 282.34",
      "\n",
      "[200]\tvalid_0's l1: 218.767",
      "\n",
      "[300]\tvalid_0's l1: 185.504",
      "\n",
      "[400]\tvalid_0's l1: 167.509",
      "\n",
      "[500]\tvalid_0's l1: 153.673",
      "\n",
      "[600]\tvalid_0's l1: 144.127",
      "\n",
      "[700]\tvalid_0's l1: 136.147",
      "\n",
      "[800]\tvalid_0's l1: 129.702",
      "\n",
      "[900]\tvalid_0's l1: 124.699",
      "\n",
      "[1000]\tvalid_0's l1: 121.016",
      "\n",
      "[1100]\tvalid_0's l1: 117.47",
      "\n",
      "[1200]\tvalid_0's l1: 114.829",
      "\n",
      "[1300]\tvalid_0's l1: 112.477",
      "\n",
      "[1400]\tvalid_0's l1: 110.345",
      "\n",
      "[1500]\tvalid_0's l1: 108.589",
      "\n",
      "[1600]\tvalid_0's l1: 106.872",
      "\n",
      "[1700]\tvalid_0's l1: 105.458",
      "\n",
      "[1800]\tvalid_0's l1: 104.219",
      "\n",
      "[1900]\tvalid_0's l1: 102.849",
      "\n",
      "[2000]\tvalid_0's l1: 101.73",
      "\n",
      "[2100]\tvalid_0's l1: 100.793",
      "\n",
      "[2200]\tvalid_0's l1: 100.007",
      "\n",
      "[2300]\tvalid_0's l1: 99.2106",
      "\n",
      "[2400]\tvalid_0's l1: 98.4836",
      "\n",
      "[2500]\tvalid_0's l1: 97.807",
      "\n",
      "[2600]\tvalid_0's l1: 97.266",
      "\n",
      "[2700]\tvalid_0's l1: 96.7421",
      "\n",
      "[2800]\tvalid_0's l1: 96.2274",
      "\n",
      "[2900]\tvalid_0's l1: 95.6938",
      "\n",
      "[3000]\tvalid_0's l1: 95.2577",
      "\n",
      "[3100]\tvalid_0's l1: 94.8015",
      "\n",
      "[3200]\tvalid_0's l1: 94.374",
      "\n",
      "[3300]\tvalid_0's l1: 94.0462",
      "\n",
      "[3400]\tvalid_0's l1: 93.5984",
      "\n",
      "[3500]\tvalid_0's l1: 93.3207",
      "\n",
      "[3600]\tvalid_0's l1: 93.0753",
      "\n",
      "[3700]\tvalid_0's l1: 92.8225",
      "\n",
      "[3800]\tvalid_0's l1: 92.559",
      "\n",
      "[3900]\tvalid_0's l1: 92.2977",
      "\n",
      "[4000]\tvalid_0's l1: 92.0227",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[3999]\tvalid_0's l1: 92.0199",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 302.754",
      "\n",
      "[200]\tvalid_0's l1: 226.863",
      "\n",
      "[300]\tvalid_0's l1: 193.861",
      "\n",
      "[400]\tvalid_0's l1: 173.532",
      "\n",
      "[500]\tvalid_0's l1: 159.314",
      "\n",
      "[600]\tvalid_0's l1: 148.605",
      "\n",
      "[700]\tvalid_0's l1: 142.152",
      "\n",
      "[800]\tvalid_0's l1: 135.701",
      "\n",
      "[900]\tvalid_0's l1: 129.691",
      "\n",
      "[1000]\tvalid_0's l1: 125.004",
      "\n",
      "[1100]\tvalid_0's l1: 121.439",
      "\n",
      "[1200]\tvalid_0's l1: 118.201",
      "\n",
      "[1300]\tvalid_0's l1: 115.286",
      "\n",
      "[1400]\tvalid_0's l1: 113.355",
      "\n",
      "[1500]\tvalid_0's l1: 111.416",
      "\n",
      "[1600]\tvalid_0's l1: 109.842",
      "\n",
      "[1700]\tvalid_0's l1: 108.176",
      "\n",
      "[1800]\tvalid_0's l1: 106.92",
      "\n",
      "[1900]\tvalid_0's l1: 105.53",
      "\n",
      "[2000]\tvalid_0's l1: 104.56",
      "\n",
      "[2100]\tvalid_0's l1: 103.446",
      "\n",
      "[2200]\tvalid_0's l1: 102.392",
      "\n",
      "[2300]\tvalid_0's l1: 101.361",
      "\n",
      "[2400]\tvalid_0's l1: 100.839",
      "\n",
      "[2500]\tvalid_0's l1: 100.234",
      "\n",
      "[2600]\tvalid_0's l1: 99.4606",
      "\n",
      "[2700]\tvalid_0's l1: 98.8368",
      "\n",
      "[2800]\tvalid_0's l1: 98.0949",
      "\n",
      "[2900]\tvalid_0's l1: 97.5603",
      "\n",
      "[3000]\tvalid_0's l1: 97.0936",
      "\n",
      "[3100]\tvalid_0's l1: 96.7108",
      "\n",
      "[3200]\tvalid_0's l1: 96.1581",
      "\n",
      "[3300]\tvalid_0's l1: 95.7199",
      "\n",
      "[3400]\tvalid_0's l1: 95.4136",
      "\n",
      "[3500]\tvalid_0's l1: 95.0083",
      "\n",
      "[3600]\tvalid_0's l1: 94.6912",
      "\n",
      "[3700]\tvalid_0's l1: 94.4204",
      "\n",
      "[3800]\tvalid_0's l1: 94.1482",
      "\n",
      "[3900]\tvalid_0's l1: 93.8628",
      "\n",
      "[4000]\tvalid_0's l1: 93.5798",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[3998]\tvalid_0's l1: 93.5788",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMRegressor(learning_rate=0.01,max_depth=8,min_data_in_leaf= 20,num_leaves=170,\n",
    "    reg_alpha=0., reg_lambda=0.01, objective='mse', metric='mae',\n",
    "      min_child_samples=20,\n",
    "    n_estimators=1000, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,num_iterations=4000\n",
    ")\n",
    "data_lgb, predict_label = get_predict_w(lgb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019, n_splits=5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMRegressor(learning_rate=0.01,max_depth=8,min_data_in_leaf= 20,num_leaves=170,\n",
    "    reg_alpha=0., reg_lambda=0.01, objective='mse', metric='mae',\n",
    "      min_child_samples=20,\n",
    "    n_estimators=1000, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,num_iterations=2000\n",
    ")\n",
    "data_lgb, predict_label = get_predict_w(lgb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019, n_splits=5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 146.754",
      "\n",
      "[200]\tvalid_0's l1: 119.417",
      "\n",
      "[300]\tvalid_0's l1: 108.279",
      "\n",
      "[400]\tvalid_0's l1: 101.885",
      "\n",
      "[500]\tvalid_0's l1: 99.0229",
      "\n",
      "[600]\tvalid_0's l1: 96.6566",
      "\n",
      "[700]\tvalid_0's l1: 94.9533",
      "\n",
      "[800]\tvalid_0's l1: 93.7366",
      "\n",
      "[900]\tvalid_0's l1: 92.5498",
      "\n",
      "[1000]\tvalid_0's l1: 92.159",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[997]\tvalid_0's l1: 92.1135",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 153.698",
      "\n",
      "[200]\tvalid_0's l1: 127.265",
      "\n",
      "[300]\tvalid_0's l1: 114.132",
      "\n",
      "[400]\tvalid_0's l1: 108.801",
      "\n",
      "[500]\tvalid_0's l1: 106.314",
      "\n",
      "[600]\tvalid_0's l1: 103.299",
      "\n",
      "[700]\tvalid_0's l1: 101.333",
      "\n",
      "[800]\tvalid_0's l1: 100.166",
      "\n",
      "[900]\tvalid_0's l1: 99.3506",
      "\n",
      "[1000]\tvalid_0's l1: 98.358",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[1000]\tvalid_0's l1: 98.358",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 155.163",
      "\n",
      "[200]\tvalid_0's l1: 124.54",
      "\n",
      "[300]\tvalid_0's l1: 114.933",
      "\n",
      "[400]\tvalid_0's l1: 109.017",
      "\n",
      "[500]\tvalid_0's l1: 105.892",
      "\n",
      "[600]\tvalid_0's l1: 103.484",
      "\n",
      "[700]\tvalid_0's l1: 101.597",
      "\n",
      "[800]\tvalid_0's l1: 100.447",
      "\n",
      "[900]\tvalid_0's l1: 99.3285",
      "\n",
      "[1000]\tvalid_0's l1: 98.6395",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[993]\tvalid_0's l1: 98.6092",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 142.397",
      "\n",
      "[200]\tvalid_0's l1: 121.386",
      "\n",
      "[300]\tvalid_0's l1: 111.131",
      "\n",
      "[400]\tvalid_0's l1: 105.6",
      "\n",
      "[500]\tvalid_0's l1: 102.253",
      "\n",
      "[600]\tvalid_0's l1: 100.406",
      "\n",
      "[700]\tvalid_0's l1: 98.8349",
      "\n",
      "[800]\tvalid_0's l1: 97.6213",
      "\n",
      "[900]\tvalid_0's l1: 96.6274",
      "\n",
      "[1000]\tvalid_0's l1: 96.2759",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[998]\tvalid_0's l1: 96.2675",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 153.302",
      "\n",
      "[200]\tvalid_0's l1: 124.308",
      "\n",
      "[300]\tvalid_0's l1: 115.258",
      "\n",
      "[400]\tvalid_0's l1: 108.741",
      "\n",
      "[500]\tvalid_0's l1: 105.334",
      "\n",
      "[600]\tvalid_0's l1: 102.814",
      "\n",
      "[700]\tvalid_0's l1: 101.426",
      "\n",
      "[800]\tvalid_0's l1: 100.37",
      "\n",
      "[900]\tvalid_0's l1: 99.1015",
      "\n",
      "[1000]\tvalid_0's l1: 97.9998",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[1000]\tvalid_0's l1: 97.9998",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMRegressor(\n",
    "    num_leaves=32, reg_alpha=0., reg_lambda=0.01, objective='mse', metric='mae',\n",
    "    max_depth=-1, learning_rate=0.12, min_child_samples=20,\n",
    "    n_estimators=1000, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    ")\n",
    "data_lgb, predict_label = get_predict_w(lgb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019, n_splits=5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 181.869",
      "\n",
      "[200]\tvalid_0's l1: 145.78",
      "\n",
      "[300]\tvalid_0's l1: 128.981",
      "\n",
      "[400]\tvalid_0's l1: 117.787",
      "\n",
      "[500]\tvalid_0's l1: 111.537",
      "\n",
      "[600]\tvalid_0's l1: 107.239",
      "\n",
      "[700]\tvalid_0's l1: 104.001",
      "\n",
      "[800]\tvalid_0's l1: 101.043",
      "\n",
      "[900]\tvalid_0's l1: 98.3299",
      "\n",
      "[1000]\tvalid_0's l1: 96.5694",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[1000]\tvalid_0's l1: 96.5694",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 190.309",
      "\n",
      "[200]\tvalid_0's l1: 153.94",
      "\n",
      "[300]\tvalid_0's l1: 133.423",
      "\n",
      "[400]\tvalid_0's l1: 122.904",
      "\n",
      "[500]\tvalid_0's l1: 117.303",
      "\n",
      "[600]\tvalid_0's l1: 111.885",
      "\n",
      "[700]\tvalid_0's l1: 107.965",
      "\n",
      "[800]\tvalid_0's l1: 105.746",
      "\n",
      "[900]\tvalid_0's l1: 103.45",
      "\n",
      "[1000]\tvalid_0's l1: 101.392",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[1000]\tvalid_0's l1: 101.392",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 193.648",
      "\n",
      "[200]\tvalid_0's l1: 153.002",
      "\n",
      "[300]\tvalid_0's l1: 136.206",
      "\n",
      "[400]\tvalid_0's l1: 125.16",
      "\n",
      "[500]\tvalid_0's l1: 118.231",
      "\n",
      "[600]\tvalid_0's l1: 112.685",
      "\n",
      "[700]\tvalid_0's l1: 108.977",
      "\n",
      "[800]\tvalid_0's l1: 106.242",
      "\n",
      "[900]\tvalid_0's l1: 103.788",
      "\n",
      "[1000]\tvalid_0's l1: 102.143",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[1000]\tvalid_0's l1: 102.143",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 181.687",
      "\n",
      "[200]\tvalid_0's l1: 150.47",
      "\n",
      "[300]\tvalid_0's l1: 132.913",
      "\n",
      "[400]\tvalid_0's l1: 122.726",
      "\n",
      "[500]\tvalid_0's l1: 115.239",
      "\n",
      "[600]\tvalid_0's l1: 110.795",
      "\n",
      "[700]\tvalid_0's l1: 106.992",
      "\n",
      "[800]\tvalid_0's l1: 104.448",
      "\n",
      "[900]\tvalid_0's l1: 102.188",
      "\n",
      "[1000]\tvalid_0's l1: 100.749",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[1000]\tvalid_0's l1: 100.749",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 189.881",
      "\n",
      "[200]\tvalid_0's l1: 152.51",
      "\n",
      "[300]\tvalid_0's l1: 136.942",
      "\n",
      "[400]\tvalid_0's l1: 124.499",
      "\n",
      "[500]\tvalid_0's l1: 117.249",
      "\n",
      "[600]\tvalid_0's l1: 112.417",
      "\n",
      "[700]\tvalid_0's l1: 109.434",
      "\n",
      "[800]\tvalid_0's l1: 106.84",
      "\n",
      "[900]\tvalid_0's l1: 104.267",
      "\n",
      "[1000]\tvalid_0's l1: 102.402",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[1000]\tvalid_0's l1: 102.402",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMRegressor(\n",
    "    num_leaves=32, reg_alpha=0., reg_lambda=0.01, objective='mse', metric='mae',\n",
    "    max_depth=-1, learning_rate=0.05, min_child_samples=20,\n",
    "    n_estimators=1000, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,num_iterations=1000\n",
    ")\n",
    "data_lgb_005, test_data_lgb_005 = get_predict_w(lgb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019, n_splits=5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "   adcode  carCommentVolum  label             model  newsReplyVolum  \\\n0  310000             11.0  292.0  3c974920a76ac9c1           106.0   \n1  530000             11.0  466.0  3c974920a76ac9c1           106.0   \n2  150000             11.0  257.0  3c974920a76ac9c1           106.0   \n3  110000             11.0  408.0  3c974920a76ac9c1           106.0   \n4  510000             11.0  610.0  3c974920a76ac9c1           106.0   \n\n   popularity  predict_label  regMonth  regYear  sample_weight  \n0      1479.0     344.319093         1     2016              1  \n1      1594.0     481.212134         1     2016              1  \n2      1479.0     183.706240         1     2016              1  \n3      2370.0     434.470023         1     2016              1  \n4      3562.0     637.968153         1     2016              1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>adcode</th>\n      <th>carCommentVolum</th>\n      <th>label</th>\n      <th>model</th>\n      <th>newsReplyVolum</th>\n      <th>popularity</th>\n      <th>predict_label</th>\n      <th>regMonth</th>\n      <th>regYear</th>\n      <th>sample_weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310000</td>\n      <td>11.0</td>\n      <td>292.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1479.0</td>\n      <td>344.319093</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>530000</td>\n      <td>11.0</td>\n      <td>466.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1594.0</td>\n      <td>481.212134</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150000</td>\n      <td>11.0</td>\n      <td>257.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1479.0</td>\n      <td>183.706240</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>110000</td>\n      <td>11.0</td>\n      <td>408.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2370.0</td>\n      <td>434.470023</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>510000</td>\n      <td>11.0</td>\n      <td>610.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3562.0</td>\n      <td>637.968153</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 14
    }
   ],
   "source": [
    "data_lgb.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 146.754",
      "\n",
      "[200]\tvalid_0's l1: 119.417",
      "\n",
      "[300]\tvalid_0's l1: 108.279",
      "\n",
      "[400]\tvalid_0's l1: 101.885",
      "\n",
      "[500]\tvalid_0's l1: 99.0229",
      "\n",
      "[600]\tvalid_0's l1: 96.6566",
      "\n",
      "[700]\tvalid_0's l1: 94.9533",
      "\n",
      "[800]\tvalid_0's l1: 93.7366",
      "\n",
      "[900]\tvalid_0's l1: 92.5498",
      "\n",
      "[1000]\tvalid_0's l1: 92.159",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[997]\tvalid_0's l1: 92.1135",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 153.698",
      "\n",
      "[200]\tvalid_0's l1: 127.265",
      "\n",
      "[300]\tvalid_0's l1: 114.132",
      "\n",
      "[400]\tvalid_0's l1: 108.801",
      "\n",
      "[500]\tvalid_0's l1: 106.314",
      "\n",
      "[600]\tvalid_0's l1: 103.299",
      "\n",
      "[700]\tvalid_0's l1: 101.333",
      "\n",
      "[800]\tvalid_0's l1: 100.166",
      "\n",
      "[900]\tvalid_0's l1: 99.3506",
      "\n",
      "[1000]\tvalid_0's l1: 98.358",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[1000]\tvalid_0's l1: 98.358",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 155.163",
      "\n",
      "[200]\tvalid_0's l1: 124.54",
      "\n",
      "[300]\tvalid_0's l1: 114.933",
      "\n",
      "[400]\tvalid_0's l1: 109.017",
      "\n",
      "[500]\tvalid_0's l1: 105.892",
      "\n",
      "[600]\tvalid_0's l1: 103.484",
      "\n",
      "[700]\tvalid_0's l1: 101.597",
      "\n",
      "[800]\tvalid_0's l1: 100.447",
      "\n",
      "[900]\tvalid_0's l1: 99.3285",
      "\n",
      "[1000]\tvalid_0's l1: 98.6395",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[993]\tvalid_0's l1: 98.6092",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 142.397",
      "\n",
      "[200]\tvalid_0's l1: 121.386",
      "\n",
      "[300]\tvalid_0's l1: 111.131",
      "\n",
      "[400]\tvalid_0's l1: 105.6",
      "\n",
      "[500]\tvalid_0's l1: 102.253",
      "\n",
      "[600]\tvalid_0's l1: 100.406",
      "\n",
      "[700]\tvalid_0's l1: 98.8349",
      "\n",
      "[800]\tvalid_0's l1: 97.6213",
      "\n",
      "[900]\tvalid_0's l1: 96.6274",
      "\n",
      "[1000]\tvalid_0's l1: 96.2759",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[998]\tvalid_0's l1: 96.2675",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l1: 153.302",
      "\n",
      "[200]\tvalid_0's l1: 124.308",
      "\n",
      "[300]\tvalid_0's l1: 115.258",
      "\n",
      "[400]\tvalid_0's l1: 108.741",
      "\n",
      "[500]\tvalid_0's l1: 105.334",
      "\n",
      "[600]\tvalid_0's l1: 102.814",
      "\n",
      "[700]\tvalid_0's l1: 101.426",
      "\n",
      "[800]\tvalid_0's l1: 100.37",
      "\n",
      "[900]\tvalid_0's l1: 99.1015",
      "\n",
      "[1000]\tvalid_0's l1: 97.9998",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[1000]\tvalid_0's l1: 97.9998",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    num_leaves=32, reg_alpha=0., reg_lambda=0.01, objective='mse', metric='mae',\n",
    "    max_depth=-1, learning_rate=0.05, min_child_samples=20,\n",
    "    n_estimators=1000, subsample=0.7, colsample_bytree=0.7, subsample_freq=1\n",
    ")\n",
    "data_lgb, predict_label = get_predict_w(lgb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019, n_splits=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l2: 49308.5\tvalid_0's l1: 120.979",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[100]\tvalid_0's l2: 49308.5\tvalid_0's l1: 120.979",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l2: 53485.4\tvalid_0's l1: 123.001",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[100]\tvalid_0's l2: 53485.4\tvalid_0's l1: 123.001",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l2: 56174.5\tvalid_0's l1: 125.9",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[100]\tvalid_0's l2: 56174.5\tvalid_0's l1: 125.9",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l2: 51288.4\tvalid_0's l1: 124.088",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[100]\tvalid_0's l2: 51288.4\tvalid_0's l1: 124.088",
      "\n",
      "Training until validation scores don't improve for 100 rounds.",
      "\n",
      "[100]\tvalid_0's l2: 53077.6\tvalid_0's l1: 124.628",
      "\n",
      "Did not meet early stopping. Best iteration is:\n[100]\tvalid_0's l2: 53077.6\tvalid_0's l1: 124.628",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMRegressor()\n",
    "data_lgb, predict_label = get_predict_w(lgb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019, n_splits=5)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "   adcode  carCommentVolum  label             model  newsReplyVolum  \\\n0  310000             11.0    395  3c974920a76ac9c1           106.0   \n1  530000             11.0    414  3c974920a76ac9c1           106.0   \n2  150000             11.0    215  3c974920a76ac9c1           106.0   \n3  110000             11.0    556  3c974920a76ac9c1           106.0   \n4  510000             11.0    559  3c974920a76ac9c1           106.0   \n\n   popularity  predict_label  regMonth  regYear  sample_weight         lgb  \n0      1479.0     395.156677         1     2016              1  395.156677  \n1      1594.0     413.963795         1     2016              1  413.963795  \n2      1479.0     215.188753         1     2016              1  215.188753  \n3      2370.0     555.716926         1     2016              1  555.716926  \n4      3562.0     558.700597         1     2016              1  558.700597  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>adcode</th>\n      <th>carCommentVolum</th>\n      <th>label</th>\n      <th>model</th>\n      <th>newsReplyVolum</th>\n      <th>popularity</th>\n      <th>predict_label</th>\n      <th>regMonth</th>\n      <th>regYear</th>\n      <th>sample_weight</th>\n      <th>lgb</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310000</td>\n      <td>11.0</td>\n      <td>395</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1479.0</td>\n      <td>395.156677</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>395.156677</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>530000</td>\n      <td>11.0</td>\n      <td>414</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1594.0</td>\n      <td>413.963795</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>413.963795</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150000</td>\n      <td>11.0</td>\n      <td>215</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1479.0</td>\n      <td>215.188753</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>215.188753</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>110000</td>\n      <td>11.0</td>\n      <td>556</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2370.0</td>\n      <td>555.716926</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>555.716926</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>510000</td>\n      <td>11.0</td>\n      <td>559</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3562.0</td>\n      <td>558.700597</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>558.700597</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 17
    }
   ],
   "source": [
    "data_lgb.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0:\tlearn: 612.4635290\ttest: 593.6865009\tbest: 593.6865009 (0)\ttotal: 18.8ms\tremaining: 18.8s\n",
      "100:\tlearn: 612.3638943\ttest: 593.5868696\tbest: 593.5868696 (100)\ttotal: 3.08s\tremaining: 27.4s\n",
      "200:\tlearn: 612.2641938\ttest: 593.4871703\tbest: 593.4871703 (200)\ttotal: 5.76s\tremaining: 22.9s\n",
      "300:\tlearn: 612.1644036\ttest: 593.3873803\tbest: 593.3873803 (300)\ttotal: 7.85s\tremaining: 18.2s\n",
      "400:\tlearn: 612.0645259\ttest: 593.2875030\tbest: 593.2875030 (400)\ttotal: 9.78s\tremaining: 14.6s\n",
      "500:\tlearn: 611.9646555\ttest: 593.1876332\tbest: 593.1876332 (500)\ttotal: 11.5s\tremaining: 11.4s\n",
      "600:\tlearn: 611.8648145\ttest: 593.0877918\tbest: 593.0877918 (600)\ttotal: 13.3s\tremaining: 8.81s\n",
      "700:\tlearn: 611.7649321\ttest: 592.9879075\tbest: 592.9879075 (700)\ttotal: 15s\tremaining: 6.38s\n",
      "800:\tlearn: 611.6651283\ttest: 592.8880826\tbest: 592.8880826 (800)\ttotal: 17.1s\tremaining: 4.26s\n",
      "900:\tlearn: 611.5652777\ttest: 592.7882273\tbest: 592.7882273 (900)\ttotal: 19s\tremaining: 2.09s\n",
      "999:\tlearn: 611.4664297\ttest: 592.6893576\tbest: 592.6893576 (999)\ttotal: 20.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 592.6893576\n",
      "bestIteration = 999\n",
      "\n",
      "0:\tlearn: 608.5804403\ttest: 609.2188557\tbest: 609.2188557 (0)\ttotal: 18.1ms\tremaining: 18.1s\n",
      "100:\tlearn: 608.4808050\ttest: 609.1192248\tbest: 609.1192248 (100)\ttotal: 2.94s\tremaining: 26.2s\n",
      "200:\tlearn: 608.3811032\ttest: 609.0195263\tbest: 609.0195263 (200)\ttotal: 5.59s\tremaining: 22.2s\n",
      "300:\tlearn: 608.2814466\ttest: 608.9198739\tbest: 608.9198739 (300)\ttotal: 8.45s\tremaining: 19.6s\n",
      "400:\tlearn: 608.1817089\ttest: 608.8201405\tbest: 608.8201405 (400)\ttotal: 10.9s\tremaining: 16.3s\n",
      "500:\tlearn: 608.0818643\ttest: 608.7202980\tbest: 608.7202980 (500)\ttotal: 12.7s\tremaining: 12.7s\n",
      "600:\tlearn: 607.9819767\ttest: 608.6204114\tbest: 608.6204114 (600)\ttotal: 14.4s\tremaining: 9.54s\n",
      "700:\tlearn: 607.8821156\ttest: 608.5205515\tbest: 608.5205515 (700)\ttotal: 16.4s\tremaining: 6.98s\n",
      "800:\tlearn: 607.7822390\ttest: 608.4206758\tbest: 608.4206758 (800)\ttotal: 18.3s\tremaining: 4.56s\n",
      "900:\tlearn: 607.6823727\ttest: 608.3208115\tbest: 608.3208115 (900)\ttotal: 20.1s\tremaining: 2.21s\n",
      "999:\tlearn: 607.5835292\ttest: 608.2219709\tbest: 608.2219709 (999)\ttotal: 22s\tremaining: 0us\n",
      "\n",
      "bestTest = 608.2219709\n",
      "bestIteration = 999\n",
      "\n",
      "0:\tlearn: 605.3128425\ttest: 622.2892471\tbest: 622.2892471 (0)\ttotal: 21.7ms\tremaining: 21.6s\n",
      "100:\tlearn: 605.2132062\ttest: 622.1896172\tbest: 622.1896172 (100)\ttotal: 2.93s\tremaining: 26.1s\n",
      "200:\tlearn: 605.1135068\ttest: 622.0899229\tbest: 622.0899229 (200)\ttotal: 5.66s\tremaining: 22.5s\n",
      "300:\tlearn: 605.0138692\ttest: 621.9902911\tbest: 621.9902911 (300)\ttotal: 8.5s\tremaining: 19.7s\n",
      "400:\tlearn: 604.9141217\ttest: 621.8905479\tbest: 621.8905479 (400)\ttotal: 10.9s\tremaining: 16.3s\n",
      "500:\tlearn: 604.8142758\ttest: 621.7907042\tbest: 621.7907042 (500)\ttotal: 12.7s\tremaining: 12.7s\n",
      "600:\tlearn: 604.7143895\ttest: 621.6908203\tbest: 621.6908203 (600)\ttotal: 14.4s\tremaining: 9.55s\n",
      "700:\tlearn: 604.6145469\ttest: 621.5909802\tbest: 621.5909802 (700)\ttotal: 16.3s\tremaining: 6.96s\n",
      "800:\tlearn: 604.5146555\ttest: 621.4910905\tbest: 621.4910905 (800)\ttotal: 17.9s\tremaining: 4.46s\n",
      "900:\tlearn: 604.4147935\ttest: 621.3912292\tbest: 621.3912292 (900)\ttotal: 19.7s\tremaining: 2.17s\n",
      "999:\tlearn: 604.3159546\ttest: 621.2923911\tbest: 621.2923911 (999)\ttotal: 21.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 621.2923911\n",
      "bestIteration = 999\n",
      "\n",
      "0:\tlearn: 609.5977620\ttest: 605.1495691\tbest: 605.1495691 (0)\ttotal: 21.5ms\tremaining: 21.5s\n",
      "100:\tlearn: 609.4981221\ttest: 605.0499381\tbest: 605.0499381 (100)\ttotal: 2.98s\tremaining: 26.5s\n",
      "200:\tlearn: 609.3984218\ttest: 604.9502454\tbest: 604.9502454 (200)\ttotal: 5.61s\tremaining: 22.3s\n",
      "300:\tlearn: 609.2987656\ttest: 604.8505985\tbest: 604.8505985 (300)\ttotal: 8.33s\tremaining: 19.3s\n",
      "400:\tlearn: 609.1990285\ttest: 604.7508680\tbest: 604.7508680 (400)\ttotal: 10.9s\tremaining: 16.2s\n",
      "500:\tlearn: 609.0991842\ttest: 604.6510271\tbest: 604.6510271 (500)\ttotal: 12.8s\tremaining: 12.8s\n",
      "600:\tlearn: 608.9992827\ttest: 604.5511279\tbest: 604.5511279 (600)\ttotal: 14.5s\tremaining: 9.6s\n",
      "700:\tlearn: 608.8994775\ttest: 604.4513068\tbest: 604.4513068 (700)\ttotal: 16.6s\tremaining: 7.06s\n",
      "800:\tlearn: 608.7996400\ttest: 604.3514549\tbest: 604.3514549 (800)\ttotal: 18.5s\tremaining: 4.6s\n",
      "900:\tlearn: 608.6998467\ttest: 604.2516420\tbest: 604.2516420 (900)\ttotal: 20.8s\tremaining: 2.28s\n",
      "999:\tlearn: 608.6010013\ttest: 604.1527811\tbest: 604.1527811 (999)\ttotal: 22.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 604.1527811\n",
      "bestIteration = 999\n",
      "\n",
      "0:\tlearn: 607.5860432\ttest: 613.1964441\tbest: 613.1964441 (0)\ttotal: 27.1ms\tremaining: 27.1s\n",
      "100:\tlearn: 607.4864055\ttest: 613.0968069\tbest: 613.0968069 (100)\ttotal: 2.93s\tremaining: 26.1s\n",
      "200:\tlearn: 607.3867006\ttest: 612.9971028\tbest: 612.9971028 (200)\ttotal: 5.6s\tremaining: 22.3s\n",
      "300:\tlearn: 607.2870614\ttest: 612.8974647\tbest: 612.8974647 (300)\ttotal: 8.5s\tremaining: 19.7s\n",
      "400:\tlearn: 607.1873142\ttest: 612.7977165\tbest: 612.7977165 (400)\ttotal: 10.9s\tremaining: 16.3s\n",
      "500:\tlearn: 607.0874587\ttest: 612.6978612\tbest: 612.6978612 (500)\ttotal: 12.6s\tremaining: 12.6s\n",
      "600:\tlearn: 606.9875787\ttest: 612.5979821\tbest: 612.5979821 (600)\ttotal: 14.4s\tremaining: 9.54s\n",
      "700:\tlearn: 606.8877306\ttest: 612.4981341\tbest: 612.4981341 (700)\ttotal: 16.2s\tremaining: 6.93s\n",
      "800:\tlearn: 606.7878384\ttest: 612.3982416\tbest: 612.3982416 (800)\ttotal: 17.9s\tremaining: 4.45s\n",
      "900:\tlearn: 606.6879767\ttest: 612.2983811\tbest: 612.2983811 (900)\ttotal: 19.8s\tremaining: 2.17s\n",
      "999:\tlearn: 606.5891381\ttest: 612.1995423\tbest: 612.1995423 (999)\ttotal: 21.6s\tremaining: 0us\n",
      "\n",
      "bestTest = 612.1995423\n",
      "bestIteration = 999\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import catboost as ctb\n",
    "ctb_model = CatBoostRegressor()\n",
    "ctb_model = CatBoostRegressor(iterations=1000,learning_rate=0.05, depth=7, loss_function='MAE', \n",
    "                          eval_metric='MAE', random_seed=1)\n",
    "\n",
    "data_ctb, predict_label = get_predict_w(ctb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019,model_type='ctb')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_ctb['ctb'] = data_ctb[predict_label]\n",
    "data_ctb['label'] = data_ctb['ctb'].apply(lambda x: 0 if x < 0 else x)\n",
    "data_ctb[data_ctb.label.isnull()][['label']].round().astype(int).to_csv('ccf_car_sales_ctb0902.csv', index=False)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "    adcode  carCommentVolum   label             model  newsReplyVolum  \\\n0   310000             11.0   292.0  3c974920a76ac9c1           106.0   \n1   530000             11.0   466.0  3c974920a76ac9c1           106.0   \n2   150000             11.0   257.0  3c974920a76ac9c1           106.0   \n3   110000             11.0   408.0  3c974920a76ac9c1           106.0   \n4   510000             11.0   610.0  3c974920a76ac9c1           106.0   \n5   340000             11.0   206.0  3c974920a76ac9c1           106.0   \n6   370000             11.0   503.0  3c974920a76ac9c1           106.0   \n7   140000             11.0   236.0  3c974920a76ac9c1           106.0   \n8   440000             11.0  3635.0  3c974920a76ac9c1           106.0   \n9   450000             11.0   450.0  3c974920a76ac9c1           106.0   \n10  320000             11.0   876.0  3c974920a76ac9c1           106.0   \n11  360000             11.0   253.0  3c974920a76ac9c1           106.0   \n12  130000             11.0   306.0  3c974920a76ac9c1           106.0   \n13  410000             11.0   537.0  3c974920a76ac9c1           106.0   \n14  330000             11.0   650.0  3c974920a76ac9c1           106.0   \n15  420000             11.0   635.0  3c974920a76ac9c1           106.0   \n16  430000             11.0   525.0  3c974920a76ac9c1           106.0   \n17  350000             11.0   462.0  3c974920a76ac9c1           106.0   \n18  210000             11.0   791.0  3c974920a76ac9c1           106.0   \n19  500000             11.0   195.0  3c974920a76ac9c1           106.0   \n\n    popularity  predict_label  regMonth  regYear  sample_weight  \n0       1479.0       0.998146         1     2016              1  \n1       1594.0       0.998163         1     2016              1  \n2       1479.0       0.998291         1     2016              1  \n3       2370.0       0.997962         1     2016              1  \n4       3562.0       0.997753         1     2016              1  \n5       1314.0       0.998365         1     2016              1  \n6       3476.0       0.997600         1     2016              1  \n7       1422.0       0.998086         1     2016              1  \n8       7182.0       0.997301         1     2016              1  \n9       1163.0       0.998304         1     2016              1  \n10      3670.0       0.997740         1     2016              1  \n11       926.0       0.997925         1     2016              1  \n12      2973.0       0.997658         1     2016              1  \n13      3483.0       0.997781         1     2016              1  \n14      3167.0       0.997891         1     2016              1  \n15      2190.0       0.997978         1     2016              1  \n16      1666.0       0.998150         1     2016              1  \n17      1357.0       0.998411         1     2016              1  \n18      2808.0       0.997838         1     2016              1  \n19       682.0       0.997486         1     2016              1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>adcode</th>\n      <th>carCommentVolum</th>\n      <th>label</th>\n      <th>model</th>\n      <th>newsReplyVolum</th>\n      <th>popularity</th>\n      <th>predict_label</th>\n      <th>regMonth</th>\n      <th>regYear</th>\n      <th>sample_weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310000</td>\n      <td>11.0</td>\n      <td>292.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1479.0</td>\n      <td>0.998146</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>530000</td>\n      <td>11.0</td>\n      <td>466.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1594.0</td>\n      <td>0.998163</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150000</td>\n      <td>11.0</td>\n      <td>257.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1479.0</td>\n      <td>0.998291</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>110000</td>\n      <td>11.0</td>\n      <td>408.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2370.0</td>\n      <td>0.997962</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>510000</td>\n      <td>11.0</td>\n      <td>610.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3562.0</td>\n      <td>0.997753</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>340000</td>\n      <td>11.0</td>\n      <td>206.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1314.0</td>\n      <td>0.998365</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>370000</td>\n      <td>11.0</td>\n      <td>503.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3476.0</td>\n      <td>0.997600</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>140000</td>\n      <td>11.0</td>\n      <td>236.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1422.0</td>\n      <td>0.998086</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>440000</td>\n      <td>11.0</td>\n      <td>3635.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>7182.0</td>\n      <td>0.997301</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>450000</td>\n      <td>11.0</td>\n      <td>450.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1163.0</td>\n      <td>0.998304</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>320000</td>\n      <td>11.0</td>\n      <td>876.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3670.0</td>\n      <td>0.997740</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>360000</td>\n      <td>11.0</td>\n      <td>253.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>926.0</td>\n      <td>0.997925</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>130000</td>\n      <td>11.0</td>\n      <td>306.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2973.0</td>\n      <td>0.997658</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>410000</td>\n      <td>11.0</td>\n      <td>537.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3483.0</td>\n      <td>0.997781</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>330000</td>\n      <td>11.0</td>\n      <td>650.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3167.0</td>\n      <td>0.997891</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>420000</td>\n      <td>11.0</td>\n      <td>635.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2190.0</td>\n      <td>0.997978</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>430000</td>\n      <td>11.0</td>\n      <td>525.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1666.0</td>\n      <td>0.998150</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>350000</td>\n      <td>11.0</td>\n      <td>462.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1357.0</td>\n      <td>0.998411</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>210000</td>\n      <td>11.0</td>\n      <td>791.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2808.0</td>\n      <td>0.997838</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>500000</td>\n      <td>11.0</td>\n      <td>195.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>682.0</td>\n      <td>0.997486</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 29
    }
   ],
   "source": [
    "data_ctb.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0:\tlearn: 612.4145754\ttest: 593.6375469\tbest: 593.6375469 (0)\ttotal: 17.4ms\tremaining: 17.4s\n",
      "100:\tlearn: 607.4342303\ttest: 588.6572326\tbest: 588.6572326 (100)\ttotal: 2.99s\tremaining: 26.6s\n",
      "200:\tlearn: 602.4486790\ttest: 583.6730899\tbest: 583.6730899 (200)\ttotal: 4.85s\tremaining: 19.3s\n",
      "300:\tlearn: 597.4822572\ttest: 578.7117534\tbest: 578.7117534 (300)\ttotal: 6s\tremaining: 13.9s\n",
      "400:\tlearn: 592.5571579\ttest: 573.7962434\tbest: 573.7962434 (400)\ttotal: 7.53s\tremaining: 11.2s\n",
      "500:\tlearn: 587.6996247\ttest: 568.9532596\tbest: 568.9532596 (500)\ttotal: 9.5s\tremaining: 9.46s\n",
      "600:\tlearn: 582.9034521\ttest: 564.1734913\tbest: 564.1734913 (600)\ttotal: 11.8s\tremaining: 7.82s\n",
      "700:\tlearn: 578.1874071\ttest: 559.4736537\tbest: 559.4736537 (700)\ttotal: 14.2s\tremaining: 6.07s\n",
      "800:\tlearn: 573.5570519\ttest: 554.8572579\tbest: 554.8572579 (800)\ttotal: 16.9s\tremaining: 4.21s\n",
      "900:\tlearn: 569.0057278\ttest: 550.3279108\tbest: 550.3279108 (900)\ttotal: 19.9s\tremaining: 2.18s\n",
      "999:\tlearn: 564.5850359\ttest: 545.9384513\tbest: 545.9384513 (999)\ttotal: 22.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 545.9384513\n",
      "bestIteration = 999\n",
      "\n",
      "0:\tlearn: 608.5314867\ttest: 609.1699019\tbest: 609.1699019 (0)\ttotal: 18.1ms\tremaining: 18.1s\n",
      "100:\tlearn: 603.5508826\ttest: 604.1901828\tbest: 604.1901828 (100)\ttotal: 3.04s\tremaining: 27.1s\n",
      "200:\tlearn: 598.5644605\ttest: 599.2067524\tbest: 599.2067524 (200)\ttotal: 4.72s\tremaining: 18.8s\n",
      "300:\tlearn: 593.5995701\ttest: 594.2429836\tbest: 594.2429836 (300)\ttotal: 5.83s\tremaining: 13.5s\n",
      "400:\tlearn: 588.6785967\ttest: 589.3196885\tbest: 589.3196885 (400)\ttotal: 7.31s\tremaining: 10.9s\n",
      "500:\tlearn: 583.8278511\ttest: 584.4630316\tbest: 584.4630316 (500)\ttotal: 9.25s\tremaining: 9.21s\n",
      "600:\tlearn: 579.0396767\ttest: 579.6671036\tbest: 579.6671036 (600)\ttotal: 11.3s\tremaining: 7.53s\n",
      "700:\tlearn: 574.3301675\ttest: 574.9523742\tbest: 574.9523742 (700)\ttotal: 14s\tremaining: 5.99s\n",
      "800:\tlearn: 569.7069134\ttest: 570.3177926\tbest: 570.3177926 (800)\ttotal: 16.9s\tremaining: 4.19s\n",
      "900:\tlearn: 565.1645982\ttest: 565.7738782\tbest: 565.7738782 (900)\ttotal: 19.7s\tremaining: 2.17s\n",
      "999:\tlearn: 560.7549178\ttest: 561.3643421\tbest: 561.3643421 (999)\ttotal: 22.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 561.3643421\n",
      "bestIteration = 999\n",
      "\n",
      "0:\tlearn: 605.2638888\ttest: 622.2402930\tbest: 622.2402930 (0)\ttotal: 17.6ms\tremaining: 17.5s\n",
      "100:\tlearn: 600.2835754\ttest: 617.2601360\tbest: 617.2601360 (100)\ttotal: 2.98s\tremaining: 26.6s\n",
      "200:\tlearn: 595.2993736\ttest: 612.2741789\tbest: 612.2741789 (200)\ttotal: 4.75s\tremaining: 18.9s\n",
      "300:\tlearn: 590.3335570\ttest: 607.3113145\tbest: 607.3113145 (300)\ttotal: 5.97s\tremaining: 13.9s\n",
      "400:\tlearn: 585.4098645\ttest: 602.3902367\tbest: 602.3902367 (400)\ttotal: 7.45s\tremaining: 11.1s\n",
      "500:\tlearn: 580.5531672\ttest: 597.5404143\tbest: 597.5404143 (500)\ttotal: 9.43s\tremaining: 9.39s\n",
      "600:\tlearn: 575.7616086\ttest: 592.7442486\tbest: 592.7442486 (600)\ttotal: 11.8s\tremaining: 7.83s\n",
      "700:\tlearn: 571.0567921\ttest: 588.0179258\tbest: 588.0179258 (700)\ttotal: 14.4s\tremaining: 6.13s\n",
      "800:\tlearn: 566.4360609\ttest: 583.3735508\tbest: 583.3735508 (800)\ttotal: 17.2s\tremaining: 4.27s\n",
      "900:\tlearn: 561.8985781\ttest: 578.8140162\tbest: 578.8140162 (900)\ttotal: 20.2s\tremaining: 2.22s\n",
      "999:\tlearn: 557.4929385\ttest: 574.3912343\tbest: 574.3912343 (999)\ttotal: 23.3s\tremaining: 0us\n",
      "\n",
      "bestTest = 574.3912343\n",
      "bestIteration = 999\n",
      "\n",
      "0:\tlearn: 609.5488083\ttest: 605.1006155\tbest: 605.1006155 (0)\ttotal: 22.9ms\tremaining: 22.9s\n",
      "100:\tlearn: 604.5684771\ttest: 600.1197115\tbest: 600.1197115 (100)\ttotal: 3.02s\tremaining: 26.9s\n",
      "200:\tlearn: 599.5857995\ttest: 595.1320447\tbest: 595.1320447 (200)\ttotal: 5.06s\tremaining: 20.1s\n",
      "300:\tlearn: 594.6260638\ttest: 590.1601271\tbest: 590.1601271 (300)\ttotal: 6.42s\tremaining: 14.9s\n",
      "400:\tlearn: 589.7098329\ttest: 585.2298865\tbest: 585.2298865 (400)\ttotal: 8.2s\tremaining: 12.3s\n",
      "500:\tlearn: 584.8628840\ttest: 580.3682856\tbest: 580.3682856 (500)\ttotal: 10.3s\tremaining: 10.2s\n",
      "600:\tlearn: 580.0752588\ttest: 575.5707601\tbest: 575.5707601 (600)\ttotal: 12.6s\tremaining: 8.34s\n",
      "700:\tlearn: 575.3648176\ttest: 570.8559653\tbest: 570.8559653 (700)\ttotal: 15s\tremaining: 6.4s\n",
      "800:\tlearn: 570.7402372\ttest: 566.2241383\tbest: 566.2241383 (800)\ttotal: 17.9s\tremaining: 4.44s\n",
      "900:\tlearn: 566.2012086\ttest: 561.6739404\tbest: 561.6739404 (900)\ttotal: 20.9s\tremaining: 2.3s\n",
      "999:\tlearn: 561.7999338\ttest: 557.2528601\tbest: 557.2528601 (999)\ttotal: 24.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 557.2528601\n",
      "bestIteration = 999\n",
      "\n",
      "0:\tlearn: 607.5370896\ttest: 613.1474915\tbest: 613.1474915 (0)\ttotal: 17.1ms\tremaining: 17.1s\n",
      "100:\tlearn: 602.5564014\ttest: 608.1675403\tbest: 608.1675403 (100)\ttotal: 2.99s\tremaining: 26.7s\n",
      "200:\tlearn: 597.5700012\ttest: 603.1836809\tbest: 603.1836809 (200)\ttotal: 4.77s\tremaining: 19s\n",
      "300:\tlearn: 592.6042871\ttest: 598.2213049\tbest: 598.2213049 (300)\ttotal: 5.93s\tremaining: 13.8s\n",
      "400:\tlearn: 587.6808900\ttest: 593.3042770\tbest: 593.3042770 (400)\ttotal: 7.62s\tremaining: 11.4s\n",
      "500:\tlearn: 582.8266172\ttest: 588.4553107\tbest: 588.4553107 (500)\ttotal: 9.92s\tremaining: 9.88s\n",
      "600:\tlearn: 578.0294741\ttest: 583.6729867\tbest: 583.6729867 (600)\ttotal: 12.3s\tremaining: 8.17s\n",
      "700:\tlearn: 573.3089635\ttest: 578.9755964\tbest: 578.9755964 (700)\ttotal: 15.1s\tremaining: 6.45s\n",
      "800:\tlearn: 568.6664252\ttest: 574.3724596\tbest: 574.3724596 (800)\ttotal: 18s\tremaining: 4.47s\n",
      "900:\tlearn: 564.1154849\ttest: 569.8473554\tbest: 569.8473554 (900)\ttotal: 21s\tremaining: 2.31s\n",
      "999:\tlearn: 559.7032831\ttest: 565.4522363\tbest: 565.4522363 (999)\ttotal: 24s\tremaining: 0us\n",
      "\n",
      "bestTest = 565.4522363\n",
      "bestIteration = 999\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "ctb_model = CatBoostRegressor(iterations=1000,learning_rate=0.1, depth=7, loss_function='MAE', \n",
    "                          eval_metric='MAE', random_seed=1)\n",
    "\n",
    "data_ctb, predict_label = get_predict_w(ctb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019,model_type='ctb')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "    adcode  carCommentVolum   label             model  newsReplyVolum  \\\n0   310000             11.0   292.0  3c974920a76ac9c1           106.0   \n1   530000             11.0   466.0  3c974920a76ac9c1           106.0   \n2   150000             11.0   257.0  3c974920a76ac9c1           106.0   \n3   110000             11.0   408.0  3c974920a76ac9c1           106.0   \n4   510000             11.0   610.0  3c974920a76ac9c1           106.0   \n5   340000             11.0   206.0  3c974920a76ac9c1           106.0   \n6   370000             11.0   503.0  3c974920a76ac9c1           106.0   \n7   140000             11.0   236.0  3c974920a76ac9c1           106.0   \n8   440000             11.0  3635.0  3c974920a76ac9c1           106.0   \n9   450000             11.0   450.0  3c974920a76ac9c1           106.0   \n10  320000             11.0   876.0  3c974920a76ac9c1           106.0   \n11  360000             11.0   253.0  3c974920a76ac9c1           106.0   \n12  130000             11.0   306.0  3c974920a76ac9c1           106.0   \n13  410000             11.0   537.0  3c974920a76ac9c1           106.0   \n14  330000             11.0   650.0  3c974920a76ac9c1           106.0   \n15  420000             11.0   635.0  3c974920a76ac9c1           106.0   \n16  430000             11.0   525.0  3c974920a76ac9c1           106.0   \n17  350000             11.0   462.0  3c974920a76ac9c1           106.0   \n18  210000             11.0   791.0  3c974920a76ac9c1           106.0   \n19  500000             11.0   195.0  3c974920a76ac9c1           106.0   \n\n    popularity  predict_label  regMonth  regYear  sample_weight  \n0       1479.0      48.400565         1     2016              1  \n1       1594.0      48.544238         1     2016              1  \n2       1479.0      48.398797         1     2016              1  \n3       2370.0      49.031031         1     2016              1  \n4       3562.0      48.906963         1     2016              1  \n5       1314.0      48.362881         1     2016              1  \n6       3476.0      48.973518         1     2016              1  \n7       1422.0      48.391441         1     2016              1  \n8       7182.0      49.170427         1     2016              1  \n9       1163.0      48.274277         1     2016              1  \n10      3670.0      48.906963         1     2016              1  \n11       926.0      47.986458         1     2016              1  \n12      2973.0      49.015690         1     2016              1  \n13      3483.0      48.906963         1     2016              1  \n14      3167.0      48.908522         1     2016              1  \n15      2190.0      48.972547         1     2016              1  \n16      1666.0      48.551515         1     2016              1  \n17      1357.0      48.372092         1     2016              1  \n18      2808.0      48.977485         1     2016              1  \n19       682.0      47.398880         1     2016              1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>adcode</th>\n      <th>carCommentVolum</th>\n      <th>label</th>\n      <th>model</th>\n      <th>newsReplyVolum</th>\n      <th>popularity</th>\n      <th>predict_label</th>\n      <th>regMonth</th>\n      <th>regYear</th>\n      <th>sample_weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310000</td>\n      <td>11.0</td>\n      <td>292.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1479.0</td>\n      <td>48.400565</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>530000</td>\n      <td>11.0</td>\n      <td>466.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1594.0</td>\n      <td>48.544238</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150000</td>\n      <td>11.0</td>\n      <td>257.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1479.0</td>\n      <td>48.398797</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>110000</td>\n      <td>11.0</td>\n      <td>408.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2370.0</td>\n      <td>49.031031</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>510000</td>\n      <td>11.0</td>\n      <td>610.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3562.0</td>\n      <td>48.906963</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>340000</td>\n      <td>11.0</td>\n      <td>206.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1314.0</td>\n      <td>48.362881</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>370000</td>\n      <td>11.0</td>\n      <td>503.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3476.0</td>\n      <td>48.973518</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>140000</td>\n      <td>11.0</td>\n      <td>236.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1422.0</td>\n      <td>48.391441</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>440000</td>\n      <td>11.0</td>\n      <td>3635.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>7182.0</td>\n      <td>49.170427</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>450000</td>\n      <td>11.0</td>\n      <td>450.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1163.0</td>\n      <td>48.274277</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>320000</td>\n      <td>11.0</td>\n      <td>876.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3670.0</td>\n      <td>48.906963</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>360000</td>\n      <td>11.0</td>\n      <td>253.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>926.0</td>\n      <td>47.986458</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>130000</td>\n      <td>11.0</td>\n      <td>306.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2973.0</td>\n      <td>49.015690</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>410000</td>\n      <td>11.0</td>\n      <td>537.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3483.0</td>\n      <td>48.906963</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>330000</td>\n      <td>11.0</td>\n      <td>650.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3167.0</td>\n      <td>48.908522</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>420000</td>\n      <td>11.0</td>\n      <td>635.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2190.0</td>\n      <td>48.972547</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>430000</td>\n      <td>11.0</td>\n      <td>525.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1666.0</td>\n      <td>48.551515</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>350000</td>\n      <td>11.0</td>\n      <td>462.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1357.0</td>\n      <td>48.372092</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>210000</td>\n      <td>11.0</td>\n      <td>791.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2808.0</td>\n      <td>48.977485</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>500000</td>\n      <td>11.0</td>\n      <td>195.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>682.0</td>\n      <td>47.398880</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 31
    }
   ],
   "source": [
    "data_ctb.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0:\tlearn: 979.7329647\ttest: 926.5130836\tbest: 926.5130836 (0)\ttotal: 89.7ms\tremaining: 1m 29s\n",
      "100:\tlearn: 441.7731645\ttest: 400.7756110\tbest: 400.7756110 (100)\ttotal: 3.52s\tremaining: 31.4s\n",
      "200:\tlearn: 391.3831055\ttest: 353.5643746\tbest: 353.5643746 (200)\ttotal: 6.77s\tremaining: 26.9s\n",
      "300:\tlearn: 368.7231480\ttest: 336.0041145\tbest: 336.0041145 (300)\ttotal: 9.72s\tremaining: 22.6s\n",
      "400:\tlearn: 347.6329050\ttest: 320.2515051\tbest: 320.2515051 (400)\ttotal: 12.8s\tremaining: 19.2s\n",
      "500:\tlearn: 330.8920428\ttest: 308.7225969\tbest: 308.7225969 (500)\ttotal: 16.2s\tremaining: 16.1s\n",
      "600:\tlearn: 319.0123137\ttest: 300.1165721\tbest: 300.1165721 (600)\ttotal: 19.4s\tremaining: 12.9s\n",
      "700:\tlearn: 311.1466984\ttest: 293.6337677\tbest: 293.6337677 (700)\ttotal: 22.6s\tremaining: 9.64s\n",
      "800:\tlearn: 306.1443342\ttest: 289.6560534\tbest: 289.6553129 (798)\ttotal: 25.6s\tremaining: 6.35s\n",
      "900:\tlearn: 299.3733776\ttest: 284.1340223\tbest: 284.1340223 (900)\ttotal: 28.8s\tremaining: 3.17s\n",
      "999:\tlearn: 294.7170611\ttest: 280.7798923\tbest: 280.7798923 (999)\ttotal: 31.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 280.7798923\n",
      "bestIteration = 999\n",
      "\n",
      "0:\tlearn: 972.1575271\ttest: 969.0568590\tbest: 969.0568590 (0)\ttotal: 29.9ms\tremaining: 29.9s\n",
      "100:\tlearn: 435.3096763\ttest: 439.7465335\tbest: 439.7465335 (100)\ttotal: 3.31s\tremaining: 29.4s\n",
      "200:\tlearn: 387.5200973\ttest: 396.6491450\tbest: 396.6491450 (200)\ttotal: 6.57s\tremaining: 26.1s\n",
      "300:\tlearn: 366.3288008\ttest: 378.3530359\tbest: 378.3530359 (300)\ttotal: 9.46s\tremaining: 22s\n",
      "400:\tlearn: 346.8384330\ttest: 360.0085101\tbest: 360.0085101 (400)\ttotal: 12.7s\tremaining: 19s\n",
      "500:\tlearn: 332.2643907\ttest: 344.7012363\tbest: 344.7012363 (500)\ttotal: 15.9s\tremaining: 15.9s\n",
      "600:\tlearn: 322.8840718\ttest: 335.1381689\tbest: 335.1381689 (600)\ttotal: 19.1s\tremaining: 12.7s\n",
      "700:\tlearn: 312.5171771\ttest: 324.6716812\tbest: 324.6716812 (700)\ttotal: 22.2s\tremaining: 9.48s\n",
      "800:\tlearn: 305.1351640\ttest: 318.5220151\tbest: 318.5220151 (800)\ttotal: 25.4s\tremaining: 6.32s\n",
      "900:\tlearn: 300.2270868\ttest: 314.5195989\tbest: 314.5195989 (900)\ttotal: 28.3s\tremaining: 3.11s\n",
      "999:\tlearn: 295.1877976\ttest: 310.0514392\tbest: 310.0514392 (999)\ttotal: 31.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 310.0514392\n",
      "bestIteration = 999\n",
      "\n",
      "0:\tlearn: 958.2339678\ttest: 1013.7209447\tbest: 1013.7209447 (0)\ttotal: 27.7ms\tremaining: 27.6s\n",
      "100:\tlearn: 440.6903897\ttest: 484.5935735\tbest: 484.5935735 (100)\ttotal: 3.24s\tremaining: 28.9s\n",
      "200:\tlearn: 392.8224148\ttest: 427.0473294\tbest: 427.0473294 (200)\ttotal: 6.33s\tremaining: 25.2s\n",
      "300:\tlearn: 376.0226829\ttest: 406.7905996\tbest: 406.7905996 (300)\ttotal: 8.26s\tremaining: 19.2s\n",
      "400:\tlearn: 354.1184694\ttest: 379.2622810\tbest: 379.2622810 (400)\ttotal: 10.9s\tremaining: 16.2s\n",
      "500:\tlearn: 337.9545756\ttest: 359.6049088\tbest: 359.6049088 (500)\ttotal: 13.1s\tremaining: 13.1s\n",
      "600:\tlearn: 325.8755473\ttest: 345.8758152\tbest: 345.8758152 (600)\ttotal: 15.6s\tremaining: 10.4s\n",
      "700:\tlearn: 317.7483393\ttest: 336.7440484\tbest: 336.7440484 (700)\ttotal: 18s\tremaining: 7.67s\n",
      "800:\tlearn: 310.8314425\ttest: 329.4585580\tbest: 329.4585580 (800)\ttotal: 20.5s\tremaining: 5.09s\n",
      "900:\tlearn: 306.7188285\ttest: 324.9904501\tbest: 324.9904501 (900)\ttotal: 22.6s\tremaining: 2.48s\n",
      "999:\tlearn: 303.1847551\ttest: 321.4976648\tbest: 321.4976648 (999)\ttotal: 24.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 321.4976648\n",
      "bestIteration = 999\n",
      "\n",
      "0:\tlearn: 980.7419929\ttest: 933.1318354\tbest: 933.1318354 (0)\ttotal: 27.2ms\tremaining: 27.2s\n",
      "100:\tlearn: 444.8224202\ttest: 407.9383121\tbest: 407.9383121 (100)\ttotal: 3.6s\tremaining: 32s\n",
      "200:\tlearn: 392.3882548\ttest: 363.6417713\tbest: 363.6417713 (200)\ttotal: 7.39s\tremaining: 29.4s\n",
      "300:\tlearn: 362.6371610\ttest: 341.3637948\tbest: 341.3637948 (300)\ttotal: 10.9s\tremaining: 25.4s\n",
      "400:\tlearn: 344.9241213\ttest: 326.3050863\tbest: 326.3050863 (400)\ttotal: 14.4s\tremaining: 21.5s\n",
      "500:\tlearn: 325.9343862\ttest: 311.3030781\tbest: 311.2877112 (499)\ttotal: 18.5s\tremaining: 18.5s\n",
      "600:\tlearn: 314.6487252\ttest: 301.4592154\tbest: 301.4592154 (600)\ttotal: 22.2s\tremaining: 14.7s\n",
      "700:\tlearn: 303.9392644\ttest: 293.1933368\tbest: 293.1933368 (700)\ttotal: 25.6s\tremaining: 10.9s\n",
      "800:\tlearn: 297.7057091\ttest: 288.8477930\tbest: 288.8360428 (799)\ttotal: 28.7s\tremaining: 7.13s\n",
      "900:\tlearn: 293.7443270\ttest: 286.1564022\tbest: 286.1564022 (900)\ttotal: 31.5s\tremaining: 3.46s\n",
      "999:\tlearn: 290.8467142\ttest: 284.3679360\tbest: 284.3657627 (998)\ttotal: 34.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 284.3657627\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.",
      "\n",
      "0:\tlearn: 962.2432986\ttest: 1008.0529273\tbest: 1008.0529273 (0)\ttotal: 28.5ms\tremaining: 28.5s\n",
      "100:\tlearn: 438.3646610\ttest: 461.3779278\tbest: 461.3779278 (100)\ttotal: 3.69s\tremaining: 32.9s\n",
      "200:\tlearn: 386.0087184\ttest: 390.5307516\tbest: 390.5307516 (200)\ttotal: 7.28s\tremaining: 28.9s\n",
      "300:\tlearn: 359.4538888\ttest: 356.7384134\tbest: 356.7384134 (300)\ttotal: 10.7s\tremaining: 24.9s\n",
      "400:\tlearn: 341.5187881\ttest: 336.5230080\tbest: 336.5230080 (400)\ttotal: 14s\tremaining: 20.9s\n",
      "500:\tlearn: 329.5128659\ttest: 323.7799853\tbest: 323.7799853 (500)\ttotal: 17.5s\tremaining: 17.4s\n",
      "600:\tlearn: 318.8578315\ttest: 313.9046187\tbest: 313.9046187 (600)\ttotal: 20.7s\tremaining: 13.8s\n",
      "700:\tlearn: 310.3870082\ttest: 306.7252684\tbest: 306.7252684 (700)\ttotal: 24.1s\tremaining: 10.3s\n",
      "800:\tlearn: 304.3799080\ttest: 301.4812602\tbest: 301.4812602 (800)\ttotal: 27.1s\tremaining: 6.73s\n",
      "900:\tlearn: 297.9054754\ttest: 295.8074849\tbest: 295.8074849 (900)\ttotal: 30.5s\tremaining: 3.35s\n",
      "999:\tlearn: 294.2827835\ttest: 292.8714185\tbest: 292.8714185 (999)\ttotal: 33.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 292.8714185\n",
      "bestIteration = 999\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "ctb_model = CatBoostRegressor()\n",
    "data_ctb, predict_label = get_predict_w(ctb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019,model_type='ctb')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "    adcode  carCommentVolum   label             model  newsReplyVolum  \\\n0   310000             11.0   292.0  3c974920a76ac9c1           106.0   \n1   530000             11.0   466.0  3c974920a76ac9c1           106.0   \n2   150000             11.0   257.0  3c974920a76ac9c1           106.0   \n3   110000             11.0   408.0  3c974920a76ac9c1           106.0   \n4   510000             11.0   610.0  3c974920a76ac9c1           106.0   \n5   340000             11.0   206.0  3c974920a76ac9c1           106.0   \n6   370000             11.0   503.0  3c974920a76ac9c1           106.0   \n7   140000             11.0   236.0  3c974920a76ac9c1           106.0   \n8   440000             11.0  3635.0  3c974920a76ac9c1           106.0   \n9   450000             11.0   450.0  3c974920a76ac9c1           106.0   \n10  320000             11.0   876.0  3c974920a76ac9c1           106.0   \n11  360000             11.0   253.0  3c974920a76ac9c1           106.0   \n12  130000             11.0   306.0  3c974920a76ac9c1           106.0   \n13  410000             11.0   537.0  3c974920a76ac9c1           106.0   \n14  330000             11.0   650.0  3c974920a76ac9c1           106.0   \n15  420000             11.0   635.0  3c974920a76ac9c1           106.0   \n16  430000             11.0   525.0  3c974920a76ac9c1           106.0   \n17  350000             11.0   462.0  3c974920a76ac9c1           106.0   \n18  210000             11.0   791.0  3c974920a76ac9c1           106.0   \n19  500000             11.0   195.0  3c974920a76ac9c1           106.0   \n\n    popularity  predict_label  regMonth  regYear  sample_weight  \n0       1479.0     287.396569         1     2016              1  \n1       1594.0     341.227381         1     2016              1  \n2       1479.0     240.915092         1     2016              1  \n3       2370.0     479.512411         1     2016              1  \n4       3562.0     549.619826         1     2016              1  \n5       1314.0     297.182276         1     2016              1  \n6       3476.0     782.533868         1     2016              1  \n7       1422.0     231.177955         1     2016              1  \n8       7182.0    2110.017264         1     2016              1  \n9       1163.0     382.200722         1     2016              1  \n10      3670.0    1159.961646         1     2016              1  \n11       926.0     259.740349         1     2016              1  \n12      2973.0     430.608609         1     2016              1  \n13      3483.0     566.510804         1     2016              1  \n14      3167.0     870.758531         1     2016              1  \n15      2190.0     618.177820         1     2016              1  \n16      1666.0     394.623402         1     2016              1  \n17      1357.0     303.998297         1     2016              1  \n18      2808.0     981.831775         1     2016              1  \n19       682.0     185.755931         1     2016              1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>adcode</th>\n      <th>carCommentVolum</th>\n      <th>label</th>\n      <th>model</th>\n      <th>newsReplyVolum</th>\n      <th>popularity</th>\n      <th>predict_label</th>\n      <th>regMonth</th>\n      <th>regYear</th>\n      <th>sample_weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310000</td>\n      <td>11.0</td>\n      <td>292.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1479.0</td>\n      <td>287.396569</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>530000</td>\n      <td>11.0</td>\n      <td>466.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1594.0</td>\n      <td>341.227381</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150000</td>\n      <td>11.0</td>\n      <td>257.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1479.0</td>\n      <td>240.915092</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>110000</td>\n      <td>11.0</td>\n      <td>408.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2370.0</td>\n      <td>479.512411</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>510000</td>\n      <td>11.0</td>\n      <td>610.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3562.0</td>\n      <td>549.619826</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>340000</td>\n      <td>11.0</td>\n      <td>206.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1314.0</td>\n      <td>297.182276</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>370000</td>\n      <td>11.0</td>\n      <td>503.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3476.0</td>\n      <td>782.533868</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>140000</td>\n      <td>11.0</td>\n      <td>236.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1422.0</td>\n      <td>231.177955</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>440000</td>\n      <td>11.0</td>\n      <td>3635.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>7182.0</td>\n      <td>2110.017264</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>450000</td>\n      <td>11.0</td>\n      <td>450.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1163.0</td>\n      <td>382.200722</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>320000</td>\n      <td>11.0</td>\n      <td>876.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3670.0</td>\n      <td>1159.961646</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>360000</td>\n      <td>11.0</td>\n      <td>253.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>926.0</td>\n      <td>259.740349</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>130000</td>\n      <td>11.0</td>\n      <td>306.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2973.0</td>\n      <td>430.608609</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>410000</td>\n      <td>11.0</td>\n      <td>537.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3483.0</td>\n      <td>566.510804</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>330000</td>\n      <td>11.0</td>\n      <td>650.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3167.0</td>\n      <td>870.758531</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>420000</td>\n      <td>11.0</td>\n      <td>635.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2190.0</td>\n      <td>618.177820</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>430000</td>\n      <td>11.0</td>\n      <td>525.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1666.0</td>\n      <td>394.623402</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>350000</td>\n      <td>11.0</td>\n      <td>462.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1357.0</td>\n      <td>303.998297</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>210000</td>\n      <td>11.0</td>\n      <td>791.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2808.0</td>\n      <td>981.831775</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>500000</td>\n      <td>11.0</td>\n      <td>195.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>682.0</td>\n      <td>185.755931</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 36
    }
   ],
   "source": [
    "data_ctb.head(20)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0:\tlearn: 713.5941974\ttest: 661.3735910\tbest: 661.3735910 (0)\ttotal: 27.4ms\tremaining: 2m 17s\n",
      "100:\tlearn: 300.2462866\ttest: 295.4223429\tbest: 295.3888800 (97)\ttotal: 3.2s\tremaining: 2m 35s\n",
      "200:\tlearn: 270.7007834\ttest: 276.3965597\tbest: 276.3965597 (200)\ttotal: 6.14s\tremaining: 2m 26s\n",
      "300:\tlearn: 259.7369584\ttest: 271.0654472\tbest: 271.0492313 (296)\ttotal: 9.15s\tremaining: 2m 22s\n",
      "400:\tlearn: 252.8090575\ttest: 268.4517404\tbest: 268.2642046 (395)\ttotal: 12.1s\tremaining: 2m 18s\n",
      "500:\tlearn: 246.4807191\ttest: 265.7575378\tbest: 265.7575378 (500)\ttotal: 15.1s\tremaining: 2m 15s\n",
      "600:\tlearn: 241.8586446\ttest: 262.9532847\tbest: 262.9089871 (591)\ttotal: 18.1s\tremaining: 2m 12s\n",
      "700:\tlearn: 237.7434162\ttest: 260.4133070\tbest: 260.4133070 (700)\ttotal: 21.2s\tremaining: 2m 9s\n",
      "800:\tlearn: 235.3329284\ttest: 258.7027886\tbest: 258.7027886 (800)\ttotal: 24.3s\tremaining: 2m 7s\n",
      "900:\tlearn: 232.9879971\ttest: 257.4943543\tbest: 257.3796727 (886)\ttotal: 27.1s\tremaining: 2m 3s\n",
      "1000:\tlearn: 230.7298908\ttest: 256.9553863\tbest: 256.9427123 (999)\ttotal: 30.3s\tremaining: 2m\n",
      "1100:\tlearn: 227.2654481\ttest: 255.2215233\tbest: 255.2215233 (1100)\ttotal: 33.4s\tremaining: 1m 58s\n",
      "1200:\tlearn: 224.3073324\ttest: 253.9552654\tbest: 253.8640910 (1187)\ttotal: 36.3s\tremaining: 1m 54s\n",
      "1300:\tlearn: 222.1968410\ttest: 252.2086148\tbest: 252.1417981 (1295)\ttotal: 39.4s\tremaining: 1m 52s\n",
      "1400:\tlearn: 219.9957689\ttest: 251.0908929\tbest: 251.0849754 (1394)\ttotal: 42.8s\tremaining: 1m 50s\n",
      "1500:\tlearn: 219.1064993\ttest: 250.7258211\tbest: 250.6633738 (1483)\ttotal: 45.9s\tremaining: 1m 46s\n",
      "1600:\tlearn: 218.2063449\ttest: 250.5518201\tbest: 250.4070545 (1544)\ttotal: 48.8s\tremaining: 1m 43s\n",
      "1700:\tlearn: 215.9189496\ttest: 248.4624056\tbest: 248.4624056 (1700)\ttotal: 51.9s\tremaining: 1m 40s\n",
      "1800:\tlearn: 214.3818155\ttest: 248.2559152\tbest: 248.1500347 (1722)\ttotal: 54.8s\tremaining: 1m 37s\n",
      "1900:\tlearn: 211.5748796\ttest: 248.4643962\tbest: 247.6759775 (1839)\ttotal: 57.8s\tremaining: 1m 34s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 247.6759775\n",
      "bestIteration = 1839\n",
      "\n",
      "Shrink model to first 1840 iterations.",
      "\n",
      "0:\tlearn: 742.0857006\ttest: 739.0881685\tbest: 739.0881685 (0)\ttotal: 26.3ms\tremaining: 2m 11s\n",
      "100:\tlearn: 305.1974787\ttest: 321.7587715\tbest: 321.7587715 (100)\ttotal: 3.1s\tremaining: 2m 30s\n",
      "200:\tlearn: 281.0887488\ttest: 301.0779219\tbest: 300.6813192 (188)\ttotal: 6.04s\tremaining: 2m 24s\n",
      "300:\tlearn: 266.4617467\ttest: 293.3299233\tbest: 293.1544577 (297)\ttotal: 9.1s\tremaining: 2m 22s\n",
      "400:\tlearn: 256.2220123\ttest: 288.8743708\tbest: 288.3851095 (385)\ttotal: 12.1s\tremaining: 2m 19s\n",
      "500:\tlearn: 250.0632994\ttest: 285.1603968\tbest: 285.1554027 (498)\ttotal: 15.2s\tremaining: 2m 16s\n",
      "600:\tlearn: 244.9987087\ttest: 281.7664560\tbest: 281.7498104 (597)\ttotal: 18s\tremaining: 2m 11s\n",
      "700:\tlearn: 240.6285090\ttest: 278.5671377\tbest: 278.5671377 (700)\ttotal: 20.7s\tremaining: 2m 7s\n",
      "800:\tlearn: 235.4622463\ttest: 278.1715935\tbest: 277.4058770 (772)\ttotal: 23.7s\tremaining: 2m 4s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 277.405877\n",
      "bestIteration = 772\n",
      "\n",
      "Shrink model to first 773 iterations.",
      "\n",
      "0:\tlearn: 693.8569029\ttest: 756.2459034\tbest: 756.2459034 (0)\ttotal: 27.1ms\tremaining: 2m 15s\n",
      "100:\tlearn: 301.7232895\ttest: 328.4686766\tbest: 328.4686766 (100)\ttotal: 2.9s\tremaining: 2m 20s\n",
      "200:\tlearn: 280.8549024\ttest: 310.0280370\tbest: 309.9639010 (194)\ttotal: 5.5s\tremaining: 2m 11s\n",
      "300:\tlearn: 265.4277338\ttest: 301.0088416\tbest: 300.8814639 (299)\ttotal: 8.2s\tremaining: 2m 7s\n",
      "400:\tlearn: 259.3208925\ttest: 297.7869684\tbest: 297.6918215 (392)\ttotal: 10.7s\tremaining: 2m 2s\n",
      "500:\tlearn: 254.9689432\ttest: 295.9468518\tbest: 295.2392101 (475)\ttotal: 13.2s\tremaining: 1m 58s\n",
      "600:\tlearn: 249.0963754\ttest: 292.0522461\tbest: 292.0522461 (600)\ttotal: 15.9s\tremaining: 1m 56s\n",
      "700:\tlearn: 244.2046979\ttest: 289.5406650\tbest: 289.5406650 (700)\ttotal: 18.6s\tremaining: 1m 54s\n",
      "800:\tlearn: 240.3274621\ttest: 286.5888380\tbest: 286.5675980 (794)\ttotal: 21.2s\tremaining: 1m 51s\n",
      "900:\tlearn: 237.9434610\ttest: 284.7026567\tbest: 284.5298331 (889)\ttotal: 24s\tremaining: 1m 49s\n",
      "1000:\tlearn: 235.8477833\ttest: 283.8424496\tbest: 283.7923771 (994)\ttotal: 26.9s\tremaining: 1m 47s\n",
      "1100:\tlearn: 234.2330067\ttest: 283.2864964\tbest: 283.2615171 (1079)\ttotal: 29.5s\tremaining: 1m 44s\n",
      "1200:\tlearn: 231.4174135\ttest: 282.8636081\tbest: 282.8636081 (1200)\ttotal: 32.3s\tremaining: 1m 42s\n",
      "1300:\tlearn: 229.2438066\ttest: 281.2743049\tbest: 281.1901339 (1280)\ttotal: 34.9s\tremaining: 1m 39s\n",
      "1400:\tlearn: 228.0724302\ttest: 280.7589550\tbest: 280.7361982 (1362)\ttotal: 37.4s\tremaining: 1m 36s\n",
      "1500:\tlearn: 227.4666052\ttest: 280.5392704\tbest: 280.5392704 (1500)\ttotal: 40s\tremaining: 1m 33s\n",
      "1600:\tlearn: 226.0834477\ttest: 279.0413384\tbest: 278.9013935 (1590)\ttotal: 42.9s\tremaining: 1m 31s\n",
      "1700:\tlearn: 223.9521472\ttest: 277.5898008\tbest: 277.5898008 (1700)\ttotal: 45.7s\tremaining: 1m 28s\n",
      "1800:\tlearn: 221.8701887\ttest: 277.1801738\tbest: 276.9677073 (1721)\ttotal: 48.5s\tremaining: 1m 26s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 276.9677073\n",
      "bestIteration = 1721\n",
      "\n",
      "Shrink model to first 1722 iterations.",
      "\n",
      "0:\tlearn: 750.5013295\ttest: 698.0333300\tbest: 698.0333300 (0)\ttotal: 28.3ms\tremaining: 2m 21s\n",
      "100:\tlearn: 291.2973832\ttest: 299.7078065\tbest: 299.1914007 (96)\ttotal: 3.15s\tremaining: 2m 32s\n",
      "200:\tlearn: 272.9789043\ttest: 290.4815531\tbest: 290.4815531 (200)\ttotal: 6.29s\tremaining: 2m 30s\n",
      "300:\tlearn: 257.7433887\ttest: 285.5564211\tbest: 285.4526860 (299)\ttotal: 9.22s\tremaining: 2m 24s\n",
      "400:\tlearn: 247.5554524\ttest: 281.3801260\tbest: 281.3801260 (400)\ttotal: 12.2s\tremaining: 2m 19s\n",
      "500:\tlearn: 240.9918871\ttest: 276.7451268\tbest: 276.3898683 (468)\ttotal: 15.3s\tremaining: 2m 17s\n",
      "600:\tlearn: 234.8910199\ttest: 272.6256615\tbest: 272.5976224 (597)\ttotal: 18.3s\tremaining: 2m 14s\n",
      "700:\tlearn: 230.5205425\ttest: 270.7314160\tbest: 270.4959766 (678)\ttotal: 21.3s\tremaining: 2m 10s\n",
      "800:\tlearn: 226.6553943\ttest: 269.5562523\tbest: 269.5035608 (796)\ttotal: 24.3s\tremaining: 2m 7s\n",
      "900:\tlearn: 223.7997830\ttest: 268.3040181\tbest: 268.3019612 (897)\ttotal: 27.3s\tremaining: 2m 4s\n",
      "1000:\tlearn: 220.9986517\ttest: 267.2742069\tbest: 266.9996812 (950)\ttotal: 30.4s\tremaining: 2m 1s\n",
      "1100:\tlearn: 218.4907357\ttest: 265.6828544\tbest: 265.6701456 (1096)\ttotal: 33.5s\tremaining: 1m 58s\n",
      "1200:\tlearn: 216.5310195\ttest: 264.2787122\tbest: 264.2666834 (1153)\ttotal: 36.6s\tremaining: 1m 55s\n",
      "1300:\tlearn: 215.1697555\ttest: 263.5800808\tbest: 263.4842743 (1248)\ttotal: 39.8s\tremaining: 1m 53s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 263.4842743\n",
      "bestIteration = 1248\n",
      "\n",
      "Shrink model to first 1249 iterations.",
      "\n",
      "0:\tlearn: 732.2625988\ttest: 778.9333055\tbest: 778.9333055 (0)\ttotal: 27ms\tremaining: 2m 15s\n",
      "100:\tlearn: 303.6212224\ttest: 312.9532382\tbest: 312.9532382 (100)\ttotal: 2.96s\tremaining: 2m 23s\n",
      "200:\tlearn: 269.2279823\ttest: 293.4458083\tbest: 293.4072517 (196)\ttotal: 6.18s\tremaining: 2m 27s\n",
      "300:\tlearn: 258.2845358\ttest: 289.4482078\tbest: 289.3762721 (298)\ttotal: 9.36s\tremaining: 2m 26s\n",
      "400:\tlearn: 250.5382847\ttest: 285.2090335\tbest: 285.2040010 (393)\ttotal: 13.1s\tremaining: 2m 30s\n",
      "500:\tlearn: 243.5946110\ttest: 282.4017578\tbest: 282.4017578 (500)\ttotal: 16.4s\tremaining: 2m 27s\n",
      "600:\tlearn: 239.1385028\ttest: 279.6253212\tbest: 278.5859485 (559)\ttotal: 19.9s\tremaining: 2m 25s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 278.5859485\n",
      "bestIteration = 559\n",
      "\n",
      "Shrink model to first 560 iterations.",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "ctb_model = CatBoostRegressor(iterations=5000,learning_rate=0.5)\n",
    "data_ctb, predict_label = get_predict_w(ctb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019,model_type='ctb')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "    adcode  carCommentVolum   label             model  newsReplyVolum  \\\n0   310000             11.0   292.0  3c974920a76ac9c1           106.0   \n1   530000             11.0   466.0  3c974920a76ac9c1           106.0   \n2   150000             11.0   257.0  3c974920a76ac9c1           106.0   \n3   110000             11.0   408.0  3c974920a76ac9c1           106.0   \n4   510000             11.0   610.0  3c974920a76ac9c1           106.0   \n5   340000             11.0   206.0  3c974920a76ac9c1           106.0   \n6   370000             11.0   503.0  3c974920a76ac9c1           106.0   \n7   140000             11.0   236.0  3c974920a76ac9c1           106.0   \n8   440000             11.0  3635.0  3c974920a76ac9c1           106.0   \n9   450000             11.0   450.0  3c974920a76ac9c1           106.0   \n10  320000             11.0   876.0  3c974920a76ac9c1           106.0   \n11  360000             11.0   253.0  3c974920a76ac9c1           106.0   \n12  130000             11.0   306.0  3c974920a76ac9c1           106.0   \n13  410000             11.0   537.0  3c974920a76ac9c1           106.0   \n14  330000             11.0   650.0  3c974920a76ac9c1           106.0   \n15  420000             11.0   635.0  3c974920a76ac9c1           106.0   \n16  430000             11.0   525.0  3c974920a76ac9c1           106.0   \n17  350000             11.0   462.0  3c974920a76ac9c1           106.0   \n18  210000             11.0   791.0  3c974920a76ac9c1           106.0   \n19  500000             11.0   195.0  3c974920a76ac9c1           106.0   \n\n    popularity  predict_label  regMonth  regYear  sample_weight  \n0       1479.0     278.610586         1     2016              1  \n1       1594.0     328.278765         1     2016              1  \n2       1479.0     336.770168         1     2016              1  \n3       2370.0     416.279245         1     2016              1  \n4       3562.0     644.360352         1     2016              1  \n5       1314.0     307.790797         1     2016              1  \n6       3476.0     851.798713         1     2016              1  \n7       1422.0     223.184129         1     2016              1  \n8       7182.0    3049.835593         1     2016              1  \n9       1163.0     477.047839         1     2016              1  \n10      3670.0    1342.472233         1     2016              1  \n11       926.0     210.288155         1     2016              1  \n12      2973.0     371.898160         1     2016              1  \n13      3483.0     688.713574         1     2016              1  \n14      3167.0     845.431000         1     2016              1  \n15      2190.0     812.153552         1     2016              1  \n16      1666.0     445.542623         1     2016              1  \n17      1357.0     375.553946         1     2016              1  \n18      2808.0    1096.617961         1     2016              1  \n19       682.0     118.094306         1     2016              1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>adcode</th>\n      <th>carCommentVolum</th>\n      <th>label</th>\n      <th>model</th>\n      <th>newsReplyVolum</th>\n      <th>popularity</th>\n      <th>predict_label</th>\n      <th>regMonth</th>\n      <th>regYear</th>\n      <th>sample_weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310000</td>\n      <td>11.0</td>\n      <td>292.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1479.0</td>\n      <td>278.610586</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>530000</td>\n      <td>11.0</td>\n      <td>466.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1594.0</td>\n      <td>328.278765</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150000</td>\n      <td>11.0</td>\n      <td>257.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1479.0</td>\n      <td>336.770168</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>110000</td>\n      <td>11.0</td>\n      <td>408.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2370.0</td>\n      <td>416.279245</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>510000</td>\n      <td>11.0</td>\n      <td>610.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3562.0</td>\n      <td>644.360352</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>340000</td>\n      <td>11.0</td>\n      <td>206.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1314.0</td>\n      <td>307.790797</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>370000</td>\n      <td>11.0</td>\n      <td>503.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3476.0</td>\n      <td>851.798713</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>140000</td>\n      <td>11.0</td>\n      <td>236.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1422.0</td>\n      <td>223.184129</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>440000</td>\n      <td>11.0</td>\n      <td>3635.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>7182.0</td>\n      <td>3049.835593</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>450000</td>\n      <td>11.0</td>\n      <td>450.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1163.0</td>\n      <td>477.047839</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>320000</td>\n      <td>11.0</td>\n      <td>876.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3670.0</td>\n      <td>1342.472233</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>360000</td>\n      <td>11.0</td>\n      <td>253.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>926.0</td>\n      <td>210.288155</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>130000</td>\n      <td>11.0</td>\n      <td>306.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2973.0</td>\n      <td>371.898160</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>410000</td>\n      <td>11.0</td>\n      <td>537.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3483.0</td>\n      <td>688.713574</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>330000</td>\n      <td>11.0</td>\n      <td>650.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3167.0</td>\n      <td>845.431000</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>420000</td>\n      <td>11.0</td>\n      <td>635.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2190.0</td>\n      <td>812.153552</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>430000</td>\n      <td>11.0</td>\n      <td>525.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1666.0</td>\n      <td>445.542623</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>350000</td>\n      <td>11.0</td>\n      <td>462.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1357.0</td>\n      <td>375.553946</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>210000</td>\n      <td>11.0</td>\n      <td>791.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2808.0</td>\n      <td>1096.617961</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>500000</td>\n      <td>11.0</td>\n      <td>195.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>682.0</td>\n      <td>118.094306</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 21
    }
   ],
   "source": [
    "\n",
    "data_ctb.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'predict_label'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 24
    }
   ],
   "source": [
    "predict_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0:\tlearn: 634.9824646\ttest: 582.5155087\tbest: 582.5155087 (0)\ttotal: 28.1ms\tremaining: 2m 20s\n",
      "100:\tlearn: 299.0629869\ttest: 302.5374598\tbest: 302.5374598 (100)\ttotal: 3.29s\tremaining: 2m 39s\n",
      "200:\tlearn: 277.4907939\ttest: 289.3109838\tbest: 289.0505088 (198)\ttotal: 6.47s\tremaining: 2m 34s\n",
      "300:\tlearn: 264.2614407\ttest: 280.9830991\tbest: 280.9830991 (300)\ttotal: 9.65s\tremaining: 2m 30s\n",
      "400:\tlearn: 256.1606035\ttest: 276.7250955\tbest: 276.5731914 (393)\ttotal: 12.6s\tremaining: 2m 24s\n",
      "500:\tlearn: 248.3319309\ttest: 273.8249722\tbest: 273.8249722 (500)\ttotal: 15.7s\tremaining: 2m 20s\n",
      "600:\tlearn: 244.9248474\ttest: 272.3291910\tbest: 271.9952956 (585)\ttotal: 19s\tremaining: 2m 18s\n",
      "700:\tlearn: 239.3857882\ttest: 269.2608605\tbest: 268.8302737 (677)\ttotal: 22s\tremaining: 2m 14s\n",
      "800:\tlearn: 236.4137937\ttest: 265.9622649\tbest: 265.9622649 (800)\ttotal: 25.1s\tremaining: 2m 11s\n",
      "900:\tlearn: 233.2140266\ttest: 265.4514646\tbest: 265.3418334 (880)\ttotal: 28.1s\tremaining: 2m 7s\n",
      "1000:\tlearn: 230.1258587\ttest: 263.4460521\tbest: 263.2980725 (975)\ttotal: 31.1s\tremaining: 2m 4s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 263.2980725\n",
      "bestIteration = 975\n",
      "\n",
      "Shrink model to first 976 iterations.",
      "\n",
      "0:\tlearn: 677.0401635\ttest: 673.3765644\tbest: 673.3765644 (0)\ttotal: 27.1ms\tremaining: 2m 15s\n",
      "100:\tlearn: 298.2154454\ttest: 319.7986141\tbest: 319.7986141 (100)\ttotal: 3.16s\tremaining: 2m 33s\n",
      "200:\tlearn: 280.2123244\ttest: 312.5579463\tbest: 312.5579463 (200)\ttotal: 6.08s\tremaining: 2m 25s\n",
      "300:\tlearn: 269.3622694\ttest: 305.1357726\tbest: 305.1357726 (300)\ttotal: 9.02s\tremaining: 2m 20s\n",
      "400:\tlearn: 263.4205742\ttest: 303.2987490\tbest: 303.2987490 (400)\ttotal: 12.2s\tremaining: 2m 19s\n",
      "500:\tlearn: 255.4199882\ttest: 297.4441887\tbest: 297.4441887 (500)\ttotal: 15.1s\tremaining: 2m 15s\n",
      "600:\tlearn: 251.5889175\ttest: 293.1501006\tbest: 293.0942778 (597)\ttotal: 17.9s\tremaining: 2m 11s\n",
      "700:\tlearn: 246.1463927\ttest: 291.3759446\tbest: 291.3195860 (693)\ttotal: 21.2s\tremaining: 2m 10s\n",
      "800:\tlearn: 242.0664100\ttest: 290.9343636\tbest: 290.1592506 (768)\ttotal: 24.3s\tremaining: 2m 7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 290.1592506\n",
      "bestIteration = 768\n",
      "\n",
      "Shrink model to first 769 iterations.",
      "\n",
      "0:\tlearn: 615.3722950\ttest: 677.3276751\tbest: 677.3276751 (0)\ttotal: 27.6ms\tremaining: 2m 17s\n",
      "100:\tlearn: 306.8245798\ttest: 333.0806962\tbest: 333.0806962 (100)\ttotal: 3.03s\tremaining: 2m 26s\n",
      "200:\tlearn: 283.9769833\ttest: 321.9611036\tbest: 321.9611036 (200)\ttotal: 5.73s\tremaining: 2m 16s\n",
      "300:\tlearn: 275.8429668\ttest: 315.0348874\tbest: 315.0348874 (300)\ttotal: 8.46s\tremaining: 2m 12s\n",
      "400:\tlearn: 269.3663389\ttest: 311.4986907\tbest: 311.4986907 (400)\ttotal: 11.1s\tremaining: 2m 7s\n",
      "500:\tlearn: 261.4718645\ttest: 306.3029694\tbest: 306.1182683 (495)\ttotal: 14s\tremaining: 2m 5s\n",
      "600:\tlearn: 258.0005886\ttest: 305.2147483\tbest: 304.0714158 (593)\ttotal: 16.7s\tremaining: 2m 2s\n",
      "700:\tlearn: 254.0869668\ttest: 302.0206352\tbest: 301.9728890 (695)\ttotal: 19.3s\tremaining: 1m 58s\n",
      "800:\tlearn: 249.8412225\ttest: 300.1697234\tbest: 299.9597671 (791)\ttotal: 22.1s\tremaining: 1m 56s\n",
      "900:\tlearn: 247.1588931\ttest: 300.2745812\tbest: 299.9099479 (871)\ttotal: 24.9s\tremaining: 1m 53s\n",
      "1000:\tlearn: 242.4223949\ttest: 296.4676302\tbest: 296.4676302 (1000)\ttotal: 27.9s\tremaining: 1m 51s\n",
      "1100:\tlearn: 239.8240661\ttest: 295.3725731\tbest: 295.3725731 (1100)\ttotal: 30.7s\tremaining: 1m 48s\n",
      "1200:\tlearn: 237.1216060\ttest: 294.4051464\tbest: 294.1281171 (1180)\ttotal: 33.6s\tremaining: 1m 46s\n",
      "1300:\tlearn: 233.1622810\ttest: 292.9414257\tbest: 292.9412198 (1298)\ttotal: 36.7s\tremaining: 1m 44s\n",
      "1400:\tlearn: 229.5182248\ttest: 290.8416900\tbest: 290.8102153 (1396)\ttotal: 39.7s\tremaining: 1m 42s\n",
      "1500:\tlearn: 226.3789229\ttest: 288.7104756\tbest: 288.6900048 (1492)\ttotal: 42.9s\tremaining: 1m 39s\n",
      "1600:\tlearn: 224.7444062\ttest: 287.7768626\tbest: 287.7768626 (1600)\ttotal: 45.9s\tremaining: 1m 37s\n",
      "1700:\tlearn: 222.7081978\ttest: 285.8499417\tbest: 285.8499417 (1700)\ttotal: 49.1s\tremaining: 1m 35s\n",
      "1800:\tlearn: 220.4928603\ttest: 284.5310136\tbest: 284.4873038 (1781)\ttotal: 52.3s\tremaining: 1m 32s\n",
      "1900:\tlearn: 218.9364406\ttest: 283.8560293\tbest: 283.8176385 (1894)\ttotal: 55.3s\tremaining: 1m 30s\n",
      "2000:\tlearn: 216.4949053\ttest: 282.1944852\tbest: 282.1833955 (1994)\ttotal: 58.5s\tremaining: 1m 27s\n",
      "2100:\tlearn: 214.9811239\ttest: 281.0691640\tbest: 281.0293595 (2099)\ttotal: 1m 1s\tremaining: 1m 25s\n",
      "2200:\tlearn: 212.1234116\ttest: 279.9469928\tbest: 279.7938945 (2198)\ttotal: 1m 4s\tremaining: 1m 22s\n",
      "2300:\tlearn: 210.7248790\ttest: 279.0900169\tbest: 279.0826168 (2299)\ttotal: 1m 7s\tremaining: 1m 19s\n",
      "2400:\tlearn: 208.9765044\ttest: 278.2819088\tbest: 278.2017950 (2386)\ttotal: 1m 10s\tremaining: 1m 16s\n",
      "2500:\tlearn: 206.8092046\ttest: 278.1183324\tbest: 278.0414989 (2483)\ttotal: 1m 13s\tremaining: 1m 13s\n",
      "2600:\tlearn: 205.6527954\ttest: 277.8005484\tbest: 277.6398516 (2547)\ttotal: 1m 17s\tremaining: 1m 11s\n",
      "2700:\tlearn: 204.0841654\ttest: 277.1259669\tbest: 277.0731867 (2665)\ttotal: 1m 20s\tremaining: 1m 8s\n",
      "2800:\tlearn: 202.7359472\ttest: 277.0954203\tbest: 276.6054220 (2766)\ttotal: 1m 23s\tremaining: 1m 5s\n",
      "2900:\tlearn: 201.2403936\ttest: 275.9121541\tbest: 275.8733556 (2886)\ttotal: 1m 25s\tremaining: 1m 2s\n",
      "3000:\tlearn: 200.3500794\ttest: 275.4544406\tbest: 275.4544406 (3000)\ttotal: 1m 29s\tremaining: 59.3s\n",
      "3100:\tlearn: 199.5026027\ttest: 274.6582001\tbest: 274.6131370 (3093)\ttotal: 1m 32s\tremaining: 56.4s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 274.613137\n",
      "bestIteration = 3093\n",
      "\n",
      "Shrink model to first 3094 iterations.",
      "\n",
      "0:\tlearn: 685.5554032\ttest: 634.2207630\tbest: 634.2207630 (0)\ttotal: 27.2ms\tremaining: 2m 15s\n",
      "100:\tlearn: 306.5159111\ttest: 314.1380639\tbest: 314.1380639 (100)\ttotal: 3.11s\tremaining: 2m 30s\n",
      "200:\tlearn: 284.2242270\ttest: 302.7333680\tbest: 302.7333680 (200)\ttotal: 6.08s\tremaining: 2m 25s\n",
      "300:\tlearn: 264.6378580\ttest: 292.3518006\tbest: 291.9233919 (290)\ttotal: 9.17s\tremaining: 2m 23s\n",
      "400:\tlearn: 256.6969762\ttest: 286.7413850\tbest: 286.6998148 (391)\ttotal: 12.1s\tremaining: 2m 18s\n",
      "500:\tlearn: 248.4513802\ttest: 282.6047360\tbest: 282.6047360 (500)\ttotal: 15.2s\tremaining: 2m 16s\n",
      "600:\tlearn: 241.6568108\ttest: 278.3801012\tbest: 278.3801012 (600)\ttotal: 18.2s\tremaining: 2m 13s\n",
      "700:\tlearn: 237.9913845\ttest: 278.3807674\tbest: 277.9820667 (621)\ttotal: 20.9s\tremaining: 2m 8s\n",
      "800:\tlearn: 234.9521160\ttest: 275.9602697\tbest: 275.9602697 (800)\ttotal: 24s\tremaining: 2m 5s\n",
      "900:\tlearn: 230.7727173\ttest: 274.7854351\tbest: 274.4699122 (815)\ttotal: 27s\tremaining: 2m 2s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 274.4699122\n",
      "bestIteration = 815\n",
      "\n",
      "Shrink model to first 816 iterations.",
      "\n",
      "0:\tlearn: 667.0921642\ttest: 712.8653692\tbest: 712.8653692 (0)\ttotal: 27.5ms\tremaining: 2m 17s\n",
      "100:\tlearn: 303.1462687\ttest: 309.9239159\tbest: 309.5894105 (95)\ttotal: 3.07s\tremaining: 2m 28s\n",
      "200:\tlearn: 280.4147057\ttest: 298.6645932\tbest: 298.6645932 (200)\ttotal: 5.96s\tremaining: 2m 22s\n",
      "300:\tlearn: 264.1806767\ttest: 290.2859044\tbest: 290.2859044 (300)\ttotal: 8.94s\tremaining: 2m 19s\n",
      "400:\tlearn: 251.7614231\ttest: 284.4386880\tbest: 284.3452786 (399)\ttotal: 12.1s\tremaining: 2m 18s\n",
      "500:\tlearn: 242.8297836\ttest: 279.4350554\tbest: 279.4350554 (500)\ttotal: 15.5s\tremaining: 2m 18s\n",
      "600:\tlearn: 234.5821087\ttest: 275.3635937\tbest: 275.3635937 (600)\ttotal: 18.5s\tremaining: 2m 15s\n",
      "700:\tlearn: 230.9683208\ttest: 274.9585236\tbest: 274.0387057 (665)\ttotal: 21.5s\tremaining: 2m 11s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 274.0387057\n",
      "bestIteration = 665\n",
      "\n",
      "Shrink model to first 666 iterations.",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "ctb_model = CatBoostRegressor(iterations=5000,learning_rate=0.7,loss_function=\"RMSE\")\n",
    "data_ctb, predict_label = get_predict_w(ctb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019,model_type='ctb')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0:\tlearn: 904.3979866\ttest: 851.7783514\tbest: 851.7783514 (0)\ttotal: 27.2ms\tremaining: 2m 16s\n",
      "100:\tlearn: 331.0171173\ttest: 312.0127987\tbest: 312.0127987 (100)\ttotal: 3.23s\tremaining: 2m 36s\n",
      "200:\tlearn: 302.2514983\ttest: 290.7868178\tbest: 290.7868178 (200)\ttotal: 6.29s\tremaining: 2m 30s\n",
      "300:\tlearn: 289.6024343\ttest: 283.0084528\tbest: 283.0084528 (300)\ttotal: 9.06s\tremaining: 2m 21s\n",
      "400:\tlearn: 278.5744090\ttest: 275.6575401\tbest: 275.6549918 (399)\ttotal: 12.1s\tremaining: 2m 19s\n",
      "500:\tlearn: 270.8127408\ttest: 270.5724197\tbest: 270.5724197 (500)\ttotal: 15.2s\tremaining: 2m 16s\n",
      "600:\tlearn: 265.9440541\ttest: 266.8965452\tbest: 266.8965452 (600)\ttotal: 18.5s\tremaining: 2m 15s\n",
      "700:\tlearn: 261.8081536\ttest: 264.2594461\tbest: 264.2541673 (697)\ttotal: 21.3s\tremaining: 2m 10s\n",
      "800:\tlearn: 256.3995947\ttest: 259.4613957\tbest: 259.4613957 (800)\ttotal: 24.3s\tremaining: 2m 7s\n",
      "900:\tlearn: 252.2560722\ttest: 257.4346552\tbest: 257.3799495 (896)\ttotal: 27.2s\tremaining: 2m 3s\n",
      "1000:\tlearn: 249.2784578\ttest: 255.2365958\tbest: 255.2046697 (999)\ttotal: 30s\tremaining: 1m 59s\n",
      "1100:\tlearn: 247.3129063\ttest: 253.9572613\tbest: 253.9572613 (1100)\ttotal: 32.5s\tremaining: 1m 54s\n",
      "1200:\tlearn: 245.1210537\ttest: 252.6212310\tbest: 252.6212310 (1200)\ttotal: 35.1s\tremaining: 1m 51s\n",
      "1300:\tlearn: 243.1643926\ttest: 251.4500906\tbest: 251.4498166 (1296)\ttotal: 38s\tremaining: 1m 47s\n",
      "1400:\tlearn: 241.1809637\ttest: 249.8545387\tbest: 249.8545387 (1400)\ttotal: 40.7s\tremaining: 1m 44s\n",
      "1500:\tlearn: 240.0350214\ttest: 248.9634105\tbest: 248.7928767 (1453)\ttotal: 43.8s\tremaining: 1m 42s\n",
      "1600:\tlearn: 238.0043452\ttest: 248.0433554\tbest: 248.0433554 (1600)\ttotal: 46.8s\tremaining: 1m 39s\n",
      "1700:\tlearn: 236.3731822\ttest: 247.5662512\tbest: 247.5662512 (1700)\ttotal: 49.6s\tremaining: 1m 36s\n",
      "1800:\tlearn: 234.7235144\ttest: 246.7193221\tbest: 246.7193221 (1800)\ttotal: 52.3s\tremaining: 1m 32s\n",
      "1900:\tlearn: 233.3806841\ttest: 245.8497627\tbest: 245.8367738 (1888)\ttotal: 55.1s\tremaining: 1m 29s\n",
      "2000:\tlearn: 232.3397566\ttest: 245.1589552\tbest: 245.1589552 (2000)\ttotal: 57.8s\tremaining: 1m 26s\n",
      "2100:\tlearn: 231.0662249\ttest: 244.3021863\tbest: 244.2811870 (2078)\ttotal: 1m\tremaining: 1m 23s\n",
      "2200:\tlearn: 229.1352259\ttest: 243.4522211\tbest: 243.4522211 (2200)\ttotal: 1m 3s\tremaining: 1m 21s\n",
      "2300:\tlearn: 226.4452133\ttest: 241.7891251\tbest: 241.7452981 (2294)\ttotal: 1m 6s\tremaining: 1m 18s\n",
      "2400:\tlearn: 225.4992837\ttest: 240.9995798\tbest: 240.9954933 (2395)\ttotal: 1m 9s\tremaining: 1m 15s\n",
      "2500:\tlearn: 224.4529079\ttest: 240.4204293\tbest: 240.4204293 (2500)\ttotal: 1m 12s\tremaining: 1m 12s\n",
      "2600:\tlearn: 223.9420425\ttest: 240.1877106\tbest: 240.1877106 (2600)\ttotal: 1m 15s\tremaining: 1m 10s\n",
      "2700:\tlearn: 223.5540741\ttest: 240.0191343\tbest: 239.9485000 (2666)\ttotal: 1m 18s\tremaining: 1m 7s\n",
      "2800:\tlearn: 222.7323095\ttest: 239.6349480\tbest: 239.6240125 (2796)\ttotal: 1m 21s\tremaining: 1m 4s\n",
      "2900:\tlearn: 221.8230292\ttest: 239.3695240\tbest: 239.3695216 (2899)\ttotal: 1m 24s\tremaining: 1m 1s\n",
      "3000:\tlearn: 221.6013511\ttest: 239.3436400\tbest: 239.3029464 (2966)\ttotal: 1m 27s\tremaining: 58.3s\n",
      "3100:\tlearn: 220.1025916\ttest: 238.4493974\tbest: 238.3909049 (3097)\ttotal: 1m 30s\tremaining: 55.5s\n",
      "3200:\tlearn: 219.4690331\ttest: 237.8938166\tbest: 237.8938166 (3200)\ttotal: 1m 33s\tremaining: 52.6s\n",
      "3300:\tlearn: 218.6489217\ttest: 237.0164762\tbest: 237.0164762 (3300)\ttotal: 1m 36s\tremaining: 49.7s\n",
      "3400:\tlearn: 217.6102017\ttest: 236.3728161\tbest: 236.3715909 (3399)\ttotal: 1m 39s\tremaining: 46.8s\n",
      "3500:\tlearn: 217.1033820\ttest: 236.1655729\tbest: 236.1526216 (3483)\ttotal: 1m 42s\tremaining: 43.9s\n",
      "3600:\tlearn: 216.3050620\ttest: 235.5656455\tbest: 235.5656455 (3600)\ttotal: 1m 45s\tremaining: 41s\n",
      "3700:\tlearn: 215.6273544\ttest: 235.0502747\tbest: 235.0232369 (3664)\ttotal: 1m 48s\tremaining: 38.1s\n",
      "3800:\tlearn: 215.0426237\ttest: 234.7235215\tbest: 234.7234547 (3799)\ttotal: 1m 51s\tremaining: 35.2s\n",
      "3900:\tlearn: 214.5556463\ttest: 234.5125613\tbest: 234.4939514 (3881)\ttotal: 1m 54s\tremaining: 32.3s\n",
      "4000:\tlearn: 214.1915527\ttest: 234.3480503\tbest: 234.3156367 (3993)\ttotal: 1m 57s\tremaining: 29.3s\n",
      "4100:\tlearn: 213.3127649\ttest: 233.7324755\tbest: 233.7324755 (4100)\ttotal: 2m\tremaining: 26.4s\n",
      "4200:\tlearn: 212.8426374\ttest: 233.4880312\tbest: 233.4859189 (4197)\ttotal: 2m 3s\tremaining: 23.5s\n",
      "4300:\tlearn: 212.0748758\ttest: 232.9852616\tbest: 232.9849894 (4298)\ttotal: 2m 6s\tremaining: 20.6s\n",
      "4400:\tlearn: 211.8208647\ttest: 232.8653731\tbest: 232.8606722 (4396)\ttotal: 2m 9s\tremaining: 17.6s\n",
      "4500:\tlearn: 211.4976390\ttest: 232.5170215\tbest: 232.5091804 (4491)\ttotal: 2m 12s\tremaining: 14.6s\n",
      "4600:\tlearn: 210.6917754\ttest: 232.0746962\tbest: 232.0746962 (4600)\ttotal: 2m 15s\tremaining: 11.7s\n",
      "4700:\tlearn: 210.1194987\ttest: 231.7021650\tbest: 231.7021650 (4700)\ttotal: 2m 17s\tremaining: 8.77s\n",
      "4800:\tlearn: 209.1166051\ttest: 230.7081168\tbest: 230.6836386 (4794)\ttotal: 2m 20s\tremaining: 5.84s\n",
      "4900:\tlearn: 208.6406800\ttest: 230.4589685\tbest: 230.4577475 (4898)\ttotal: 2m 23s\tremaining: 2.9s\n",
      "4999:\tlearn: 208.1186744\ttest: 230.0840269\tbest: 230.0699658 (4995)\ttotal: 2m 26s\tremaining: 0us\n",
      "\n",
      "bestTest = 230.0699658\n",
      "bestIteration = 4995\n",
      "\n",
      "Shrink model to first 4996 iterations.",
      "\n",
      "0:\tlearn: 905.9369030\ttest: 903.0368259\tbest: 903.0368259 (0)\ttotal: 25.7ms\tremaining: 2m 8s\n",
      "100:\tlearn: 338.8284558\ttest: 350.3243368\tbest: 350.3243368 (100)\ttotal: 3.22s\tremaining: 2m 36s\n",
      "200:\tlearn: 299.1988448\ttest: 310.9324809\tbest: 310.9324809 (200)\ttotal: 6.1s\tremaining: 2m 25s\n",
      "300:\tlearn: 283.7420702\ttest: 298.5784718\tbest: 298.5128446 (289)\ttotal: 8.88s\tremaining: 2m 18s\n",
      "400:\tlearn: 275.2059155\ttest: 292.8936991\tbest: 292.8936991 (400)\ttotal: 11.7s\tremaining: 2m 14s\n",
      "500:\tlearn: 268.2994025\ttest: 287.5356489\tbest: 287.5356489 (500)\ttotal: 14.7s\tremaining: 2m 11s\n",
      "600:\tlearn: 259.3465543\ttest: 280.8358050\tbest: 280.8315813 (596)\ttotal: 17.8s\tremaining: 2m 10s\n",
      "700:\tlearn: 254.5309121\ttest: 277.2260392\tbest: 277.1879964 (692)\ttotal: 20.7s\tremaining: 2m 7s\n",
      "800:\tlearn: 250.5647814\ttest: 274.4840733\tbest: 274.4675331 (794)\ttotal: 23.4s\tremaining: 2m 2s\n",
      "900:\tlearn: 246.2050093\ttest: 270.9279777\tbest: 270.8227621 (898)\ttotal: 26.4s\tremaining: 1m 59s\n",
      "1000:\tlearn: 242.4956655\ttest: 269.0125386\tbest: 269.0125386 (1000)\ttotal: 29.3s\tremaining: 1m 56s\n",
      "1100:\tlearn: 238.9762661\ttest: 266.4865939\tbest: 266.4822407 (1099)\ttotal: 32.2s\tremaining: 1m 54s\n",
      "1200:\tlearn: 236.3858707\ttest: 264.5147054\tbest: 264.5147054 (1200)\ttotal: 35s\tremaining: 1m 50s\n",
      "1300:\tlearn: 233.6930420\ttest: 261.7809357\tbest: 261.7809357 (1300)\ttotal: 37.9s\tremaining: 1m 47s\n",
      "1400:\tlearn: 231.5243392\ttest: 260.9466051\tbest: 260.9466051 (1400)\ttotal: 40.7s\tremaining: 1m 44s\n",
      "1500:\tlearn: 229.6940944\ttest: 259.8786184\tbest: 259.8786184 (1500)\ttotal: 43.6s\tremaining: 1m 41s\n",
      "1600:\tlearn: 228.7172766\ttest: 259.5333056\tbest: 259.5286326 (1594)\ttotal: 46.5s\tremaining: 1m 38s\n",
      "1700:\tlearn: 228.2434316\ttest: 259.4134249\tbest: 259.4055301 (1695)\ttotal: 49.2s\tremaining: 1m 35s\n",
      "1800:\tlearn: 226.5754801\ttest: 258.1835714\tbest: 258.1733916 (1799)\ttotal: 52.4s\tremaining: 1m 33s\n",
      "1900:\tlearn: 226.0236488\ttest: 257.8464464\tbest: 257.8390779 (1880)\ttotal: 55.1s\tremaining: 1m 29s\n",
      "2000:\tlearn: 225.1678973\ttest: 257.6859753\tbest: 257.6542912 (1936)\ttotal: 57.8s\tremaining: 1m 26s\n",
      "2100:\tlearn: 224.3678363\ttest: 257.0554187\tbest: 257.0544465 (2099)\ttotal: 1m\tremaining: 1m 23s\n",
      "2200:\tlearn: 223.5708374\ttest: 256.8194079\tbest: 256.7863470 (2176)\ttotal: 1m 3s\tremaining: 1m 20s\n",
      "2300:\tlearn: 222.6346220\ttest: 256.3994289\tbest: 256.3786963 (2295)\ttotal: 1m 6s\tremaining: 1m 17s\n",
      "2400:\tlearn: 221.9344736\ttest: 255.8293949\tbest: 255.8293949 (2400)\ttotal: 1m 9s\tremaining: 1m 14s\n",
      "2500:\tlearn: 220.5966061\ttest: 255.2160282\tbest: 255.2160282 (2500)\ttotal: 1m 11s\tremaining: 1m 11s\n",
      "2600:\tlearn: 219.2707524\ttest: 254.2691576\tbest: 254.2691576 (2600)\ttotal: 1m 14s\tremaining: 1m 9s\n",
      "2700:\tlearn: 218.0530857\ttest: 253.5706635\tbest: 253.5705065 (2699)\ttotal: 1m 17s\tremaining: 1m 6s\n",
      "2800:\tlearn: 217.5430567\ttest: 253.2186675\tbest: 253.2183803 (2798)\ttotal: 1m 20s\tremaining: 1m 3s\n",
      "2900:\tlearn: 216.7656162\ttest: 252.8207770\tbest: 252.8078515 (2875)\ttotal: 1m 23s\tremaining: 1m\n",
      "3000:\tlearn: 215.6242955\ttest: 251.9801775\tbest: 251.9620599 (2990)\ttotal: 1m 27s\tremaining: 58.1s\n",
      "3100:\tlearn: 214.8192676\ttest: 251.6626194\tbest: 251.6626194 (3100)\ttotal: 1m 30s\tremaining: 55.3s\n",
      "3200:\tlearn: 213.9475498\ttest: 251.2849689\tbest: 251.2827677 (3192)\ttotal: 1m 33s\tremaining: 52.4s\n",
      "3300:\tlearn: 213.5953655\ttest: 251.2403847\tbest: 251.2386949 (3299)\ttotal: 1m 35s\tremaining: 49.4s\n",
      "3400:\tlearn: 212.6067931\ttest: 250.5799149\tbest: 250.5785977 (3399)\ttotal: 1m 39s\tremaining: 46.5s\n",
      "3500:\tlearn: 211.7386032\ttest: 249.7624914\tbest: 249.7623546 (3498)\ttotal: 1m 41s\tremaining: 43.7s\n",
      "3600:\tlearn: 211.1501166\ttest: 249.6779756\tbest: 249.6436885 (3598)\ttotal: 1m 44s\tremaining: 40.8s\n",
      "3700:\tlearn: 209.9901084\ttest: 249.0009592\tbest: 249.0009592 (3700)\ttotal: 1m 48s\tremaining: 38s\n",
      "3800:\tlearn: 209.3976057\ttest: 248.6226552\tbest: 248.6182371 (3793)\ttotal: 1m 51s\tremaining: 35s\n",
      "3900:\tlearn: 208.7140745\ttest: 248.3089628\tbest: 248.2737954 (3898)\ttotal: 1m 53s\tremaining: 32s\n",
      "4000:\tlearn: 208.2321691\ttest: 248.1737592\tbest: 248.1321552 (3968)\ttotal: 1m 56s\tremaining: 29.2s\n",
      "4100:\tlearn: 208.0564958\ttest: 248.1250518\tbest: 248.1044005 (4054)\ttotal: 1m 59s\tremaining: 26.3s\n",
      "4200:\tlearn: 207.6170670\ttest: 247.7961616\tbest: 247.7961616 (4200)\ttotal: 2m 2s\tremaining: 23.4s\n",
      "4300:\tlearn: 207.2427405\ttest: 247.6327936\tbest: 247.6253938 (4293)\ttotal: 2m 5s\tremaining: 20.5s\n",
      "4400:\tlearn: 206.6408355\ttest: 247.2072229\tbest: 247.2072229 (4400)\ttotal: 2m 8s\tremaining: 17.5s\n",
      "4500:\tlearn: 206.2389087\ttest: 247.1245673\tbest: 247.1245673 (4500)\ttotal: 2m 11s\tremaining: 14.6s\n",
      "4600:\tlearn: 205.6815341\ttest: 246.8051663\tbest: 246.7447416 (4590)\ttotal: 2m 14s\tremaining: 11.7s\n",
      "4700:\tlearn: 204.8917667\ttest: 246.1926219\tbest: 246.1926219 (4700)\ttotal: 2m 17s\tremaining: 8.75s\n",
      "4800:\tlearn: 204.1391259\ttest: 245.8556288\tbest: 245.8509278 (4794)\ttotal: 2m 20s\tremaining: 5.83s\n",
      "4900:\tlearn: 203.7469262\ttest: 245.7254255\tbest: 245.7254255 (4900)\ttotal: 2m 23s\tremaining: 2.89s\n",
      "4999:\tlearn: 203.0588765\ttest: 245.5315141\tbest: 245.5315141 (4999)\ttotal: 2m 26s\tremaining: 0us\n",
      "\n",
      "bestTest = 245.5315141\n",
      "bestIteration = 4999\n",
      "\n",
      "0:\tlearn: 883.5421662\ttest: 941.2510320\tbest: 941.2510320 (0)\ttotal: 29.9ms\tremaining: 2m 29s\n",
      "100:\tlearn: 331.6585281\ttest: 349.3124958\tbest: 349.3124958 (100)\ttotal: 2.49s\tremaining: 2m\n",
      "200:\tlearn: 298.7388985\ttest: 314.6774943\tbest: 314.6774943 (200)\ttotal: 5.41s\tremaining: 2m 9s\n",
      "300:\tlearn: 284.8413471\ttest: 301.8574060\tbest: 301.8574060 (300)\ttotal: 8.35s\tremaining: 2m 10s\n",
      "400:\tlearn: 273.6672045\ttest: 292.5771236\tbest: 292.5771236 (400)\ttotal: 11.1s\tremaining: 2m 7s\n",
      "500:\tlearn: 267.2191603\ttest: 286.7181522\tbest: 286.7181522 (500)\ttotal: 13.9s\tremaining: 2m 4s\n",
      "600:\tlearn: 260.8929424\ttest: 282.7592734\tbest: 282.7404982 (582)\ttotal: 16.7s\tremaining: 2m 2s\n",
      "700:\tlearn: 257.4928248\ttest: 280.1999366\tbest: 280.1977862 (698)\ttotal: 19.4s\tremaining: 1m 59s\n",
      "800:\tlearn: 256.2696888\ttest: 279.3623889\tbest: 279.3623889 (800)\ttotal: 22.1s\tremaining: 1m 55s\n",
      "900:\tlearn: 252.0034732\ttest: 275.8060608\tbest: 275.8060608 (900)\ttotal: 24.9s\tremaining: 1m 53s\n",
      "1000:\tlearn: 249.8021440\ttest: 273.4226498\tbest: 273.4171373 (999)\ttotal: 27.6s\tremaining: 1m 50s\n",
      "1100:\tlearn: 248.6779503\ttest: 272.7726269\tbest: 272.7660969 (1097)\ttotal: 29.9s\tremaining: 1m 45s\n",
      "1200:\tlearn: 246.1439337\ttest: 270.8245226\tbest: 270.8225980 (1198)\ttotal: 32.3s\tremaining: 1m 42s\n",
      "1300:\tlearn: 242.9796799\ttest: 268.2015082\tbest: 268.1949304 (1295)\ttotal: 35s\tremaining: 1m 39s\n",
      "1400:\tlearn: 239.8664723\ttest: 265.6134444\tbest: 265.5989615 (1390)\ttotal: 37.9s\tremaining: 1m 37s\n",
      "1500:\tlearn: 237.8773587\ttest: 264.6695922\tbest: 264.6413673 (1486)\ttotal: 40.6s\tremaining: 1m 34s\n",
      "1600:\tlearn: 236.8017175\ttest: 263.8258555\tbest: 263.8084416 (1589)\ttotal: 43.1s\tremaining: 1m 31s\n",
      "1700:\tlearn: 233.9499827\ttest: 262.3336028\tbest: 262.3331376 (1699)\ttotal: 46s\tremaining: 1m 29s\n",
      "1800:\tlearn: 232.9156942\ttest: 261.6261847\tbest: 261.6248940 (1791)\ttotal: 48.6s\tremaining: 1m 26s\n",
      "1900:\tlearn: 231.5396015\ttest: 260.6960202\tbest: 260.6959068 (1892)\ttotal: 51s\tremaining: 1m 23s\n",
      "2000:\tlearn: 230.7739421\ttest: 260.3590095\tbest: 260.3586722 (1999)\ttotal: 53.6s\tremaining: 1m 20s\n",
      "2100:\tlearn: 230.1969248\ttest: 260.0863493\tbest: 260.0863493 (2100)\ttotal: 56.1s\tremaining: 1m 17s\n",
      "2200:\tlearn: 228.6668973\ttest: 259.5918315\tbest: 259.5592656 (2193)\ttotal: 58.8s\tremaining: 1m 14s\n",
      "2300:\tlearn: 227.8905589\ttest: 259.2375791\tbest: 259.2306949 (2278)\ttotal: 1m 1s\tremaining: 1m 11s\n",
      "2400:\tlearn: 226.9056177\ttest: 258.7257430\tbest: 258.6956472 (2377)\ttotal: 1m 3s\tremaining: 1m 9s\n",
      "2500:\tlearn: 224.9274252\ttest: 257.4993225\tbest: 257.4993225 (2500)\ttotal: 1m 6s\tremaining: 1m 6s\n",
      "2600:\tlearn: 223.8272338\ttest: 256.8915985\tbest: 256.8913863 (2598)\ttotal: 1m 9s\tremaining: 1m 4s\n",
      "2700:\tlearn: 222.5264423\ttest: 255.6559947\tbest: 255.6382694 (2682)\ttotal: 1m 11s\tremaining: 1m 1s\n",
      "2800:\tlearn: 221.7693316\ttest: 255.3344759\tbest: 255.3344759 (2800)\ttotal: 1m 14s\tremaining: 58.3s\n",
      "2900:\tlearn: 220.8322184\ttest: 254.7667418\tbest: 254.7667418 (2900)\ttotal: 1m 16s\tremaining: 55.7s\n",
      "3000:\tlearn: 220.2280835\ttest: 254.2054556\tbest: 254.1961005 (2981)\ttotal: 1m 19s\tremaining: 52.9s\n",
      "3100:\tlearn: 219.3496342\ttest: 253.5906313\tbest: 253.5906313 (3100)\ttotal: 1m 21s\tremaining: 50.2s\n",
      "3200:\tlearn: 218.6310668\ttest: 253.3162789\tbest: 253.3154452 (3199)\ttotal: 1m 24s\tremaining: 47.5s\n",
      "3300:\tlearn: 217.3751460\ttest: 252.7359834\tbest: 252.7359437 (3299)\ttotal: 1m 26s\tremaining: 44.7s\n",
      "3400:\tlearn: 216.4264267\ttest: 252.2651909\tbest: 252.1677338 (3368)\ttotal: 1m 29s\tremaining: 42.1s\n",
      "3500:\tlearn: 215.5324929\ttest: 251.6502223\tbest: 251.6502223 (3500)\ttotal: 1m 32s\tremaining: 39.5s\n",
      "3600:\tlearn: 215.1648042\ttest: 251.4120519\tbest: 251.3937106 (3589)\ttotal: 1m 35s\tremaining: 37.1s\n",
      "3700:\tlearn: 213.1108255\ttest: 249.5181568\tbest: 249.5181568 (3700)\ttotal: 1m 38s\tremaining: 34.6s\n",
      "3800:\tlearn: 212.0091352\ttest: 248.7415490\tbest: 248.7264590 (3778)\ttotal: 1m 41s\tremaining: 32s\n",
      "3900:\tlearn: 210.7732015\ttest: 248.2484884\tbest: 248.1776325 (3827)\ttotal: 1m 44s\tremaining: 29.4s\n",
      "4000:\tlearn: 209.4110582\ttest: 247.3885492\tbest: 247.3865102 (3999)\ttotal: 1m 47s\tremaining: 26.7s\n",
      "4100:\tlearn: 208.5743615\ttest: 246.6994624\tbest: 246.6786734 (4098)\ttotal: 1m 49s\tremaining: 24.1s\n",
      "4200:\tlearn: 207.6847442\ttest: 246.4613092\tbest: 246.4577186 (4196)\ttotal: 1m 52s\tremaining: 21.4s\n",
      "4300:\tlearn: 207.2309598\ttest: 246.3413665\tbest: 246.3413665 (4300)\ttotal: 1m 55s\tremaining: 18.8s\n",
      "4400:\tlearn: 207.0767726\ttest: 246.3970995\tbest: 246.3413655 (4301)\ttotal: 1m 57s\tremaining: 16s\n",
      "4500:\tlearn: 206.2880630\ttest: 245.8778954\tbest: 245.8589295 (4497)\ttotal: 2m\tremaining: 13.4s\n",
      "4600:\tlearn: 205.6479661\ttest: 245.3981189\tbest: 245.3980668 (4599)\ttotal: 2m 3s\tremaining: 10.7s\n",
      "4700:\tlearn: 204.6165650\ttest: 245.0146812\tbest: 245.0140132 (4699)\ttotal: 2m 6s\tremaining: 8.03s\n",
      "4800:\tlearn: 203.5903794\ttest: 244.1202585\tbest: 244.1177603 (4796)\ttotal: 2m 9s\tremaining: 5.35s\n",
      "4900:\tlearn: 202.8287465\ttest: 243.7248960\tbest: 243.7202217 (4896)\ttotal: 2m 11s\tremaining: 2.66s\n",
      "4999:\tlearn: 202.2907793\ttest: 243.5697398\tbest: 243.5685856 (4997)\ttotal: 2m 14s\tremaining: 0us\n",
      "\n",
      "bestTest = 243.5685856\n",
      "bestIteration = 4997\n",
      "\n",
      "Shrink model to first 4998 iterations.",
      "\n",
      "0:\tlearn: 914.4138657\ttest: 865.0566067\tbest: 865.0566067 (0)\ttotal: 30.1ms\tremaining: 2m 30s\n",
      "100:\tlearn: 329.4932713\ttest: 317.1183500\tbest: 317.1183500 (100)\ttotal: 3.34s\tremaining: 2m 42s\n",
      "200:\tlearn: 297.8531970\ttest: 295.5406710\tbest: 295.5207864 (199)\ttotal: 6.44s\tremaining: 2m 33s\n",
      "300:\tlearn: 284.4365256\ttest: 283.3120483\tbest: 283.3052346 (298)\ttotal: 9.26s\tremaining: 2m 24s\n",
      "400:\tlearn: 270.5650257\ttest: 273.7941693\tbest: 273.7941693 (400)\ttotal: 12.2s\tremaining: 2m 19s\n",
      "500:\tlearn: 262.8183914\ttest: 269.0337997\tbest: 269.0337997 (500)\ttotal: 15.3s\tremaining: 2m 17s\n",
      "600:\tlearn: 257.3660136\ttest: 265.7981711\tbest: 265.7902833 (599)\ttotal: 18.4s\tremaining: 2m 14s\n",
      "700:\tlearn: 250.2095213\ttest: 260.5618990\tbest: 260.5618990 (700)\ttotal: 21.6s\tremaining: 2m 12s\n",
      "800:\tlearn: 246.1335667\ttest: 258.2179947\tbest: 258.2179947 (800)\ttotal: 24.6s\tremaining: 2m 9s\n",
      "900:\tlearn: 241.4570469\ttest: 255.0753794\tbest: 255.0291703 (898)\ttotal: 27.6s\tremaining: 2m 5s\n",
      "1000:\tlearn: 238.1551944\ttest: 253.0653446\tbest: 253.0653408 (999)\ttotal: 30.7s\tremaining: 2m 2s\n",
      "1100:\tlearn: 234.3642268\ttest: 250.7696921\tbest: 250.7644101 (1098)\ttotal: 33.7s\tremaining: 1m 59s\n",
      "1200:\tlearn: 231.5523168\ttest: 249.7205328\tbest: 249.6602596 (1191)\ttotal: 36.8s\tremaining: 1m 56s\n",
      "1300:\tlearn: 229.8701534\ttest: 248.6806191\tbest: 248.6775184 (1295)\ttotal: 39.8s\tremaining: 1m 53s\n",
      "1400:\tlearn: 227.7963568\ttest: 247.5934184\tbest: 247.5844112 (1397)\ttotal: 42.8s\tremaining: 1m 49s\n",
      "1500:\tlearn: 226.7016731\ttest: 246.9182692\tbest: 246.8732571 (1487)\ttotal: 46.1s\tremaining: 1m 47s\n",
      "1600:\tlearn: 225.3912664\ttest: 245.8773771\tbest: 245.8771977 (1593)\ttotal: 49.7s\tremaining: 1m 45s\n",
      "1700:\tlearn: 223.3905655\ttest: 244.6466605\tbest: 244.6026664 (1697)\ttotal: 53s\tremaining: 1m 42s\n",
      "1800:\tlearn: 221.9794694\ttest: 244.1332631\tbest: 244.1332631 (1800)\ttotal: 56.4s\tremaining: 1m 40s\n",
      "1900:\tlearn: 220.4470486\ttest: 243.4890501\tbest: 243.4890501 (1900)\ttotal: 59.6s\tremaining: 1m 37s\n",
      "2000:\tlearn: 218.1555765\ttest: 241.9728118\tbest: 241.9728118 (2000)\ttotal: 1m 2s\tremaining: 1m 34s\n",
      "2100:\tlearn: 217.3717999\ttest: 241.5476635\tbest: 241.5476635 (2100)\ttotal: 1m 6s\tremaining: 1m 31s\n",
      "2200:\tlearn: 216.3283134\ttest: 241.0691857\tbest: 241.0542252 (2191)\ttotal: 1m 9s\tremaining: 1m 28s\n",
      "2300:\tlearn: 215.1442097\ttest: 240.7636180\tbest: 240.6497137 (2275)\ttotal: 1m 13s\tremaining: 1m 25s\n",
      "2400:\tlearn: 214.0596451\ttest: 240.5036787\tbest: 240.5030535 (2399)\ttotal: 1m 16s\tremaining: 1m 22s\n",
      "2500:\tlearn: 213.2898809\ttest: 240.1413400\tbest: 240.1413400 (2500)\ttotal: 1m 20s\tremaining: 1m 20s\n",
      "2600:\tlearn: 212.2252094\ttest: 239.1944110\tbest: 239.1944110 (2600)\ttotal: 1m 23s\tremaining: 1m 16s\n",
      "2700:\tlearn: 211.4331639\ttest: 238.7564290\tbest: 238.6595451 (2681)\ttotal: 1m 26s\tremaining: 1m 13s\n",
      "2800:\tlearn: 210.6706428\ttest: 238.3693490\tbest: 238.3693490 (2800)\ttotal: 1m 29s\tremaining: 1m 10s\n",
      "2900:\tlearn: 209.9212095\ttest: 238.1369178\tbest: 238.1369178 (2900)\ttotal: 1m 32s\tremaining: 1m 6s\n",
      "3000:\tlearn: 209.0465303\ttest: 237.6276178\tbest: 237.6169620 (2988)\ttotal: 1m 35s\tremaining: 1m 3s\n",
      "3100:\tlearn: 208.1689633\ttest: 237.5318626\tbest: 237.5220625 (3099)\ttotal: 1m 38s\tremaining: 1m\n",
      "3200:\tlearn: 207.4274332\ttest: 237.1266971\tbest: 237.1241468 (3195)\ttotal: 1m 41s\tremaining: 57s\n",
      "3300:\tlearn: 206.9701420\ttest: 236.9802177\tbest: 236.8841958 (3288)\ttotal: 1m 44s\tremaining: 53.7s\n",
      "3400:\tlearn: 206.1769143\ttest: 236.6480819\tbest: 236.5711989 (3382)\ttotal: 1m 47s\tremaining: 50.4s\n",
      "3500:\tlearn: 205.5608018\ttest: 236.2776178\tbest: 236.2688646 (3499)\ttotal: 1m 50s\tremaining: 47.2s\n",
      "3600:\tlearn: 204.7431912\ttest: 235.6617894\tbest: 235.6497411 (3576)\ttotal: 1m 52s\tremaining: 43.9s\n",
      "3700:\tlearn: 204.5277987\ttest: 235.5726604\tbest: 235.5713701 (3699)\ttotal: 1m 55s\tremaining: 40.6s\n",
      "3800:\tlearn: 204.0601123\ttest: 235.4102973\tbest: 235.3890457 (3765)\ttotal: 1m 58s\tremaining: 37.5s\n",
      "3900:\tlearn: 203.8146453\ttest: 235.3444268\tbest: 235.3444265 (3899)\ttotal: 2m 1s\tremaining: 34.2s\n",
      "4000:\tlearn: 203.3573994\ttest: 235.1783277\tbest: 235.1692047 (3982)\ttotal: 2m 4s\tremaining: 31.1s\n",
      "4100:\tlearn: 202.7097875\ttest: 234.9853598\tbest: 234.9385652 (4076)\ttotal: 2m 7s\tremaining: 27.9s\n",
      "4200:\tlearn: 202.3817802\ttest: 234.9074057\tbest: 234.8438614 (4148)\ttotal: 2m 10s\tremaining: 24.8s\n",
      "4300:\tlearn: 202.0901672\ttest: 234.8102090\tbest: 234.7749147 (4273)\ttotal: 2m 13s\tremaining: 21.7s\n",
      "4400:\tlearn: 201.7813527\ttest: 234.5926012\tbest: 234.5926012 (4400)\ttotal: 2m 16s\tremaining: 18.5s\n",
      "4500:\tlearn: 200.8318583\ttest: 234.6868283\tbest: 234.5724648 (4438)\ttotal: 2m 19s\tremaining: 15.4s\n",
      "4600:\tlearn: 200.3730773\ttest: 234.3890809\tbest: 234.3890716 (4598)\ttotal: 2m 22s\tremaining: 12.3s\n",
      "4700:\tlearn: 199.7804126\ttest: 234.0958073\tbest: 234.0082792 (4682)\ttotal: 2m 25s\tremaining: 9.24s\n",
      "4800:\tlearn: 198.9456504\ttest: 233.7259212\tbest: 233.7159647 (4789)\ttotal: 2m 28s\tremaining: 6.14s\n",
      "4900:\tlearn: 198.3636389\ttest: 233.3680844\tbest: 233.3422387 (4894)\ttotal: 2m 31s\tremaining: 3.05s\n",
      "4999:\tlearn: 198.0450263\ttest: 233.1843526\tbest: 233.1834151 (4977)\ttotal: 2m 34s\tremaining: 0us\n",
      "\n",
      "bestTest = 233.1834151\n",
      "bestIteration = 4977\n",
      "\n",
      "Shrink model to first 4978 iterations.",
      "\n",
      "0:\tlearn: 896.1140354\ttest: 942.2939740\tbest: 942.2939740 (0)\ttotal: 27.5ms\tremaining: 2m 17s\n",
      "100:\tlearn: 329.0140777\ttest: 323.7074904\tbest: 323.7074904 (100)\ttotal: 3.17s\tremaining: 2m 33s\n",
      "200:\tlearn: 297.9735464\ttest: 297.2935572\tbest: 297.2601369 (198)\ttotal: 5.92s\tremaining: 2m 21s\n",
      "300:\tlearn: 282.0680452\ttest: 284.2173581\tbest: 284.2171018 (299)\ttotal: 8.91s\tremaining: 2m 19s\n",
      "400:\tlearn: 275.2097552\ttest: 278.6855384\tbest: 278.6848500 (397)\ttotal: 11.6s\tremaining: 2m 12s\n",
      "500:\tlearn: 266.1591405\ttest: 273.1366070\tbest: 273.1366070 (500)\ttotal: 14.3s\tremaining: 2m 8s\n",
      "600:\tlearn: 255.8657040\ttest: 266.2298142\tbest: 266.2298142 (600)\ttotal: 17.4s\tremaining: 2m 7s\n",
      "700:\tlearn: 250.5772218\ttest: 263.0106332\tbest: 262.9725539 (697)\ttotal: 20.2s\tremaining: 2m 3s\n",
      "800:\tlearn: 245.4068499\ttest: 258.7440248\tbest: 258.7440248 (800)\ttotal: 23.1s\tremaining: 2m 1s\n",
      "900:\tlearn: 243.1344398\ttest: 256.8903437\tbest: 256.8881715 (898)\ttotal: 25.9s\tremaining: 1m 57s\n",
      "1000:\tlearn: 240.7157132\ttest: 255.6375533\tbest: 255.6289534 (997)\ttotal: 28.6s\tremaining: 1m 54s\n",
      "1100:\tlearn: 237.5160056\ttest: 253.7574057\tbest: 253.7574057 (1100)\ttotal: 31.8s\tremaining: 1m 52s\n",
      "1200:\tlearn: 235.8142603\ttest: 252.5948924\tbest: 252.5733426 (1192)\ttotal: 34.5s\tremaining: 1m 49s\n",
      "1300:\tlearn: 233.9635242\ttest: 251.0559171\tbest: 251.0559171 (1300)\ttotal: 37.7s\tremaining: 1m 47s\n",
      "1400:\tlearn: 231.1527144\ttest: 250.0631918\tbest: 250.0586654 (1399)\ttotal: 40.6s\tremaining: 1m 44s\n",
      "1500:\tlearn: 229.6736240\ttest: 249.4355594\tbest: 249.4355594 (1500)\ttotal: 43.4s\tremaining: 1m 41s\n",
      "1600:\tlearn: 228.4109308\ttest: 248.6513341\tbest: 248.6513341 (1600)\ttotal: 46.3s\tremaining: 1m 38s\n",
      "1700:\tlearn: 226.9942062\ttest: 247.4875278\tbest: 247.4833429 (1695)\ttotal: 49.4s\tremaining: 1m 35s\n",
      "1800:\tlearn: 225.9612561\ttest: 246.6735565\tbest: 246.6070592 (1788)\ttotal: 52.1s\tremaining: 1m 32s\n",
      "1900:\tlearn: 225.0744130\ttest: 246.1543025\tbest: 246.1423086 (1893)\ttotal: 54.9s\tremaining: 1m 29s\n",
      "2000:\tlearn: 224.4132280\ttest: 246.1357619\tbest: 246.0243436 (1963)\ttotal: 57.9s\tremaining: 1m 26s\n",
      "2100:\tlearn: 223.6740631\ttest: 245.7764787\tbest: 245.7577207 (2087)\ttotal: 1m\tremaining: 1m 23s\n",
      "2200:\tlearn: 222.5874048\ttest: 245.2811719\tbest: 245.2626288 (2191)\ttotal: 1m 3s\tremaining: 1m 20s\n",
      "2300:\tlearn: 221.1663671\ttest: 245.0155341\tbest: 244.9359716 (2281)\ttotal: 1m 6s\tremaining: 1m 17s\n",
      "2400:\tlearn: 220.3630164\ttest: 244.5215572\tbest: 244.5193456 (2399)\ttotal: 1m 8s\tremaining: 1m 14s\n",
      "2500:\tlearn: 218.9341867\ttest: 243.8168139\tbest: 243.8120608 (2493)\ttotal: 1m 11s\tremaining: 1m 11s\n",
      "2600:\tlearn: 217.9655646\ttest: 243.3074886\tbest: 243.2897636 (2578)\ttotal: 1m 14s\tremaining: 1m 8s\n",
      "2700:\tlearn: 216.4429352\ttest: 242.5662274\tbest: 242.5484915 (2683)\ttotal: 1m 17s\tremaining: 1m 5s\n",
      "2800:\tlearn: 215.9102259\ttest: 241.8006879\tbest: 241.7975770 (2798)\ttotal: 1m 20s\tremaining: 1m 3s\n",
      "2900:\tlearn: 214.6577876\ttest: 240.9271996\tbest: 240.9256309 (2897)\ttotal: 1m 23s\tremaining: 1m\n",
      "3000:\tlearn: 214.2009764\ttest: 240.8847982\tbest: 240.8547032 (2973)\ttotal: 1m 26s\tremaining: 57.3s\n",
      "3100:\tlearn: 213.5504679\ttest: 240.5855167\tbest: 240.5361898 (3087)\ttotal: 1m 29s\tremaining: 54.5s\n",
      "3200:\tlearn: 212.5799943\ttest: 240.1654278\tbest: 240.1654278 (3200)\ttotal: 1m 31s\tremaining: 51.7s\n",
      "3300:\tlearn: 210.5741975\ttest: 239.0750586\tbest: 239.0633542 (3297)\ttotal: 1m 34s\tremaining: 48.8s\n",
      "3400:\tlearn: 209.9424709\ttest: 238.6444698\tbest: 238.6430224 (3398)\ttotal: 1m 37s\tremaining: 45.8s\n",
      "3500:\tlearn: 208.6744819\ttest: 237.9972556\tbest: 237.9960635 (3499)\ttotal: 1m 40s\tremaining: 43s\n",
      "3600:\tlearn: 207.8791504\ttest: 237.4206380\tbest: 237.4205206 (3599)\ttotal: 1m 43s\tremaining: 40.2s\n",
      "3700:\tlearn: 206.8723820\ttest: 236.5807266\tbest: 236.5779543 (3690)\ttotal: 1m 46s\tremaining: 37.3s\n",
      "3800:\tlearn: 206.3657603\ttest: 236.6323731\tbest: 236.5402079 (3723)\ttotal: 1m 48s\tremaining: 34.4s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 236.5402079\n",
      "bestIteration = 3723\n",
      "\n",
      "Shrink model to first 3724 iterations.",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "ctb_model = CatBoostRegressor(iterations=5000,learning_rate=0.15,loss_function=\"RMSE\")\n",
    "data_ctb, predict_label = get_predict_w(ctb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019,model_type='ctb')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0:\tlearn: 966.9229081\ttest: 913.8197712\tbest: 913.8197712 (0)\ttotal: 29.9ms\tremaining: 4m 59s\n",
      "100:\tlearn: 403.4534404\ttest: 365.7935225\tbest: 365.7935225 (100)\ttotal: 3.66s\tremaining: 5m 58s\n",
      "200:\tlearn: 359.6144306\ttest: 331.1568133\tbest: 331.1568133 (200)\ttotal: 6.8s\tremaining: 5m 31s\n",
      "300:\tlearn: 331.1049800\ttest: 311.5698898\tbest: 311.5698898 (300)\ttotal: 10.3s\tremaining: 5m 31s\n",
      "400:\tlearn: 312.6379623\ttest: 298.2009619\tbest: 298.2009619 (400)\ttotal: 13.9s\tremaining: 5m 31s\n",
      "500:\tlearn: 302.8842061\ttest: 291.1307435\tbest: 291.1062395 (499)\ttotal: 17.1s\tremaining: 5m 24s\n",
      "600:\tlearn: 294.2406591\ttest: 284.4298345\tbest: 284.4298321 (599)\ttotal: 20.6s\tremaining: 5m 22s\n",
      "700:\tlearn: 288.3283389\ttest: 280.0320236\tbest: 280.0257096 (699)\ttotal: 23.7s\tremaining: 5m 14s\n",
      "800:\tlearn: 284.5178030\ttest: 277.7651874\tbest: 277.7649971 (799)\ttotal: 26.5s\tremaining: 5m 4s\n",
      "900:\tlearn: 279.1784628\ttest: 274.9506737\tbest: 274.9481866 (896)\ttotal: 29.7s\tremaining: 4m 59s\n",
      "1000:\tlearn: 277.1929276\ttest: 273.9953592\tbest: 273.9948227 (999)\ttotal: 32.2s\tremaining: 4m 49s\n",
      "1100:\tlearn: 274.1610055\ttest: 272.1953154\tbest: 272.1950410 (1097)\ttotal: 34.9s\tremaining: 4m 42s\n",
      "1200:\tlearn: 271.6321759\ttest: 270.8172497\tbest: 270.8172497 (1200)\ttotal: 38.1s\tremaining: 4m 38s\n",
      "1300:\tlearn: 270.0815828\ttest: 269.7824324\tbest: 269.7824324 (1300)\ttotal: 40.9s\tremaining: 4m 33s\n",
      "1400:\tlearn: 268.0625747\ttest: 268.1925053\tbest: 268.1796776 (1396)\ttotal: 44s\tremaining: 4m 29s\n",
      "1500:\tlearn: 266.7723049\ttest: 267.2915991\tbest: 267.2915991 (1500)\ttotal: 46.7s\tremaining: 4m 24s\n",
      "1600:\tlearn: 264.9311634\ttest: 266.2579054\tbest: 266.2567685 (1597)\ttotal: 49.7s\tremaining: 4m 20s\n",
      "1700:\tlearn: 261.6797672\ttest: 263.6524245\tbest: 263.6522655 (1699)\ttotal: 53.1s\tremaining: 4m 18s\n",
      "1800:\tlearn: 258.9301355\ttest: 261.5153002\tbest: 261.5153002 (1800)\ttotal: 56.6s\tremaining: 4m 17s\n",
      "1900:\tlearn: 256.6819552\ttest: 259.7445475\tbest: 259.7362796 (1896)\ttotal: 59.9s\tremaining: 4m 15s\n",
      "2000:\tlearn: 255.1401331\ttest: 258.4589173\tbest: 258.4589002 (1998)\ttotal: 1m 3s\tremaining: 4m 12s\n",
      "2100:\tlearn: 253.6817727\ttest: 257.5468393\tbest: 257.5465463 (2095)\ttotal: 1m 5s\tremaining: 4m 7s\n",
      "2200:\tlearn: 251.9980128\ttest: 256.1935341\tbest: 256.1604051 (2196)\ttotal: 1m 8s\tremaining: 4m 4s\n",
      "2300:\tlearn: 249.7286608\ttest: 254.6936297\tbest: 254.6846703 (2295)\ttotal: 1m 12s\tremaining: 4m 2s\n",
      "2400:\tlearn: 249.0342124\ttest: 254.1495868\tbest: 254.1449523 (2389)\ttotal: 1m 15s\tremaining: 3m 58s\n",
      "2500:\tlearn: 247.8427166\ttest: 253.3620785\tbest: 253.3437103 (2497)\ttotal: 1m 18s\tremaining: 3m 55s\n",
      "2600:\tlearn: 247.1348383\ttest: 252.8192225\tbest: 252.8109554 (2592)\ttotal: 1m 22s\tremaining: 3m 53s\n",
      "2700:\tlearn: 246.4321596\ttest: 252.2441181\tbest: 252.2365697 (2697)\ttotal: 1m 25s\tremaining: 3m 50s\n",
      "2800:\tlearn: 246.1650105\ttest: 252.1601707\tbest: 252.1563852 (2796)\ttotal: 1m 28s\tremaining: 3m 46s\n",
      "2900:\tlearn: 245.2249190\ttest: 251.4136607\tbest: 251.4136607 (2900)\ttotal: 1m 31s\tremaining: 3m 42s\n",
      "3000:\tlearn: 244.3466222\ttest: 250.7537964\tbest: 250.7359553 (2988)\ttotal: 1m 34s\tremaining: 3m 39s\n",
      "3100:\tlearn: 242.9927994\ttest: 249.9091437\tbest: 249.9091437 (3100)\ttotal: 1m 37s\tremaining: 3m 36s\n",
      "3200:\tlearn: 242.2459802\ttest: 249.4210088\tbest: 249.4116789 (3184)\ttotal: 1m 40s\tremaining: 3m 33s\n",
      "3300:\tlearn: 240.7005087\ttest: 248.4508806\tbest: 248.4471012 (3295)\ttotal: 1m 43s\tremaining: 3m 30s\n",
      "3400:\tlearn: 239.8772139\ttest: 247.7561504\tbest: 247.7538862 (3398)\ttotal: 1m 46s\tremaining: 3m 27s\n",
      "3500:\tlearn: 239.0107248\ttest: 247.1490191\tbest: 247.1469874 (3499)\ttotal: 1m 49s\tremaining: 3m 23s\n",
      "3600:\tlearn: 238.1089577\ttest: 246.7810628\tbest: 246.7810628 (3600)\ttotal: 1m 52s\tremaining: 3m 20s\n",
      "3700:\tlearn: 237.3846988\ttest: 246.2965875\tbest: 246.2960144 (3694)\ttotal: 1m 55s\tremaining: 3m 17s\n",
      "3800:\tlearn: 236.4379715\ttest: 245.4077070\tbest: 245.4047054 (3796)\ttotal: 1m 59s\tremaining: 3m 14s\n",
      "3900:\tlearn: 235.6045852\ttest: 244.7960686\tbest: 244.7960686 (3900)\ttotal: 2m 2s\tremaining: 3m 11s\n",
      "4000:\tlearn: 234.8618537\ttest: 244.3521733\tbest: 244.3511990 (3997)\ttotal: 2m 5s\tremaining: 3m 8s\n",
      "4100:\tlearn: 234.4714169\ttest: 244.2339205\tbest: 244.2224844 (4097)\ttotal: 2m 8s\tremaining: 3m 5s\n",
      "4200:\tlearn: 234.0652095\ttest: 243.9762554\tbest: 243.9695395 (4187)\ttotal: 2m 11s\tremaining: 3m 1s\n",
      "4300:\tlearn: 233.4653214\ttest: 243.5332867\tbest: 243.5306048 (4293)\ttotal: 2m 14s\tremaining: 2m 58s\n",
      "4400:\tlearn: 233.1579964\ttest: 243.3892025\tbest: 243.3892025 (4400)\ttotal: 2m 17s\tremaining: 2m 55s\n",
      "4500:\tlearn: 232.3438935\ttest: 242.9307361\tbest: 242.9307361 (4500)\ttotal: 2m 21s\tremaining: 2m 53s\n",
      "4600:\tlearn: 231.9175422\ttest: 242.6222335\tbest: 242.5859460 (4577)\ttotal: 2m 25s\tremaining: 2m 50s\n",
      "4700:\tlearn: 231.5778068\ttest: 242.4801854\tbest: 242.4801854 (4700)\ttotal: 2m 28s\tremaining: 2m 47s\n",
      "4800:\tlearn: 231.2308197\ttest: 242.2092978\tbest: 242.2092978 (4800)\ttotal: 2m 32s\tremaining: 2m 45s\n",
      "4900:\tlearn: 230.9579766\ttest: 241.8607691\tbest: 241.8607489 (4899)\ttotal: 2m 35s\tremaining: 2m 41s\n",
      "5000:\tlearn: 230.4663848\ttest: 241.5169647\tbest: 241.5165494 (4999)\ttotal: 2m 38s\tremaining: 2m 38s\n",
      "5100:\tlearn: 230.0942485\ttest: 241.2090003\tbest: 241.2073099 (5096)\ttotal: 2m 42s\tremaining: 2m 36s\n",
      "5200:\tlearn: 229.4985745\ttest: 240.7169963\tbest: 240.7169867 (5199)\ttotal: 2m 45s\tremaining: 2m 33s\n",
      "5300:\tlearn: 228.8414269\ttest: 240.2634395\tbest: 240.2628752 (5296)\ttotal: 2m 49s\tremaining: 2m 30s\n",
      "5400:\tlearn: 228.5713571\ttest: 240.0830496\tbest: 240.0830496 (5400)\ttotal: 2m 53s\tremaining: 2m 27s\n",
      "5500:\tlearn: 227.8607361\ttest: 239.5593280\tbest: 239.5593280 (5500)\ttotal: 2m 56s\tremaining: 2m 24s\n",
      "5600:\tlearn: 227.3661713\ttest: 239.1707114\tbest: 239.1691753 (5591)\ttotal: 3m\tremaining: 2m 21s\n",
      "5700:\tlearn: 226.4556827\ttest: 238.5163527\tbest: 238.5157753 (5697)\ttotal: 3m 3s\tremaining: 2m 18s\n",
      "5800:\tlearn: 226.0902440\ttest: 238.2755840\tbest: 238.2741584 (5797)\ttotal: 3m 7s\tremaining: 2m 15s\n",
      "5900:\tlearn: 225.3965892\ttest: 237.7201142\tbest: 237.7201142 (5900)\ttotal: 3m 10s\tremaining: 2m 12s\n",
      "6000:\tlearn: 225.0194395\ttest: 237.6694396\tbest: 237.6578333 (5985)\ttotal: 3m 14s\tremaining: 2m 9s\n",
      "6100:\tlearn: 224.7352929\ttest: 237.6172399\tbest: 237.6036532 (6032)\ttotal: 3m 17s\tremaining: 2m 6s\n",
      "6200:\tlearn: 223.9942752\ttest: 237.2088740\tbest: 237.1424471 (6187)\ttotal: 3m 22s\tremaining: 2m 4s\n",
      "6300:\tlearn: 223.6645906\ttest: 236.9971258\tbest: 236.9968893 (6298)\ttotal: 3m 26s\tremaining: 2m 1s\n",
      "6400:\tlearn: 223.4466917\ttest: 236.8267146\tbest: 236.8257807 (6386)\ttotal: 3m 30s\tremaining: 1m 58s\n",
      "6500:\tlearn: 223.0811925\ttest: 236.6779643\tbest: 236.6729381 (6472)\ttotal: 3m 33s\tremaining: 1m 54s\n",
      "6600:\tlearn: 222.7037571\ttest: 236.4698740\tbest: 236.4692271 (6589)\ttotal: 3m 36s\tremaining: 1m 51s\n",
      "6700:\tlearn: 222.4900147\ttest: 236.3412616\tbest: 236.3412616 (6700)\ttotal: 3m 40s\tremaining: 1m 48s\n",
      "6800:\tlearn: 222.2324000\ttest: 236.1235457\tbest: 236.1235457 (6800)\ttotal: 3m 43s\tremaining: 1m 45s\n",
      "6900:\tlearn: 221.8787172\ttest: 235.8534507\tbest: 235.8464885 (6883)\ttotal: 3m 46s\tremaining: 1m 41s\n",
      "7000:\tlearn: 221.6541980\ttest: 235.7344667\tbest: 235.7242675 (6990)\ttotal: 3m 50s\tremaining: 1m 38s\n",
      "7100:\tlearn: 221.5046104\ttest: 235.5842337\tbest: 235.5842337 (7100)\ttotal: 3m 52s\tremaining: 1m 35s\n",
      "7200:\tlearn: 221.1196283\ttest: 235.3934738\tbest: 235.3915269 (7194)\ttotal: 3m 56s\tremaining: 1m 31s\n",
      "7300:\tlearn: 220.7976749\ttest: 235.2998043\tbest: 235.2997991 (7299)\ttotal: 3m 58s\tremaining: 1m 28s\n",
      "7400:\tlearn: 220.6936990\ttest: 235.2713874\tbest: 235.2712155 (7399)\ttotal: 4m 1s\tremaining: 1m 24s\n",
      "7500:\tlearn: 220.2585211\ttest: 235.0259460\tbest: 234.9953551 (7491)\ttotal: 4m 4s\tremaining: 1m 21s\n",
      "7600:\tlearn: 220.0371973\ttest: 234.9087109\tbest: 234.9085767 (7586)\ttotal: 4m 7s\tremaining: 1m 18s\n",
      "7700:\tlearn: 219.8448704\ttest: 234.8046154\tbest: 234.8046154 (7700)\ttotal: 4m 10s\tremaining: 1m 14s\n",
      "7800:\tlearn: 219.5352555\ttest: 234.6704860\tbest: 234.6671420 (7799)\ttotal: 4m 14s\tremaining: 1m 11s\n",
      "7900:\tlearn: 219.2609032\ttest: 234.4941467\tbest: 234.4941467 (7900)\ttotal: 4m 17s\tremaining: 1m 8s\n",
      "8000:\tlearn: 219.0569275\ttest: 234.3840870\tbest: 234.3840870 (8000)\ttotal: 4m 20s\tremaining: 1m 5s\n",
      "8100:\tlearn: 218.7269481\ttest: 234.2114611\tbest: 234.2101461 (8096)\ttotal: 4m 24s\tremaining: 1m 1s\n",
      "8200:\tlearn: 218.5098555\ttest: 233.9934936\tbest: 233.9934936 (8200)\ttotal: 4m 27s\tremaining: 58.6s\n",
      "8300:\tlearn: 218.2695587\ttest: 233.8010273\tbest: 233.7865633 (8298)\ttotal: 4m 30s\tremaining: 55.3s\n",
      "8400:\tlearn: 217.8858670\ttest: 233.6442689\tbest: 233.6442689 (8400)\ttotal: 4m 33s\tremaining: 52s\n",
      "8500:\tlearn: 217.6444309\ttest: 233.4552104\tbest: 233.4544627 (8497)\ttotal: 4m 36s\tremaining: 48.8s\n",
      "8600:\tlearn: 217.1496208\ttest: 233.1905396\tbest: 233.1905396 (8600)\ttotal: 4m 39s\tremaining: 45.5s\n",
      "8700:\tlearn: 216.9369647\ttest: 233.0798783\tbest: 233.0762852 (8686)\ttotal: 4m 42s\tremaining: 42.2s\n",
      "8800:\tlearn: 216.8122889\ttest: 232.9944238\tbest: 232.9935773 (8793)\ttotal: 4m 45s\tremaining: 38.8s\n",
      "8900:\tlearn: 216.7434660\ttest: 232.9458498\tbest: 232.9443171 (8885)\ttotal: 4m 47s\tremaining: 35.6s\n",
      "9000:\tlearn: 216.5008900\ttest: 232.7909134\tbest: 232.7907457 (8999)\ttotal: 4m 51s\tremaining: 32.3s\n",
      "9100:\tlearn: 216.3054302\ttest: 232.6927019\tbest: 232.6924076 (9097)\ttotal: 4m 54s\tremaining: 29.1s\n",
      "9200:\tlearn: 215.9514196\ttest: 232.4412276\tbest: 232.4412276 (9200)\ttotal: 4m 57s\tremaining: 25.8s\n",
      "9300:\tlearn: 215.7539491\ttest: 232.4068972\tbest: 232.4068972 (9300)\ttotal: 5m\tremaining: 22.6s\n",
      "9400:\tlearn: 215.5444752\ttest: 232.2290044\tbest: 232.2198268 (9362)\ttotal: 5m 3s\tremaining: 19.3s\n",
      "9500:\tlearn: 215.2022090\ttest: 232.0579282\tbest: 232.0579282 (9500)\ttotal: 5m 6s\tremaining: 16.1s\n",
      "9600:\tlearn: 214.8890173\ttest: 231.8954425\tbest: 231.8954212 (9599)\ttotal: 5m 9s\tremaining: 12.9s\n",
      "9700:\tlearn: 214.7107719\ttest: 231.7627816\tbest: 231.7594573 (9682)\ttotal: 5m 12s\tremaining: 9.63s\n",
      "9800:\tlearn: 214.4167236\ttest: 231.6000490\tbest: 231.5999301 (9796)\ttotal: 5m 15s\tremaining: 6.41s\n",
      "9900:\tlearn: 214.2386271\ttest: 231.4806587\tbest: 231.4800639 (9891)\ttotal: 5m 18s\tremaining: 3.18s\n",
      "9999:\tlearn: 214.0856566\ttest: 231.3191384\tbest: 231.3190661 (9998)\ttotal: 5m 21s\tremaining: 0us\n",
      "\n",
      "bestTest = 231.3190661\n",
      "bestIteration = 9998\n",
      "\n",
      "Shrink model to first 9999 iterations.",
      "\n",
      "0:\tlearn: 960.8511704\ttest: 957.7903378\tbest: 957.7903378 (0)\ttotal: 33.7ms\tremaining: 5m 37s\n",
      "100:\tlearn: 398.7903675\ttest: 407.0675056\tbest: 407.0675056 (100)\ttotal: 3.62s\tremaining: 5m 55s\n",
      "200:\tlearn: 360.7663442\ttest: 374.1259512\tbest: 374.1259512 (200)\ttotal: 7.36s\tremaining: 5m 58s\n",
      "300:\tlearn: 335.6307550\ttest: 349.0572380\tbest: 349.0572380 (300)\ttotal: 11.3s\tremaining: 6m 3s\n",
      "400:\tlearn: 318.4055113\ttest: 329.2353591\tbest: 329.2353591 (400)\ttotal: 15s\tremaining: 5m 58s\n",
      "500:\tlearn: 306.7666034\ttest: 316.8592186\tbest: 316.8592186 (500)\ttotal: 18.3s\tremaining: 5m 47s\n",
      "600:\tlearn: 297.6316438\ttest: 307.7006457\tbest: 307.6792940 (594)\ttotal: 21.8s\tremaining: 5m 40s\n",
      "700:\tlearn: 290.2752352\ttest: 301.2772244\tbest: 301.2772244 (700)\ttotal: 25.4s\tremaining: 5m 36s\n",
      "800:\tlearn: 284.8780004\ttest: 296.7063107\tbest: 296.7063107 (800)\ttotal: 28.9s\tremaining: 5m 32s\n",
      "900:\tlearn: 281.3474421\ttest: 294.0317057\tbest: 294.0310752 (899)\ttotal: 32.7s\tremaining: 5m 29s\n",
      "1000:\tlearn: 277.7902351\ttest: 291.2585462\tbest: 291.2585462 (1000)\ttotal: 36.3s\tremaining: 5m 26s\n",
      "1100:\tlearn: 274.3854431\ttest: 288.4734536\tbest: 288.4516646 (1097)\ttotal: 39.4s\tremaining: 5m 18s\n",
      "1200:\tlearn: 270.7830168\ttest: 285.6156149\tbest: 285.6132977 (1198)\ttotal: 42.6s\tremaining: 5m 12s\n",
      "1300:\tlearn: 267.4394296\ttest: 282.8245881\tbest: 282.8245881 (1300)\ttotal: 45.9s\tremaining: 5m 6s\n",
      "1400:\tlearn: 264.0634800\ttest: 279.8738873\tbest: 279.8738873 (1400)\ttotal: 49.2s\tremaining: 5m 1s\n",
      "1500:\tlearn: 262.3740021\ttest: 278.7658233\tbest: 278.7658233 (1500)\ttotal: 52.6s\tremaining: 4m 57s\n",
      "1600:\tlearn: 260.1575149\ttest: 277.3067610\tbest: 277.3060244 (1598)\ttotal: 55.9s\tremaining: 4m 53s\n",
      "1700:\tlearn: 257.8476988\ttest: 275.7790907\tbest: 275.7790615 (1699)\ttotal: 59s\tremaining: 4m 48s\n",
      "1800:\tlearn: 256.5339477\ttest: 274.7364160\tbest: 274.7364160 (1800)\ttotal: 1m 2s\tremaining: 4m 43s\n",
      "1900:\tlearn: 254.8737192\ttest: 273.6881199\tbest: 273.6875553 (1897)\ttotal: 1m 5s\tremaining: 4m 38s\n",
      "2000:\tlearn: 253.0537836\ttest: 272.5747609\tbest: 272.5718837 (1997)\ttotal: 1m 8s\tremaining: 4m 34s\n",
      "2100:\tlearn: 251.2051373\ttest: 271.5694086\tbest: 271.5694086 (2100)\ttotal: 1m 11s\tremaining: 4m 29s\n",
      "2200:\tlearn: 249.6044298\ttest: 270.2341888\tbest: 270.2335238 (2198)\ttotal: 1m 14s\tremaining: 4m 24s\n",
      "2300:\tlearn: 247.5362014\ttest: 268.6191970\tbest: 268.6191970 (2300)\ttotal: 1m 17s\tremaining: 4m 20s\n",
      "2400:\tlearn: 246.2027849\ttest: 267.8126094\tbest: 267.8121520 (2398)\ttotal: 1m 20s\tremaining: 4m 15s\n",
      "2500:\tlearn: 245.3696449\ttest: 267.5600097\tbest: 267.5432373 (2495)\ttotal: 1m 23s\tremaining: 4m 11s\n",
      "2600:\tlearn: 244.3347498\ttest: 266.9736064\tbest: 266.9736064 (2600)\ttotal: 1m 26s\tremaining: 4m 7s\n",
      "2700:\tlearn: 243.3832085\ttest: 266.3287706\tbest: 266.3287706 (2700)\ttotal: 1m 30s\tremaining: 4m 3s\n",
      "2800:\tlearn: 242.1728465\ttest: 265.6084378\tbest: 265.6057790 (2791)\ttotal: 1m 33s\tremaining: 3m 59s\n",
      "2900:\tlearn: 240.7306028\ttest: 264.6897911\tbest: 264.6891204 (2899)\ttotal: 1m 36s\tremaining: 3m 55s\n",
      "3000:\tlearn: 239.8484732\ttest: 264.1832714\tbest: 264.1829466 (2999)\ttotal: 1m 39s\tremaining: 3m 51s\n",
      "3100:\tlearn: 238.2734193\ttest: 263.1290463\tbest: 263.1269846 (3099)\ttotal: 1m 42s\tremaining: 3m 48s\n",
      "3200:\tlearn: 237.2822548\ttest: 262.4856061\tbest: 262.4856061 (3200)\ttotal: 1m 46s\tremaining: 3m 45s\n",
      "3300:\tlearn: 236.2271885\ttest: 261.8900438\tbest: 261.8900438 (3300)\ttotal: 1m 49s\tremaining: 3m 41s\n",
      "3400:\tlearn: 235.5299917\ttest: 261.5588090\tbest: 261.5502329 (3394)\ttotal: 1m 52s\tremaining: 3m 38s\n",
      "3500:\tlearn: 234.8617271\ttest: 260.9258217\tbest: 260.9258217 (3500)\ttotal: 1m 55s\tremaining: 3m 34s\n",
      "3600:\tlearn: 234.2433825\ttest: 260.4801693\tbest: 260.4679129 (3580)\ttotal: 1m 58s\tremaining: 3m 31s\n",
      "3700:\tlearn: 233.5808989\ttest: 260.0587800\tbest: 260.0277304 (3687)\ttotal: 2m 1s\tremaining: 3m 27s\n",
      "3800:\tlearn: 232.7993159\ttest: 259.4681456\tbest: 259.4680137 (3796)\ttotal: 2m 4s\tremaining: 3m 23s\n",
      "3900:\tlearn: 232.2143221\ttest: 259.1855187\tbest: 259.1855187 (3900)\ttotal: 2m 8s\tremaining: 3m 20s\n",
      "4000:\tlearn: 231.7656858\ttest: 259.0495555\tbest: 259.0495555 (4000)\ttotal: 2m 11s\tremaining: 3m 17s\n",
      "4100:\tlearn: 231.3224460\ttest: 258.7975528\tbest: 258.7856676 (4096)\ttotal: 2m 15s\tremaining: 3m 14s\n",
      "4200:\tlearn: 230.2714370\ttest: 258.2937269\tbest: 258.2937269 (4200)\ttotal: 2m 18s\tremaining: 3m 11s\n",
      "4300:\tlearn: 229.3561034\ttest: 257.4520724\tbest: 257.4520724 (4300)\ttotal: 2m 22s\tremaining: 3m 8s\n",
      "4400:\tlearn: 228.4241804\ttest: 256.8849106\tbest: 256.8849106 (4400)\ttotal: 2m 25s\tremaining: 3m 4s\n",
      "4500:\tlearn: 227.7955994\ttest: 256.6307080\tbest: 256.5916421 (4484)\ttotal: 2m 28s\tremaining: 3m 1s\n",
      "4600:\tlearn: 226.9975705\ttest: 255.9722606\tbest: 255.9722606 (4600)\ttotal: 2m 31s\tremaining: 2m 58s\n",
      "4700:\tlearn: 226.1618901\ttest: 255.5620128\tbest: 255.5523223 (4689)\ttotal: 2m 35s\tremaining: 2m 55s\n",
      "4800:\tlearn: 224.9440438\ttest: 254.7353508\tbest: 254.7353508 (4800)\ttotal: 2m 38s\tremaining: 2m 52s\n",
      "4900:\tlearn: 224.3403657\ttest: 254.3632632\tbest: 254.3586035 (4891)\ttotal: 2m 41s\tremaining: 2m 48s\n",
      "5000:\tlearn: 223.9269021\ttest: 254.3016154\tbest: 254.2946798 (4954)\ttotal: 2m 45s\tremaining: 2m 44s\n",
      "5100:\tlearn: 223.5454886\ttest: 254.0803535\tbest: 254.0797873 (5096)\ttotal: 2m 48s\tremaining: 2m 41s\n",
      "5200:\tlearn: 222.4830040\ttest: 253.4747769\tbest: 253.4744150 (5199)\ttotal: 2m 52s\tremaining: 2m 38s\n",
      "5300:\tlearn: 221.9944959\ttest: 253.2478378\tbest: 253.2477589 (5298)\ttotal: 2m 55s\tremaining: 2m 35s\n",
      "5400:\tlearn: 221.0782354\ttest: 252.7528974\tbest: 252.7528974 (5400)\ttotal: 2m 59s\tremaining: 2m 32s\n",
      "5500:\tlearn: 220.3355000\ttest: 252.3880286\tbest: 252.3880286 (5500)\ttotal: 3m 2s\tremaining: 2m 29s\n",
      "5600:\tlearn: 219.7506428\ttest: 252.0424387\tbest: 252.0376308 (5594)\ttotal: 3m 5s\tremaining: 2m 26s\n",
      "5700:\tlearn: 219.1430780\ttest: 251.6745691\tbest: 251.6623746 (5688)\ttotal: 3m 9s\tremaining: 2m 23s\n",
      "5800:\tlearn: 218.8198200\ttest: 251.5406332\tbest: 251.5406332 (5800)\ttotal: 3m 13s\tremaining: 2m 20s\n",
      "5900:\tlearn: 218.3452601\ttest: 251.4121074\tbest: 251.4098198 (5898)\ttotal: 3m 17s\tremaining: 2m 17s\n",
      "6000:\tlearn: 217.8985516\ttest: 251.2114018\tbest: 251.1973137 (5986)\ttotal: 3m 21s\tremaining: 2m 14s\n",
      "6100:\tlearn: 217.4923337\ttest: 250.9558633\tbest: 250.9506087 (6092)\ttotal: 3m 24s\tremaining: 2m 10s\n",
      "6200:\tlearn: 217.0176034\ttest: 250.8190246\tbest: 250.8097408 (6198)\ttotal: 3m 28s\tremaining: 2m 7s\n",
      "6300:\tlearn: 216.6440898\ttest: 250.6546592\tbest: 250.6546504 (6299)\ttotal: 3m 32s\tremaining: 2m 4s\n",
      "6400:\tlearn: 216.3023101\ttest: 250.5173598\tbest: 250.5172426 (6399)\ttotal: 3m 36s\tremaining: 2m 1s\n",
      "6500:\tlearn: 216.0108803\ttest: 250.3570526\tbest: 250.3570526 (6500)\ttotal: 3m 39s\tremaining: 1m 58s\n",
      "6600:\tlearn: 215.5937710\ttest: 250.1107540\tbest: 250.0839528 (6595)\ttotal: 3m 42s\tremaining: 1m 54s\n",
      "6700:\tlearn: 215.3418674\ttest: 250.0294684\tbest: 250.0078930 (6667)\ttotal: 3m 45s\tremaining: 1m 51s\n",
      "6800:\tlearn: 214.9323348\ttest: 249.8566117\tbest: 249.8311359 (6763)\ttotal: 3m 48s\tremaining: 1m 47s\n",
      "6900:\tlearn: 214.4027085\ttest: 249.4478218\tbest: 249.4478218 (6900)\ttotal: 3m 52s\tremaining: 1m 44s\n",
      "7000:\tlearn: 213.8490039\ttest: 249.1215398\tbest: 249.1215398 (7000)\ttotal: 3m 55s\tremaining: 1m 40s\n",
      "7100:\tlearn: 213.7117905\ttest: 249.1002299\tbest: 249.0884038 (7091)\ttotal: 3m 59s\tremaining: 1m 37s\n",
      "7200:\tlearn: 213.4887466\ttest: 248.9624077\tbest: 248.9624077 (7200)\ttotal: 4m 2s\tremaining: 1m 34s\n",
      "7300:\tlearn: 213.2266424\ttest: 248.8010300\tbest: 248.8000367 (7293)\ttotal: 4m 5s\tremaining: 1m 30s\n",
      "7400:\tlearn: 212.6511206\ttest: 248.4824568\tbest: 248.4823884 (7394)\ttotal: 4m 8s\tremaining: 1m 27s\n",
      "7500:\tlearn: 212.2818663\ttest: 248.1455123\tbest: 248.1360286 (7485)\ttotal: 4m 11s\tremaining: 1m 23s\n",
      "7600:\tlearn: 212.0799051\ttest: 248.0568583\tbest: 248.0479718 (7585)\ttotal: 4m 14s\tremaining: 1m 20s\n",
      "7700:\tlearn: 211.5020005\ttest: 247.6229716\tbest: 247.6143134 (7687)\ttotal: 4m 17s\tremaining: 1m 16s\n",
      "7800:\tlearn: 211.2913648\ttest: 247.5751302\tbest: 247.5591494 (7780)\ttotal: 4m 20s\tremaining: 1m 13s\n",
      "7900:\tlearn: 210.7583729\ttest: 247.1553008\tbest: 247.1553008 (7900)\ttotal: 4m 24s\tremaining: 1m 10s\n",
      "8000:\tlearn: 210.5962839\ttest: 247.1405460\tbest: 247.1168201 (7961)\ttotal: 4m 28s\tremaining: 1m 7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 247.1168201\n",
      "bestIteration = 7961\n",
      "\n",
      "Shrink model to first 7962 iterations.",
      "\n",
      "0:\tlearn: 945.5391755\ttest: 1001.4047974\tbest: 1001.4047974 (0)\ttotal: 31ms\tremaining: 5m 9s\n",
      "100:\tlearn: 398.4754907\ttest: 433.1000236\tbest: 433.1000236 (100)\ttotal: 3.69s\tremaining: 6m 1s\n",
      "200:\tlearn: 356.4814680\ttest: 381.4074455\tbest: 381.4074455 (200)\ttotal: 6.7s\tremaining: 5m 26s\n",
      "300:\tlearn: 324.9621968\ttest: 342.9313889\tbest: 342.9313889 (300)\ttotal: 10.3s\tremaining: 5m 30s\n",
      "400:\tlearn: 311.7147337\ttest: 328.8706057\tbest: 328.8706057 (400)\ttotal: 13.6s\tremaining: 5m 25s\n",
      "500:\tlearn: 301.9166650\ttest: 318.3483955\tbest: 318.3474145 (499)\ttotal: 16.8s\tremaining: 5m 19s\n",
      "600:\tlearn: 295.4460853\ttest: 311.6855465\tbest: 311.6855465 (600)\ttotal: 19.7s\tremaining: 5m 8s\n",
      "700:\tlearn: 289.1598712\ttest: 305.6134080\tbest: 305.6134080 (700)\ttotal: 23.5s\tremaining: 5m 12s\n",
      "800:\tlearn: 285.5445381\ttest: 301.9886241\tbest: 301.9697740 (789)\ttotal: 26.8s\tremaining: 5m 7s\n",
      "900:\tlearn: 280.1109614\ttest: 296.8453571\tbest: 296.8453571 (900)\ttotal: 30.4s\tremaining: 5m 6s\n",
      "1000:\tlearn: 276.2164284\ttest: 293.8584341\tbest: 293.8584341 (1000)\ttotal: 33.3s\tremaining: 4m 59s\n",
      "1100:\tlearn: 273.3507191\ttest: 291.5235041\tbest: 291.5235041 (1100)\ttotal: 36.3s\tremaining: 4m 53s\n",
      "1200:\tlearn: 269.5859704\ttest: 287.9963555\tbest: 287.9963555 (1200)\ttotal: 39.5s\tremaining: 4m 49s\n",
      "1300:\tlearn: 267.6937148\ttest: 286.5067229\tbest: 286.5031562 (1296)\ttotal: 42.5s\tremaining: 4m 43s\n",
      "1400:\tlearn: 264.8303216\ttest: 284.5667288\tbest: 284.5656176 (1395)\ttotal: 45.4s\tremaining: 4m 38s\n",
      "1500:\tlearn: 262.4223129\ttest: 282.7616556\tbest: 282.7616556 (1500)\ttotal: 48.4s\tremaining: 4m 34s\n",
      "1600:\tlearn: 259.5059225\ttest: 280.4417895\tbest: 280.4417895 (1600)\ttotal: 51.5s\tremaining: 4m 30s\n",
      "1700:\tlearn: 257.4705437\ttest: 278.5960017\tbest: 278.5934574 (1697)\ttotal: 54.9s\tremaining: 4m 28s\n",
      "1800:\tlearn: 255.7583939\ttest: 277.2332221\tbest: 277.2332221 (1800)\ttotal: 57.8s\tremaining: 4m 23s\n",
      "1900:\tlearn: 255.1309522\ttest: 276.6909165\tbest: 276.6909165 (1900)\ttotal: 1m\tremaining: 4m 16s\n",
      "2000:\tlearn: 254.1406808\ttest: 275.7697102\tbest: 275.7672720 (1992)\ttotal: 1m 2s\tremaining: 4m 11s\n",
      "2100:\tlearn: 253.2534200\ttest: 274.9263897\tbest: 274.9166685 (2096)\ttotal: 1m 5s\tremaining: 4m 6s\n",
      "2200:\tlearn: 252.3141962\ttest: 274.2482939\tbest: 274.2482939 (2200)\ttotal: 1m 8s\tremaining: 4m 3s\n",
      "2300:\tlearn: 251.5182863\ttest: 273.5411637\tbest: 273.5411637 (2300)\ttotal: 1m 11s\tremaining: 3m 58s\n",
      "2400:\tlearn: 250.8781922\ttest: 273.0735063\tbest: 273.0690595 (2392)\ttotal: 1m 14s\tremaining: 3m 54s\n",
      "2500:\tlearn: 249.5276433\ttest: 271.8022266\tbest: 271.8016622 (2495)\ttotal: 1m 17s\tremaining: 3m 52s\n",
      "2600:\tlearn: 248.1893092\ttest: 271.1630676\tbest: 271.1169288 (2589)\ttotal: 1m 20s\tremaining: 3m 48s\n",
      "2700:\tlearn: 247.5437919\ttest: 270.7438240\tbest: 270.7438240 (2700)\ttotal: 1m 23s\tremaining: 3m 44s\n",
      "2800:\tlearn: 247.1560949\ttest: 270.5511082\tbest: 270.5510999 (2799)\ttotal: 1m 25s\tremaining: 3m 40s\n",
      "2900:\tlearn: 246.4414502\ttest: 269.9396253\tbest: 269.9367330 (2893)\ttotal: 1m 28s\tremaining: 3m 35s\n",
      "3000:\tlearn: 245.8919331\ttest: 269.5652491\tbest: 269.5652143 (2993)\ttotal: 1m 30s\tremaining: 3m 31s\n",
      "3100:\tlearn: 244.6792302\ttest: 268.6197118\tbest: 268.6188061 (3096)\ttotal: 1m 33s\tremaining: 3m 28s\n",
      "3200:\tlearn: 244.1293294\ttest: 268.2395952\tbest: 268.2320566 (3179)\ttotal: 1m 36s\tremaining: 3m 24s\n",
      "3300:\tlearn: 243.7750074\ttest: 268.0520150\tbest: 268.0518212 (3299)\ttotal: 1m 39s\tremaining: 3m 20s\n",
      "3400:\tlearn: 242.8893228\ttest: 267.5310324\tbest: 267.5250339 (3392)\ttotal: 1m 42s\tremaining: 3m 18s\n",
      "3500:\tlearn: 241.6926959\ttest: 266.6701711\tbest: 266.6701711 (3500)\ttotal: 1m 45s\tremaining: 3m 15s\n",
      "3600:\tlearn: 240.5682037\ttest: 265.7646035\tbest: 265.7617681 (3591)\ttotal: 1m 48s\tremaining: 3m 12s\n",
      "3700:\tlearn: 239.9688378\ttest: 265.4015717\tbest: 265.3776267 (3693)\ttotal: 1m 51s\tremaining: 3m 9s\n",
      "3800:\tlearn: 239.4868203\ttest: 265.0618468\tbest: 265.0618468 (3800)\ttotal: 1m 54s\tremaining: 3m 6s\n",
      "3900:\tlearn: 238.9185216\ttest: 264.6506171\tbest: 264.6503847 (3899)\ttotal: 1m 57s\tremaining: 3m 3s\n",
      "4000:\tlearn: 238.1126024\ttest: 264.0074225\tbest: 264.0074225 (4000)\ttotal: 2m\tremaining: 3m\n",
      "4100:\tlearn: 237.5571651\ttest: 263.6007658\tbest: 263.5959486 (4091)\ttotal: 2m 3s\tremaining: 2m 57s\n",
      "4200:\tlearn: 237.1366234\ttest: 263.1579395\tbest: 263.1577266 (4198)\ttotal: 2m 6s\tremaining: 2m 54s\n",
      "4300:\tlearn: 236.7225428\ttest: 262.9666125\tbest: 262.9633090 (4297)\ttotal: 2m 9s\tremaining: 2m 51s\n",
      "4400:\tlearn: 236.0487916\ttest: 262.3567922\tbest: 262.3567922 (4400)\ttotal: 2m 12s\tremaining: 2m 48s\n",
      "4500:\tlearn: 235.6367762\ttest: 262.2093434\tbest: 262.2093434 (4500)\ttotal: 2m 15s\tremaining: 2m 45s\n",
      "4600:\tlearn: 235.2601612\ttest: 261.9637923\tbest: 261.9637886 (4599)\ttotal: 2m 18s\tremaining: 2m 42s\n",
      "4700:\tlearn: 234.3284602\ttest: 261.5355849\tbest: 261.5216998 (4650)\ttotal: 2m 21s\tremaining: 2m 39s\n",
      "4800:\tlearn: 233.7487081\ttest: 261.1076338\tbest: 261.1076338 (4800)\ttotal: 2m 23s\tremaining: 2m 35s\n",
      "4900:\tlearn: 233.4927672\ttest: 260.9312329\tbest: 260.9291885 (4894)\ttotal: 2m 26s\tremaining: 2m 32s\n",
      "5000:\tlearn: 233.1958204\ttest: 260.7180976\tbest: 260.7180976 (5000)\ttotal: 2m 29s\tremaining: 2m 29s\n",
      "5100:\tlearn: 232.5960480\ttest: 260.2167370\tbest: 260.2167370 (5100)\ttotal: 2m 32s\tremaining: 2m 26s\n",
      "5200:\tlearn: 231.6989032\ttest: 259.6789302\tbest: 259.6789302 (5200)\ttotal: 2m 35s\tremaining: 2m 23s\n",
      "5300:\tlearn: 231.0564547\ttest: 259.3243271\tbest: 259.3243271 (5300)\ttotal: 2m 38s\tremaining: 2m 20s\n",
      "5400:\tlearn: 230.4748799\ttest: 258.9663507\tbest: 258.9663507 (5400)\ttotal: 2m 41s\tremaining: 2m 17s\n",
      "5500:\tlearn: 230.1326464\ttest: 258.7901331\tbest: 258.7841117 (5476)\ttotal: 2m 43s\tremaining: 2m 13s\n",
      "5600:\tlearn: 229.7709827\ttest: 258.7837252\tbest: 258.7408053 (5551)\ttotal: 2m 46s\tremaining: 2m 10s\n",
      "5700:\tlearn: 229.1442193\ttest: 258.3125198\tbest: 258.3036272 (5699)\ttotal: 2m 49s\tremaining: 2m 7s\n",
      "5800:\tlearn: 228.6461055\ttest: 257.8987183\tbest: 257.8654502 (5777)\ttotal: 2m 52s\tremaining: 2m 4s\n",
      "5900:\tlearn: 228.4437491\ttest: 257.7132367\tbest: 257.7086811 (5892)\ttotal: 2m 55s\tremaining: 2m 1s\n",
      "6000:\tlearn: 227.8833580\ttest: 257.3657032\tbest: 257.3657032 (6000)\ttotal: 2m 57s\tremaining: 1m 58s\n",
      "6100:\tlearn: 227.6328262\ttest: 257.1827184\tbest: 257.1827184 (6100)\ttotal: 3m\tremaining: 1m 55s\n",
      "6200:\tlearn: 227.1750111\ttest: 256.7059714\tbest: 256.7059714 (6200)\ttotal: 3m 3s\tremaining: 1m 52s\n",
      "6300:\tlearn: 226.7614984\ttest: 256.4150774\tbest: 256.4113403 (6288)\ttotal: 3m 6s\tremaining: 1m 49s\n",
      "6400:\tlearn: 226.3977235\ttest: 256.2847121\tbest: 256.2798711 (6384)\ttotal: 3m 9s\tremaining: 1m 46s\n",
      "6500:\tlearn: 226.0255018\ttest: 256.2044640\tbest: 256.1915569 (6466)\ttotal: 3m 12s\tremaining: 1m 43s\n",
      "6600:\tlearn: 225.9150250\ttest: 256.1769806\tbest: 256.1767873 (6599)\ttotal: 3m 14s\tremaining: 1m 40s\n",
      "6700:\tlearn: 225.7507377\ttest: 256.0470504\tbest: 256.0419737 (6697)\ttotal: 3m 17s\tremaining: 1m 37s\n",
      "6800:\tlearn: 225.6193740\ttest: 256.0054787\tbest: 255.9890952 (6778)\ttotal: 3m 20s\tremaining: 1m 34s\n",
      "6900:\tlearn: 225.4557471\ttest: 255.8842722\tbest: 255.8842722 (6900)\ttotal: 3m 23s\tremaining: 1m 31s\n",
      "7000:\tlearn: 225.0725502\ttest: 255.6250423\tbest: 255.6239383 (6997)\ttotal: 3m 26s\tremaining: 1m 28s\n",
      "7100:\tlearn: 224.8818219\ttest: 255.5415387\tbest: 255.5353902 (7075)\ttotal: 3m 29s\tremaining: 1m 25s\n",
      "7200:\tlearn: 224.7822843\ttest: 255.4327609\tbest: 255.4211318 (7174)\ttotal: 3m 32s\tremaining: 1m 22s\n",
      "7300:\tlearn: 224.4663494\ttest: 255.1675522\tbest: 255.1674042 (7296)\ttotal: 3m 35s\tremaining: 1m 19s\n",
      "7400:\tlearn: 224.1433345\ttest: 255.0317702\tbest: 255.0261893 (7398)\ttotal: 3m 37s\tremaining: 1m 16s\n",
      "7500:\tlearn: 223.8379966\ttest: 254.8703394\tbest: 254.8700265 (7495)\ttotal: 3m 40s\tremaining: 1m 13s\n",
      "7600:\tlearn: 223.5592557\ttest: 254.7416308\tbest: 254.7286836 (7580)\ttotal: 3m 43s\tremaining: 1m 10s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 254.7286836\n",
      "bestIteration = 7580\n",
      "\n",
      "Shrink model to first 7581 iterations.",
      "\n",
      "0:\tlearn: 969.4147287\ttest: 921.5021896\tbest: 921.5021896 (0)\ttotal: 29.5ms\tremaining: 4m 55s\n",
      "100:\tlearn: 401.7691431\ttest: 372.2771603\tbest: 372.2771603 (100)\ttotal: 3.41s\tremaining: 5m 34s\n",
      "200:\tlearn: 355.2760592\ttest: 334.0599437\tbest: 334.0599437 (200)\ttotal: 6.68s\tremaining: 5m 25s\n",
      "300:\tlearn: 330.1709151\ttest: 314.0285115\tbest: 314.0285115 (300)\ttotal: 9.84s\tremaining: 5m 17s\n",
      "400:\tlearn: 311.5642133\ttest: 299.6001104\tbest: 299.6001104 (400)\ttotal: 13.1s\tremaining: 5m 14s\n",
      "500:\tlearn: 301.9576010\ttest: 291.2253466\tbest: 291.2253466 (500)\ttotal: 16.4s\tremaining: 5m 10s\n",
      "600:\tlearn: 295.2832625\ttest: 286.2834772\tbest: 286.2834772 (600)\ttotal: 19.5s\tremaining: 5m 4s\n",
      "700:\tlearn: 289.9115843\ttest: 282.5981277\tbest: 282.5981277 (700)\ttotal: 22.6s\tremaining: 4m 59s\n",
      "800:\tlearn: 285.5946926\ttest: 279.4987413\tbest: 279.4987413 (800)\ttotal: 25.9s\tremaining: 4m 57s\n",
      "900:\tlearn: 279.7666260\ttest: 275.4770933\tbest: 275.4770933 (900)\ttotal: 29s\tremaining: 4m 53s\n",
      "1000:\tlearn: 274.7311458\ttest: 272.6551150\tbest: 272.6449255 (995)\ttotal: 32.1s\tremaining: 4m 48s\n",
      "1100:\tlearn: 271.0234244\ttest: 270.5350310\tbest: 270.5341217 (1099)\ttotal: 35.4s\tremaining: 4m 46s\n",
      "1200:\tlearn: 267.4832307\ttest: 267.9230815\tbest: 267.9203135 (1198)\ttotal: 38.5s\tremaining: 4m 42s\n",
      "1300:\tlearn: 263.3207713\ttest: 264.8281895\tbest: 264.8281895 (1300)\ttotal: 41.4s\tremaining: 4m 36s\n",
      "1400:\tlearn: 260.1410862\ttest: 263.0274287\tbest: 263.0274287 (1400)\ttotal: 44.8s\tremaining: 4m 34s\n",
      "1500:\tlearn: 257.7480664\ttest: 261.3633674\tbest: 261.3633674 (1500)\ttotal: 48.2s\tremaining: 4m 32s\n",
      "1600:\tlearn: 256.0282230\ttest: 260.2819013\tbest: 260.2819013 (1600)\ttotal: 51.2s\tremaining: 4m 28s\n",
      "1700:\tlearn: 253.1400042\ttest: 257.9758154\tbest: 257.9758154 (1700)\ttotal: 54.3s\tremaining: 4m 25s\n",
      "1800:\tlearn: 251.0506996\ttest: 256.3315743\tbest: 256.3315351 (1799)\ttotal: 57.3s\tremaining: 4m 20s\n",
      "1900:\tlearn: 249.6379968\ttest: 255.4531910\tbest: 255.4432591 (1896)\ttotal: 1m\tremaining: 4m 17s\n",
      "2000:\tlearn: 248.4199324\ttest: 254.8913578\tbest: 254.8758660 (1991)\ttotal: 1m 3s\tremaining: 4m 14s\n",
      "2100:\tlearn: 247.3502751\ttest: 253.9212995\tbest: 253.9180601 (2094)\ttotal: 1m 6s\tremaining: 4m 9s\n",
      "2200:\tlearn: 246.4826118\ttest: 253.2079610\tbest: 253.2070361 (2196)\ttotal: 1m 9s\tremaining: 4m 6s\n",
      "2300:\tlearn: 245.3373166\ttest: 252.3919188\tbest: 252.3919188 (2300)\ttotal: 1m 12s\tremaining: 4m\n",
      "2400:\tlearn: 244.6677538\ttest: 252.1497996\tbest: 252.1436541 (2399)\ttotal: 1m 14s\tremaining: 3m 56s\n",
      "2500:\tlearn: 243.3381892\ttest: 251.4560931\tbest: 251.4521765 (2495)\ttotal: 1m 17s\tremaining: 3m 53s\n",
      "2600:\tlearn: 242.4645799\ttest: 250.8255640\tbest: 250.8255640 (2600)\ttotal: 1m 21s\tremaining: 3m 50s\n",
      "2700:\tlearn: 241.3670095\ttest: 249.8093615\tbest: 249.8093615 (2700)\ttotal: 1m 24s\tremaining: 3m 47s\n",
      "2800:\tlearn: 240.8348666\ttest: 249.5915522\tbest: 249.5797358 (2797)\ttotal: 1m 26s\tremaining: 3m 43s\n",
      "2900:\tlearn: 238.9528759\ttest: 248.6842018\tbest: 248.6842018 (2900)\ttotal: 1m 29s\tremaining: 3m 39s\n",
      "3000:\tlearn: 238.1143575\ttest: 248.1657691\tbest: 248.1657691 (3000)\ttotal: 1m 33s\tremaining: 3m 37s\n",
      "3100:\tlearn: 237.0867860\ttest: 247.6203270\tbest: 247.6196169 (3099)\ttotal: 1m 36s\tremaining: 3m 34s\n",
      "3200:\tlearn: 236.3945487\ttest: 247.0954471\tbest: 247.0954471 (3200)\ttotal: 1m 39s\tremaining: 3m 31s\n",
      "3300:\tlearn: 235.5555177\ttest: 246.6105189\tbest: 246.6093033 (3299)\ttotal: 1m 42s\tremaining: 3m 28s\n",
      "3400:\tlearn: 235.2137772\ttest: 246.3335149\tbest: 246.3335149 (3400)\ttotal: 1m 45s\tremaining: 3m 24s\n",
      "3500:\tlearn: 234.4934610\ttest: 245.9770043\tbest: 245.9768992 (3499)\ttotal: 1m 48s\tremaining: 3m 21s\n",
      "3600:\tlearn: 233.9412133\ttest: 245.6080898\tbest: 245.6048001 (3594)\ttotal: 1m 51s\tremaining: 3m 18s\n",
      "3700:\tlearn: 233.7312783\ttest: 245.5383330\tbest: 245.5383311 (3699)\ttotal: 1m 54s\tremaining: 3m 15s\n",
      "3800:\tlearn: 233.0983860\ttest: 245.0276213\tbest: 245.0276213 (3800)\ttotal: 1m 58s\tremaining: 3m 12s\n",
      "3900:\tlearn: 232.5672058\ttest: 244.7716527\tbest: 244.7693419 (3877)\ttotal: 2m 1s\tremaining: 3m 9s\n",
      "4000:\tlearn: 231.8322814\ttest: 244.3755581\tbest: 244.3755581 (4000)\ttotal: 2m 4s\tremaining: 3m 7s\n",
      "4100:\tlearn: 231.2738308\ttest: 244.0704897\tbest: 244.0617322 (4097)\ttotal: 2m 8s\tremaining: 3m 4s\n",
      "4200:\tlearn: 230.3293658\ttest: 243.4977677\tbest: 243.4957676 (4199)\ttotal: 2m 11s\tremaining: 3m 1s\n",
      "4300:\tlearn: 229.1642938\ttest: 242.7148359\tbest: 242.7109970 (4298)\ttotal: 2m 14s\tremaining: 2m 58s\n",
      "4400:\tlearn: 228.4564715\ttest: 242.2481918\tbest: 242.2476039 (4397)\ttotal: 2m 17s\tremaining: 2m 55s\n",
      "4500:\tlearn: 227.7696105\ttest: 241.8407966\tbest: 241.8407966 (4500)\ttotal: 2m 20s\tremaining: 2m 52s\n",
      "4600:\tlearn: 226.9337666\ttest: 241.4525112\tbest: 241.4514163 (4599)\ttotal: 2m 23s\tremaining: 2m 48s\n",
      "4700:\tlearn: 226.2200714\ttest: 241.0216699\tbest: 241.0211400 (4699)\ttotal: 2m 26s\tremaining: 2m 45s\n",
      "4800:\tlearn: 225.4787714\ttest: 240.7136647\tbest: 240.7090784 (4793)\ttotal: 2m 30s\tremaining: 2m 42s\n",
      "4900:\tlearn: 224.8792543\ttest: 240.3426614\tbest: 240.3426614 (4900)\ttotal: 2m 33s\tremaining: 2m 39s\n",
      "5000:\tlearn: 224.5123627\ttest: 240.2023774\tbest: 240.1987161 (4922)\ttotal: 2m 36s\tremaining: 2m 36s\n",
      "5100:\tlearn: 224.2337019\ttest: 240.0446400\tbest: 240.0403392 (5092)\ttotal: 2m 39s\tremaining: 2m 32s\n",
      "5200:\tlearn: 223.9664725\ttest: 239.8990422\tbest: 239.8841533 (5176)\ttotal: 2m 42s\tremaining: 2m 29s\n",
      "5300:\tlearn: 223.6223922\ttest: 239.6806685\tbest: 239.6806685 (5300)\ttotal: 2m 45s\tremaining: 2m 26s\n",
      "5400:\tlearn: 223.2859644\ttest: 239.4778341\tbest: 239.4773044 (5397)\ttotal: 2m 48s\tremaining: 2m 23s\n",
      "5500:\tlearn: 222.6171461\ttest: 239.1803429\tbest: 239.1727478 (5498)\ttotal: 2m 51s\tremaining: 2m 20s\n",
      "5600:\tlearn: 222.2950834\ttest: 239.1195006\tbest: 239.0921209 (5557)\ttotal: 2m 55s\tremaining: 2m 17s\n",
      "5700:\tlearn: 221.5048196\ttest: 238.8154148\tbest: 238.8154148 (5700)\ttotal: 2m 58s\tremaining: 2m 14s\n",
      "5800:\tlearn: 221.1528698\ttest: 238.6870427\tbest: 238.6870427 (5800)\ttotal: 3m 1s\tremaining: 2m 11s\n",
      "5900:\tlearn: 220.7293110\ttest: 238.4119665\tbest: 238.4119665 (5900)\ttotal: 3m 5s\tremaining: 2m 8s\n",
      "6000:\tlearn: 219.9679962\ttest: 237.9213161\tbest: 237.9201760 (5996)\ttotal: 3m 9s\tremaining: 2m 6s\n",
      "6100:\tlearn: 219.4066616\ttest: 237.7317568\tbest: 237.7208452 (6094)\ttotal: 3m 12s\tremaining: 2m 3s\n",
      "6200:\tlearn: 218.9468381\ttest: 237.5016568\tbest: 237.4678872 (6170)\ttotal: 3m 15s\tremaining: 1m 59s\n",
      "6300:\tlearn: 218.4468653\ttest: 237.2850359\tbest: 237.2850256 (6299)\ttotal: 3m 18s\tremaining: 1m 56s\n",
      "6400:\tlearn: 218.1097366\ttest: 237.0958870\tbest: 237.0958870 (6400)\ttotal: 3m 22s\tremaining: 1m 53s\n",
      "6500:\tlearn: 217.7644426\ttest: 236.9895487\tbest: 236.9838845 (6469)\ttotal: 3m 26s\tremaining: 1m 50s\n",
      "6600:\tlearn: 217.2483883\ttest: 236.8158744\tbest: 236.8153630 (6598)\ttotal: 3m 29s\tremaining: 1m 48s\n",
      "6700:\tlearn: 216.9790050\ttest: 236.6561256\tbest: 236.6561256 (6700)\ttotal: 3m 33s\tremaining: 1m 45s\n",
      "6800:\tlearn: 216.6157020\ttest: 236.4663159\tbest: 236.4663159 (6800)\ttotal: 3m 36s\tremaining: 1m 41s\n",
      "6900:\tlearn: 216.2196294\ttest: 236.3309292\tbest: 236.3236866 (6895)\ttotal: 3m 39s\tremaining: 1m 38s\n",
      "7000:\tlearn: 215.8492907\ttest: 236.1409611\tbest: 236.1409611 (7000)\ttotal: 3m 42s\tremaining: 1m 35s\n",
      "7100:\tlearn: 215.2019666\ttest: 235.8421059\tbest: 235.8299368 (7095)\ttotal: 3m 45s\tremaining: 1m 32s\n",
      "7200:\tlearn: 214.5709111\ttest: 235.3816154\tbest: 235.3816154 (7200)\ttotal: 3m 48s\tremaining: 1m 28s\n",
      "7300:\tlearn: 214.2591387\ttest: 235.2515947\tbest: 235.2226668 (7293)\ttotal: 3m 51s\tremaining: 1m 25s\n",
      "7400:\tlearn: 213.9587499\ttest: 235.0033610\tbest: 235.0029684 (7397)\ttotal: 3m 54s\tremaining: 1m 22s\n",
      "7500:\tlearn: 213.6042852\ttest: 234.8371188\tbest: 234.8366156 (7495)\ttotal: 3m 58s\tremaining: 1m 19s\n",
      "7600:\tlearn: 213.2814078\ttest: 234.7529101\tbest: 234.7354344 (7594)\ttotal: 4m 1s\tremaining: 1m 16s\n",
      "7700:\tlearn: 212.7550554\ttest: 234.3913471\tbest: 234.3863610 (7691)\ttotal: 4m 4s\tremaining: 1m 12s\n",
      "7800:\tlearn: 212.4199920\ttest: 234.2624532\tbest: 234.2562741 (7778)\ttotal: 4m 7s\tremaining: 1m 9s\n",
      "7900:\tlearn: 211.9431842\ttest: 233.9933813\tbest: 233.9933813 (7900)\ttotal: 4m 10s\tremaining: 1m 6s\n",
      "8000:\tlearn: 211.6027798\ttest: 233.7765501\tbest: 233.7753743 (7998)\ttotal: 4m 13s\tremaining: 1m 3s\n",
      "8100:\tlearn: 211.0828944\ttest: 233.4793612\tbest: 233.4793612 (8100)\ttotal: 4m 16s\tremaining: 1m\n",
      "8200:\tlearn: 210.6173925\ttest: 233.2891640\tbest: 233.2879449 (8199)\ttotal: 4m 19s\tremaining: 57s\n",
      "8300:\tlearn: 210.4546385\ttest: 233.2404275\tbest: 233.2366146 (8291)\ttotal: 4m 22s\tremaining: 53.7s\n",
      "8400:\tlearn: 210.2978335\ttest: 233.1645708\tbest: 233.1596277 (8382)\ttotal: 4m 26s\tremaining: 50.6s\n",
      "8500:\tlearn: 210.1184495\ttest: 233.0535043\tbest: 233.0528257 (8497)\ttotal: 4m 29s\tremaining: 47.5s\n",
      "8600:\tlearn: 209.7666069\ttest: 232.8900130\tbest: 232.8807653 (8574)\ttotal: 4m 32s\tremaining: 44.4s\n",
      "8700:\tlearn: 209.4937732\ttest: 232.7334127\tbest: 232.7251204 (8699)\ttotal: 4m 36s\tremaining: 41.2s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 232.7251204\n",
      "bestIteration = 8699\n",
      "\n",
      "Shrink model to first 8700 iterations.",
      "\n",
      "0:\tlearn: 950.9554388\ttest: 996.8279108\tbest: 996.8279108 (0)\ttotal: 33.2ms\tremaining: 5m 31s\n",
      "100:\tlearn: 404.4122870\ttest: 413.6845903\tbest: 413.6845903 (100)\ttotal: 3.69s\tremaining: 6m 2s\n",
      "200:\tlearn: 358.2163664\ttest: 353.4228195\tbest: 353.4228195 (200)\ttotal: 7.15s\tremaining: 5m 48s\n",
      "300:\tlearn: 332.1568987\ttest: 327.9438708\tbest: 327.9438708 (300)\ttotal: 10.6s\tremaining: 5m 39s\n",
      "400:\tlearn: 316.0352940\ttest: 312.6239996\tbest: 312.6239996 (400)\ttotal: 14s\tremaining: 5m 35s\n",
      "500:\tlearn: 303.6711377\ttest: 301.8454259\tbest: 301.8454259 (500)\ttotal: 17.2s\tremaining: 5m 25s\n",
      "600:\tlearn: 292.8617620\ttest: 292.5087319\tbest: 292.5087319 (600)\ttotal: 20.3s\tremaining: 5m 17s\n",
      "700:\tlearn: 286.6633085\ttest: 287.5667957\tbest: 287.5667957 (700)\ttotal: 23.6s\tremaining: 5m 12s\n",
      "800:\tlearn: 282.3627039\ttest: 284.2428633\tbest: 284.2392927 (799)\ttotal: 26.6s\tremaining: 5m 6s\n",
      "900:\tlearn: 278.4872685\ttest: 281.3849505\tbest: 281.3816449 (899)\ttotal: 29.6s\tremaining: 4m 59s\n",
      "1000:\tlearn: 274.4009248\ttest: 278.9947428\tbest: 278.9737085 (999)\ttotal: 33s\tremaining: 4m 56s\n",
      "1100:\tlearn: 271.9110831\ttest: 277.4652383\tbest: 277.4652383 (1100)\ttotal: 35.9s\tremaining: 4m 50s\n",
      "1200:\tlearn: 269.8533627\ttest: 275.8900811\tbest: 275.8900811 (1200)\ttotal: 38.6s\tremaining: 4m 42s\n",
      "1300:\tlearn: 267.0124149\ttest: 274.2779336\tbest: 274.2625703 (1292)\ttotal: 41.6s\tremaining: 4m 37s\n",
      "1400:\tlearn: 266.0131811\ttest: 273.6528312\tbest: 273.6403395 (1396)\ttotal: 44.3s\tremaining: 4m 31s\n",
      "1500:\tlearn: 264.8317597\ttest: 272.7363006\tbest: 272.7353593 (1499)\ttotal: 47.8s\tremaining: 4m 30s\n",
      "1600:\tlearn: 262.9327038\ttest: 271.2541532\tbest: 271.2541532 (1600)\ttotal: 51.2s\tremaining: 4m 28s\n",
      "1700:\tlearn: 260.6014383\ttest: 269.4896109\tbest: 269.4894923 (1697)\ttotal: 54.3s\tremaining: 4m 24s\n",
      "1800:\tlearn: 259.1160033\ttest: 268.3715553\tbest: 268.3715553 (1800)\ttotal: 57s\tremaining: 4m 19s\n",
      "1900:\tlearn: 257.3622310\ttest: 267.3626614\tbest: 267.3276578 (1887)\ttotal: 1m\tremaining: 4m 16s\n",
      "2000:\tlearn: 255.8100720\ttest: 266.5237564\tbest: 266.5220800 (1998)\ttotal: 1m 3s\tremaining: 4m 12s\n",
      "2100:\tlearn: 254.0271498\ttest: 265.3600441\tbest: 265.3539183 (2093)\ttotal: 1m 5s\tremaining: 4m 7s\n",
      "2200:\tlearn: 252.6777070\ttest: 264.3142888\tbest: 264.3142141 (2199)\ttotal: 1m 8s\tremaining: 4m 3s\n",
      "2300:\tlearn: 251.6410317\ttest: 263.5960903\tbest: 263.5825436 (2299)\ttotal: 1m 11s\tremaining: 3m 59s\n",
      "2400:\tlearn: 249.0546869\ttest: 261.4192800\tbest: 261.4192320 (2399)\ttotal: 1m 14s\tremaining: 3m 57s\n",
      "2500:\tlearn: 248.0411755\ttest: 260.8425709\tbest: 260.8422354 (2499)\ttotal: 1m 17s\tremaining: 3m 53s\n",
      "2600:\tlearn: 247.2790951\ttest: 260.3896120\tbest: 260.3825583 (2599)\ttotal: 1m 20s\tremaining: 3m 50s\n",
      "2700:\tlearn: 246.5894056\ttest: 260.1549022\tbest: 260.1549022 (2700)\ttotal: 1m 23s\tremaining: 3m 46s\n",
      "2800:\tlearn: 245.8040482\ttest: 259.7202669\tbest: 259.6991866 (2789)\ttotal: 1m 27s\tremaining: 3m 43s\n",
      "2900:\tlearn: 245.0414972\ttest: 259.3138016\tbest: 259.3138016 (2900)\ttotal: 1m 30s\tremaining: 3m 40s\n",
      "3000:\tlearn: 244.2796459\ttest: 258.8316922\tbest: 258.8316922 (3000)\ttotal: 1m 33s\tremaining: 3m 37s\n",
      "3100:\tlearn: 243.6208329\ttest: 258.5486311\tbest: 258.5242158 (3082)\ttotal: 1m 36s\tremaining: 3m 34s\n",
      "3200:\tlearn: 242.7898469\ttest: 258.1483213\tbest: 258.1007366 (3177)\ttotal: 1m 39s\tremaining: 3m 31s\n",
      "3300:\tlearn: 242.2869724\ttest: 257.9529368\tbest: 257.9517014 (3299)\ttotal: 1m 42s\tremaining: 3m 28s\n",
      "3400:\tlearn: 241.6666799\ttest: 257.4540715\tbest: 257.4528187 (3399)\ttotal: 1m 45s\tremaining: 3m 25s\n",
      "3500:\tlearn: 240.8550881\ttest: 256.8649896\tbest: 256.8565003 (3465)\ttotal: 1m 48s\tremaining: 3m 22s\n",
      "3600:\tlearn: 240.2554480\ttest: 256.5508855\tbest: 256.5487418 (3598)\ttotal: 1m 52s\tremaining: 3m 19s\n",
      "3700:\tlearn: 239.9747392\ttest: 256.3574727\tbest: 256.3568564 (3694)\ttotal: 1m 54s\tremaining: 3m 15s\n",
      "3800:\tlearn: 239.4054067\ttest: 256.0610821\tbest: 256.0446581 (3780)\ttotal: 1m 57s\tremaining: 3m 12s\n",
      "3900:\tlearn: 238.8890898\ttest: 255.7855317\tbest: 255.7854628 (3899)\ttotal: 2m\tremaining: 3m 8s\n",
      "4000:\tlearn: 238.3863529\ttest: 255.4561918\tbest: 255.4551599 (3999)\ttotal: 2m 3s\tremaining: 3m 5s\n",
      "4100:\tlearn: 237.8109726\ttest: 255.1119716\tbest: 255.1045274 (4095)\ttotal: 2m 6s\tremaining: 3m 2s\n",
      "4200:\tlearn: 237.0394580\ttest: 254.6781322\tbest: 254.6777563 (4198)\ttotal: 2m 10s\tremaining: 2m 59s\n",
      "4300:\tlearn: 236.7218120\ttest: 254.5306001\tbest: 254.5281482 (4281)\ttotal: 2m 12s\tremaining: 2m 56s\n",
      "4400:\tlearn: 236.0614822\ttest: 254.1025717\tbest: 254.0958884 (4398)\ttotal: 2m 16s\tremaining: 2m 53s\n",
      "4500:\tlearn: 235.5813203\ttest: 253.6230847\tbest: 253.6219028 (4498)\ttotal: 2m 18s\tremaining: 2m 49s\n",
      "4600:\tlearn: 234.6686163\ttest: 253.0032865\tbest: 252.9741152 (4594)\ttotal: 2m 22s\tremaining: 2m 46s\n",
      "4700:\tlearn: 233.5144118\ttest: 252.2325883\tbest: 252.2102708 (4692)\ttotal: 2m 25s\tremaining: 2m 44s\n",
      "4800:\tlearn: 232.9683954\ttest: 251.8754454\tbest: 251.8697631 (4793)\ttotal: 2m 28s\tremaining: 2m 41s\n",
      "4900:\tlearn: 232.5991430\ttest: 251.6309222\tbest: 251.6306759 (4897)\ttotal: 2m 31s\tremaining: 2m 37s\n",
      "5000:\tlearn: 232.3536765\ttest: 251.5778584\tbest: 251.5764260 (4998)\ttotal: 2m 34s\tremaining: 2m 34s\n",
      "5100:\tlearn: 232.0684305\ttest: 251.4516280\tbest: 251.4516280 (5100)\ttotal: 2m 37s\tremaining: 2m 31s\n",
      "5200:\tlearn: 231.8240386\ttest: 251.3604653\tbest: 251.3593612 (5196)\ttotal: 2m 41s\tremaining: 2m 28s\n",
      "5300:\tlearn: 231.6114270\ttest: 251.2034610\tbest: 251.1960278 (5290)\ttotal: 2m 44s\tremaining: 2m 25s\n",
      "5400:\tlearn: 231.2471780\ttest: 251.0887738\tbest: 251.0887738 (5400)\ttotal: 2m 47s\tremaining: 2m 22s\n",
      "5500:\tlearn: 231.0037637\ttest: 250.9048677\tbest: 250.8938055 (5492)\ttotal: 2m 50s\tremaining: 2m 19s\n",
      "5600:\tlearn: 230.6364310\ttest: 250.6017257\tbest: 250.6017257 (5600)\ttotal: 2m 54s\tremaining: 2m 16s\n",
      "5700:\tlearn: 230.1612792\ttest: 250.3355841\tbest: 250.3353904 (5699)\ttotal: 2m 57s\tremaining: 2m 13s\n",
      "5800:\tlearn: 229.7242428\ttest: 250.0503458\tbest: 250.0484042 (5797)\ttotal: 3m\tremaining: 2m 10s\n",
      "5900:\tlearn: 229.5062022\ttest: 249.9816357\tbest: 249.9816357 (5900)\ttotal: 3m 4s\tremaining: 2m 7s\n",
      "6000:\tlearn: 229.0175144\ttest: 249.7616751\tbest: 249.7457887 (5991)\ttotal: 3m 6s\tremaining: 2m 4s\n",
      "6100:\tlearn: 228.4227324\ttest: 249.2910634\tbest: 249.2897232 (6098)\ttotal: 3m 10s\tremaining: 2m 1s\n",
      "6200:\tlearn: 228.0402225\ttest: 248.9952327\tbest: 248.9952327 (6200)\ttotal: 3m 13s\tremaining: 1m 58s\n",
      "6300:\tlearn: 227.6398986\ttest: 248.6957542\tbest: 248.6957542 (6300)\ttotal: 3m 16s\tremaining: 1m 55s\n",
      "6400:\tlearn: 227.2609980\ttest: 248.5592196\tbest: 248.5590706 (6399)\ttotal: 3m 19s\tremaining: 1m 52s\n",
      "6500:\tlearn: 226.9399985\ttest: 248.2766234\tbest: 248.2766234 (6500)\ttotal: 3m 22s\tremaining: 1m 48s\n",
      "6600:\tlearn: 226.7577236\ttest: 248.0909461\tbest: 248.0903930 (6597)\ttotal: 3m 25s\tremaining: 1m 45s\n",
      "6700:\tlearn: 226.4802061\ttest: 247.9253936\tbest: 247.9221677 (6693)\ttotal: 3m 28s\tremaining: 1m 42s\n",
      "6800:\tlearn: 226.0904509\ttest: 247.7649759\tbest: 247.7391079 (6777)\ttotal: 3m 31s\tremaining: 1m 39s\n",
      "6900:\tlearn: 225.7153627\ttest: 247.5873910\tbest: 247.5843662 (6890)\ttotal: 3m 34s\tremaining: 1m 36s\n",
      "7000:\tlearn: 225.3423282\ttest: 247.3920666\tbest: 247.3687339 (6971)\ttotal: 3m 38s\tremaining: 1m 33s\n",
      "7100:\tlearn: 225.1738211\ttest: 247.2489779\tbest: 247.2482114 (7097)\ttotal: 3m 41s\tremaining: 1m 30s\n",
      "7200:\tlearn: 224.7315009\ttest: 246.9326868\tbest: 246.9326868 (7200)\ttotal: 3m 44s\tremaining: 1m 27s\n",
      "7300:\tlearn: 224.5361645\ttest: 246.7535786\tbest: 246.7514051 (7294)\ttotal: 3m 48s\tremaining: 1m 24s\n",
      "7400:\tlearn: 224.3092813\ttest: 246.6299013\tbest: 246.6275638 (7393)\ttotal: 3m 52s\tremaining: 1m 21s\n",
      "7500:\tlearn: 224.1525779\ttest: 246.5647362\tbest: 246.5417262 (7473)\ttotal: 3m 55s\tremaining: 1m 18s\n",
      "7600:\tlearn: 223.9215308\ttest: 246.4692679\tbest: 246.4682615 (7595)\ttotal: 3m 59s\tremaining: 1m 15s\n",
      "7700:\tlearn: 223.5210092\ttest: 246.1466383\tbest: 246.1412002 (7688)\ttotal: 4m 3s\tremaining: 1m 12s\n",
      "7800:\tlearn: 223.1684357\ttest: 246.0395742\tbest: 246.0395742 (7800)\ttotal: 4m 6s\tremaining: 1m 9s\n",
      "7900:\tlearn: 223.0672959\ttest: 246.0206584\tbest: 246.0169366 (7898)\ttotal: 4m 9s\tremaining: 1m 6s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 246.0169366\n",
      "bestIteration = 7898\n",
      "\n",
      "Shrink model to first 7899 iterations.",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "ctb_model = CatBoostRegressor(iterations=10000,learning_rate=0.05,loss_function=\"RMSE\")\n",
    "data_ctb, predict_label = get_predict_w(ctb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019,model_type='ctb')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0:\tlearn: 992.6355976\ttest: 939.2924841\tbest: 939.2924841 (0)\ttotal: 33ms\tremaining: 11m\n",
      "100:\tlearn: 618.2645786\ttest: 562.0726875\tbest: 562.0726875 (100)\ttotal: 3.54s\tremaining: 11m 37s\n",
      "200:\tlearn: 501.1368020\ttest: 457.0353068\tbest: 457.0353068 (200)\ttotal: 7.22s\tremaining: 11m 50s\n",
      "300:\tlearn: 441.0289974\ttest: 400.3376937\tbest: 400.3376937 (300)\ttotal: 10.7s\tremaining: 11m 38s\n",
      "400:\tlearn: 416.2488872\ttest: 376.7771274\tbest: 376.7771274 (400)\ttotal: 14.2s\tremaining: 11m 34s\n",
      "500:\tlearn: 401.2810894\ttest: 362.9771509\tbest: 362.9771509 (500)\ttotal: 17.7s\tremaining: 11m 30s\n",
      "600:\tlearn: 388.6221696\ttest: 352.2661751\tbest: 352.2661751 (600)\ttotal: 21.1s\tremaining: 11m 21s\n",
      "700:\tlearn: 379.5138418\ttest: 344.6741474\tbest: 344.6741474 (700)\ttotal: 24.6s\tremaining: 11m 17s\n",
      "800:\tlearn: 372.8416613\ttest: 339.0643752\tbest: 339.0643752 (800)\ttotal: 28.1s\tremaining: 11m 14s\n",
      "900:\tlearn: 366.2750687\ttest: 334.1356729\tbest: 334.1356729 (900)\ttotal: 31.4s\tremaining: 11m 6s\n",
      "1000:\tlearn: 358.9171954\ttest: 328.1568333\tbest: 328.1568333 (1000)\ttotal: 35.1s\tremaining: 11m 5s\n",
      "1100:\tlearn: 350.8862389\ttest: 322.7167500\tbest: 322.7167500 (1100)\ttotal: 38.7s\tremaining: 11m 4s\n",
      "1200:\tlearn: 344.7488097\ttest: 318.5262906\tbest: 318.5262906 (1200)\ttotal: 42s\tremaining: 10m 57s\n",
      "1300:\tlearn: 339.2472824\ttest: 314.4073861\tbest: 314.4073861 (1300)\ttotal: 45.4s\tremaining: 10m 52s\n",
      "1400:\tlearn: 334.6968947\ttest: 311.0369974\tbest: 311.0369974 (1400)\ttotal: 48.6s\tremaining: 10m 45s\n",
      "1500:\tlearn: 330.0782324\ttest: 307.9688303\tbest: 307.9688303 (1500)\ttotal: 52.3s\tremaining: 10m 44s\n",
      "1600:\tlearn: 325.9946372\ttest: 305.0156251\tbest: 305.0156251 (1600)\ttotal: 55.8s\tremaining: 10m 41s\n",
      "1700:\tlearn: 322.7138094\ttest: 302.4755870\tbest: 302.4755870 (1700)\ttotal: 59.2s\tremaining: 10m 36s\n",
      "1800:\tlearn: 319.3142222\ttest: 299.7363396\tbest: 299.7363396 (1800)\ttotal: 1m 2s\tremaining: 10m 31s\n",
      "1900:\tlearn: 316.6644410\ttest: 297.7330805\tbest: 297.7330805 (1900)\ttotal: 1m 5s\tremaining: 10m 26s\n",
      "2000:\tlearn: 314.2070153\ttest: 295.9102441\tbest: 295.9102441 (2000)\ttotal: 1m 9s\tremaining: 10m 22s\n",
      "2100:\tlearn: 311.8922310\ttest: 294.1808511\tbest: 294.1808511 (2100)\ttotal: 1m 12s\tremaining: 10m 16s\n",
      "2200:\tlearn: 309.8808314\ttest: 292.6533305\tbest: 292.6533305 (2200)\ttotal: 1m 15s\tremaining: 10m 10s\n",
      "2300:\tlearn: 308.0334075\ttest: 291.0355151\tbest: 291.0355151 (2300)\ttotal: 1m 18s\tremaining: 10m 7s\n",
      "2400:\tlearn: 305.9460898\ttest: 289.3642096\tbest: 289.3642096 (2400)\ttotal: 1m 22s\tremaining: 10m 2s\n",
      "2500:\tlearn: 304.2856919\ttest: 288.0307451\tbest: 288.0307451 (2500)\ttotal: 1m 25s\tremaining: 9m 57s\n",
      "2600:\tlearn: 302.2032782\ttest: 286.3308715\tbest: 286.3308715 (2600)\ttotal: 1m 28s\tremaining: 9m 55s\n",
      "2700:\tlearn: 300.5512349\ttest: 284.9359981\tbest: 284.9359981 (2700)\ttotal: 1m 32s\tremaining: 9m 49s\n",
      "2800:\tlearn: 299.0495966\ttest: 283.7842142\tbest: 283.7842142 (2800)\ttotal: 1m 35s\tremaining: 9m 44s\n",
      "2900:\tlearn: 297.5813123\ttest: 282.5829634\tbest: 282.5829634 (2900)\ttotal: 1m 38s\tremaining: 9m 38s\n",
      "3000:\tlearn: 296.4725390\ttest: 281.8349251\tbest: 281.8343013 (2999)\ttotal: 1m 41s\tremaining: 9m 32s\n",
      "3100:\tlearn: 295.1313706\ttest: 280.7170728\tbest: 280.7170728 (3100)\ttotal: 1m 44s\tremaining: 9m 26s\n",
      "3200:\tlearn: 293.7692921\ttest: 279.8388164\tbest: 279.8388164 (3200)\ttotal: 1m 47s\tremaining: 9m 22s\n",
      "3300:\tlearn: 292.5781990\ttest: 278.8426572\tbest: 278.8426572 (3300)\ttotal: 1m 49s\tremaining: 9m 15s\n",
      "3400:\tlearn: 291.1124375\ttest: 277.7036118\tbest: 277.7036118 (3400)\ttotal: 1m 52s\tremaining: 9m 11s\n",
      "3500:\tlearn: 290.2202967\ttest: 277.0009991\tbest: 277.0009991 (3500)\ttotal: 1m 55s\tremaining: 9m 4s\n",
      "3600:\tlearn: 289.1283431\ttest: 276.3479862\tbest: 276.3479415 (3599)\ttotal: 1m 58s\tremaining: 8m 58s\n",
      "3700:\tlearn: 288.4655909\ttest: 275.8062086\tbest: 275.8062086 (3700)\ttotal: 2m\tremaining: 8m 52s\n",
      "3800:\tlearn: 287.8486255\ttest: 275.3977871\tbest: 275.3927758 (3798)\ttotal: 2m 3s\tremaining: 8m 45s\n",
      "3900:\tlearn: 287.0683320\ttest: 275.0079144\tbest: 275.0079144 (3900)\ttotal: 2m 5s\tremaining: 8m 38s\n",
      "4000:\tlearn: 286.4162330\ttest: 274.5497008\tbest: 274.5497007 (3999)\ttotal: 2m 8s\tremaining: 8m 33s\n",
      "4100:\tlearn: 285.3280970\ttest: 273.9520099\tbest: 273.9520099 (4100)\ttotal: 2m 11s\tremaining: 8m 29s\n",
      "4200:\tlearn: 284.2378701\ttest: 273.1360194\tbest: 273.1360194 (4200)\ttotal: 2m 14s\tremaining: 8m 25s\n",
      "4300:\tlearn: 283.3263537\ttest: 272.4308998\tbest: 272.4308998 (4300)\ttotal: 2m 17s\tremaining: 8m 22s\n",
      "4400:\tlearn: 282.3388591\ttest: 271.7532177\tbest: 271.7531271 (4397)\ttotal: 2m 20s\tremaining: 8m 18s\n",
      "4500:\tlearn: 281.4505371\ttest: 271.2376638\tbest: 271.2376638 (4500)\ttotal: 2m 23s\tremaining: 8m 14s\n",
      "4600:\tlearn: 280.9275468\ttest: 270.9144495\tbest: 270.9144495 (4600)\ttotal: 2m 26s\tremaining: 8m 9s\n",
      "4700:\tlearn: 280.2746584\ttest: 270.5538519\tbest: 270.5523419 (4694)\ttotal: 2m 28s\tremaining: 8m 4s\n",
      "4800:\tlearn: 279.3071053\ttest: 269.8730038\tbest: 269.8729521 (4799)\ttotal: 2m 31s\tremaining: 8m\n",
      "4900:\tlearn: 278.7123957\ttest: 269.4588554\tbest: 269.4588554 (4900)\ttotal: 2m 34s\tremaining: 7m 55s\n",
      "5000:\tlearn: 278.1470113\ttest: 269.1256168\tbest: 269.1246127 (4993)\ttotal: 2m 37s\tremaining: 7m 51s\n",
      "5100:\tlearn: 277.4843939\ttest: 268.6319980\tbest: 268.6319980 (5100)\ttotal: 2m 40s\tremaining: 7m 47s\n",
      "5200:\tlearn: 276.9523960\ttest: 268.3011598\tbest: 268.3010333 (5199)\ttotal: 2m 42s\tremaining: 7m 42s\n",
      "5300:\tlearn: 276.5962094\ttest: 268.0905058\tbest: 268.0905058 (5300)\ttotal: 2m 44s\tremaining: 7m 37s\n",
      "5400:\tlearn: 276.1051613\ttest: 267.8069828\tbest: 267.8069828 (5400)\ttotal: 2m 47s\tremaining: 7m 33s\n",
      "5500:\tlearn: 275.3207546\ttest: 267.3584938\tbest: 267.3584525 (5496)\ttotal: 2m 50s\tremaining: 7m 29s\n",
      "5600:\tlearn: 274.6185005\ttest: 266.9812326\tbest: 266.9778668 (5598)\ttotal: 2m 53s\tremaining: 7m 25s\n",
      "5700:\tlearn: 274.0322361\ttest: 266.6389108\tbest: 266.6380133 (5698)\ttotal: 2m 55s\tremaining: 7m 20s\n",
      "5800:\tlearn: 273.2676446\ttest: 266.1823018\tbest: 266.1823018 (5800)\ttotal: 2m 58s\tremaining: 7m 17s\n",
      "5900:\tlearn: 272.3939806\ttest: 265.6706157\tbest: 265.6706157 (5900)\ttotal: 3m 1s\tremaining: 7m 14s\n",
      "6000:\tlearn: 271.8290454\ttest: 265.3216386\tbest: 265.3216386 (6000)\ttotal: 3m 4s\tremaining: 7m 9s\n",
      "6100:\tlearn: 271.3696073\ttest: 264.9819480\tbest: 264.9819480 (6100)\ttotal: 3m 6s\tremaining: 7m 5s\n",
      "6200:\tlearn: 271.0447115\ttest: 264.7537352\tbest: 264.7537352 (6200)\ttotal: 3m 8s\tremaining: 7m\n",
      "6300:\tlearn: 270.6431807\ttest: 264.5609186\tbest: 264.5608821 (6299)\ttotal: 3m 11s\tremaining: 6m 56s\n",
      "6400:\tlearn: 270.0532976\ttest: 264.1973893\tbest: 264.1973724 (6399)\ttotal: 3m 14s\tremaining: 6m 52s\n",
      "6500:\tlearn: 269.6952612\ttest: 263.9220520\tbest: 263.9220520 (6500)\ttotal: 3m 16s\tremaining: 6m 48s\n",
      "6600:\tlearn: 268.9590521\ttest: 263.4473949\tbest: 263.4473949 (6600)\ttotal: 3m 19s\tremaining: 6m 44s\n",
      "6700:\tlearn: 268.5203366\ttest: 263.1766189\tbest: 263.1765988 (6699)\ttotal: 3m 21s\tremaining: 6m 40s\n",
      "6800:\tlearn: 268.1373387\ttest: 262.9106868\tbest: 262.9106868 (6800)\ttotal: 3m 24s\tremaining: 6m 36s\n",
      "6900:\tlearn: 267.9982326\ttest: 262.8185259\tbest: 262.8185259 (6900)\ttotal: 3m 26s\tremaining: 6m 31s\n",
      "7000:\tlearn: 267.6748183\ttest: 262.6175091\tbest: 262.6175091 (7000)\ttotal: 3m 28s\tremaining: 6m 27s\n",
      "7100:\tlearn: 267.4404043\ttest: 262.4597661\tbest: 262.4586800 (7076)\ttotal: 3m 30s\tremaining: 6m 22s\n",
      "7200:\tlearn: 267.2238742\ttest: 262.3021356\tbest: 262.3010624 (7191)\ttotal: 3m 32s\tremaining: 6m 17s\n",
      "7300:\tlearn: 266.8583076\ttest: 262.1226074\tbest: 262.1226074 (7300)\ttotal: 3m 35s\tremaining: 6m 14s\n",
      "7400:\tlearn: 266.7274348\ttest: 262.0203365\tbest: 262.0203058 (7395)\ttotal: 3m 37s\tremaining: 6m 9s\n",
      "7500:\tlearn: 266.5503473\ttest: 261.9472805\tbest: 261.9471788 (7490)\ttotal: 3m 39s\tremaining: 6m 5s\n",
      "7600:\tlearn: 266.0061908\ttest: 261.5899758\tbest: 261.5889382 (7597)\ttotal: 3m 42s\tremaining: 6m 2s\n",
      "7700:\tlearn: 265.4750917\ttest: 261.2735515\tbest: 261.2731514 (7690)\ttotal: 3m 44s\tremaining: 5m 58s\n",
      "7800:\tlearn: 265.2345524\ttest: 261.1235202\tbest: 261.1235202 (7800)\ttotal: 3m 47s\tremaining: 5m 55s\n",
      "7900:\tlearn: 265.0315083\ttest: 261.0380559\tbest: 261.0353901 (7876)\ttotal: 3m 49s\tremaining: 5m 51s\n",
      "8000:\tlearn: 264.8125439\ttest: 260.9168498\tbest: 260.9168384 (7998)\ttotal: 3m 52s\tremaining: 5m 48s\n",
      "8100:\tlearn: 264.6098256\ttest: 260.7923652\tbest: 260.7923236 (8087)\ttotal: 3m 55s\tremaining: 5m 45s\n",
      "8200:\tlearn: 264.0167269\ttest: 260.3658123\tbest: 260.3654953 (8197)\ttotal: 3m 58s\tremaining: 5m 42s\n",
      "8300:\tlearn: 263.8369531\ttest: 260.2200210\tbest: 260.2199972 (8296)\ttotal: 4m\tremaining: 5m 39s\n",
      "8400:\tlearn: 263.7390223\ttest: 260.1500830\tbest: 260.1500830 (8400)\ttotal: 4m 2s\tremaining: 5m 35s\n",
      "8500:\tlearn: 263.3354772\ttest: 259.8454499\tbest: 259.8454497 (8499)\ttotal: 4m 5s\tremaining: 5m 32s\n",
      "8600:\tlearn: 262.9044060\ttest: 259.5438424\tbest: 259.5437394 (8593)\ttotal: 4m 8s\tremaining: 5m 29s\n",
      "8700:\tlearn: 262.5878745\ttest: 259.3130533\tbest: 259.3130533 (8700)\ttotal: 4m 11s\tremaining: 5m 26s\n",
      "8800:\tlearn: 262.4474103\ttest: 259.1973412\tbest: 259.1973412 (8800)\ttotal: 4m 13s\tremaining: 5m 22s\n",
      "8900:\tlearn: 262.0003250\ttest: 258.9026378\tbest: 258.9026378 (8900)\ttotal: 4m 16s\tremaining: 5m 19s\n",
      "9000:\tlearn: 261.7194960\ttest: 258.7289663\tbest: 258.7281212 (8990)\ttotal: 4m 19s\tremaining: 5m 16s\n",
      "9100:\tlearn: 261.3216021\ttest: 258.5037869\tbest: 258.5037659 (9093)\ttotal: 4m 21s\tremaining: 5m 13s\n",
      "9200:\tlearn: 261.0450568\ttest: 258.3496407\tbest: 258.3496407 (9200)\ttotal: 4m 24s\tremaining: 5m 10s\n",
      "9300:\tlearn: 260.5379557\ttest: 258.0218854\tbest: 258.0218854 (9300)\ttotal: 4m 27s\tremaining: 5m 7s\n",
      "9400:\tlearn: 260.0654104\ttest: 257.7464124\tbest: 257.7464122 (9399)\ttotal: 4m 29s\tremaining: 5m 4s\n",
      "9500:\tlearn: 259.5917923\ttest: 257.3956078\tbest: 257.3956078 (9500)\ttotal: 4m 32s\tremaining: 5m 1s\n",
      "9600:\tlearn: 259.3366204\ttest: 257.2115103\tbest: 257.2115103 (9600)\ttotal: 4m 35s\tremaining: 4m 58s\n",
      "9700:\tlearn: 258.8996152\ttest: 256.9116468\tbest: 256.9116203 (9699)\ttotal: 4m 38s\tremaining: 4m 55s\n",
      "9800:\tlearn: 258.5229305\ttest: 256.6244565\tbest: 256.6224757 (9796)\ttotal: 4m 41s\tremaining: 4m 52s\n",
      "9900:\tlearn: 258.4226168\ttest: 256.5844418\tbest: 256.5843957 (9894)\ttotal: 4m 43s\tremaining: 4m 49s\n",
      "10000:\tlearn: 258.2949658\ttest: 256.5092973\tbest: 256.5092973 (10000)\ttotal: 4m 45s\tremaining: 4m 45s\n",
      "10100:\tlearn: 258.0439991\ttest: 256.3299422\tbest: 256.3299422 (10100)\ttotal: 4m 48s\tremaining: 4m 42s\n",
      "10200:\tlearn: 257.6061423\ttest: 256.0636551\tbest: 256.0635645 (10199)\ttotal: 4m 51s\tremaining: 4m 39s\n",
      "10300:\tlearn: 257.0450364\ttest: 255.6951496\tbest: 255.6940342 (10292)\ttotal: 4m 54s\tremaining: 4m 37s\n",
      "10400:\tlearn: 256.6440904\ttest: 255.4602480\tbest: 255.4602480 (10400)\ttotal: 4m 57s\tremaining: 4m 34s\n",
      "10500:\tlearn: 256.0238585\ttest: 255.0224586\tbest: 255.0224586 (10500)\ttotal: 5m\tremaining: 4m 31s\n",
      "10600:\tlearn: 255.6952800\ttest: 254.8112064\tbest: 254.8111858 (10596)\ttotal: 5m 2s\tremaining: 4m 28s\n",
      "10700:\tlearn: 255.4478236\ttest: 254.6692993\tbest: 254.6688136 (10698)\ttotal: 5m 5s\tremaining: 4m 25s\n",
      "10800:\tlearn: 255.1309463\ttest: 254.4393803\tbest: 254.4392625 (10799)\ttotal: 5m 8s\tremaining: 4m 22s\n",
      "10900:\tlearn: 254.8834809\ttest: 254.2572304\tbest: 254.2571741 (10895)\ttotal: 5m 10s\tremaining: 4m 19s\n",
      "11000:\tlearn: 254.5729146\ttest: 254.0932005\tbest: 254.0932005 (11000)\ttotal: 5m 13s\tremaining: 4m 16s\n",
      "11100:\tlearn: 254.1814453\ttest: 253.8292263\tbest: 253.8292263 (11100)\ttotal: 5m 16s\tremaining: 4m 13s\n",
      "11200:\tlearn: 253.7187151\ttest: 253.4264432\tbest: 253.4251230 (11199)\ttotal: 5m 19s\tremaining: 4m 10s\n",
      "11300:\tlearn: 253.2533302\ttest: 253.0361330\tbest: 253.0361330 (11300)\ttotal: 5m 22s\tremaining: 4m 8s\n",
      "11400:\tlearn: 252.8057541\ttest: 252.7061090\tbest: 252.7058109 (11395)\ttotal: 5m 25s\tremaining: 4m 5s\n",
      "11500:\tlearn: 252.3966909\ttest: 252.4538640\tbest: 252.4521265 (11496)\ttotal: 5m 28s\tremaining: 4m 2s\n",
      "11600:\tlearn: 252.0983736\ttest: 252.2765762\tbest: 252.2765762 (11600)\ttotal: 5m 31s\tremaining: 4m\n",
      "11700:\tlearn: 251.6654473\ttest: 251.9443739\tbest: 251.9441169 (11696)\ttotal: 5m 34s\tremaining: 3m 57s\n",
      "11800:\tlearn: 251.2335440\ttest: 251.6202204\tbest: 251.6202204 (11800)\ttotal: 5m 38s\tremaining: 3m 54s\n",
      "11900:\tlearn: 250.8143657\ttest: 251.3337820\tbest: 251.3335065 (11894)\ttotal: 5m 41s\tremaining: 3m 52s\n",
      "12000:\tlearn: 250.4914636\ttest: 251.1782464\tbest: 251.1782464 (12000)\ttotal: 5m 44s\tremaining: 3m 49s\n",
      "12100:\tlearn: 250.2658212\ttest: 250.9963054\tbest: 250.9963054 (12100)\ttotal: 5m 46s\tremaining: 3m 46s\n",
      "12200:\tlearn: 250.0542849\ttest: 250.8799718\tbest: 250.8799718 (12200)\ttotal: 5m 49s\tremaining: 3m 43s\n",
      "12300:\tlearn: 249.8376236\ttest: 250.7276691\tbest: 250.7276691 (12300)\ttotal: 5m 52s\tremaining: 3m 40s\n",
      "12400:\tlearn: 249.6224658\ttest: 250.6336607\tbest: 250.6268758 (12395)\ttotal: 5m 55s\tremaining: 3m 38s\n",
      "12500:\tlearn: 249.3976488\ttest: 250.5240707\tbest: 250.5239846 (12499)\ttotal: 5m 58s\tremaining: 3m 35s\n",
      "12600:\tlearn: 249.1939390\ttest: 250.3893161\tbest: 250.3886668 (12596)\ttotal: 6m 1s\tremaining: 3m 32s\n",
      "12700:\tlearn: 249.0158559\ttest: 250.2811209\tbest: 250.2811208 (12698)\ttotal: 6m 3s\tremaining: 3m 29s\n",
      "12800:\tlearn: 248.7375332\ttest: 250.0597207\tbest: 250.0597207 (12800)\ttotal: 6m 7s\tremaining: 3m 26s\n",
      "12900:\tlearn: 248.4778700\ttest: 249.8566608\tbest: 249.8547668 (12879)\ttotal: 6m 10s\tremaining: 3m 23s\n",
      "13000:\tlearn: 248.1259291\ttest: 249.6235056\tbest: 249.6235049 (12999)\ttotal: 6m 13s\tremaining: 3m 21s\n",
      "13100:\tlearn: 247.7324176\ttest: 249.3750765\tbest: 249.3744765 (13097)\ttotal: 6m 16s\tremaining: 3m 18s\n",
      "13200:\tlearn: 247.3720836\ttest: 249.1767481\tbest: 249.1739316 (13198)\ttotal: 6m 19s\tremaining: 3m 15s\n",
      "13300:\tlearn: 247.1399480\ttest: 249.0449541\tbest: 249.0436338 (13297)\ttotal: 6m 23s\tremaining: 3m 13s\n",
      "13400:\tlearn: 246.7449184\ttest: 248.7845476\tbest: 248.7845476 (13400)\ttotal: 6m 27s\tremaining: 3m 10s\n",
      "13500:\tlearn: 246.4803186\ttest: 248.6076738\tbest: 248.6076738 (13500)\ttotal: 6m 30s\tremaining: 3m 7s\n",
      "13600:\tlearn: 246.1919349\ttest: 248.4458369\tbest: 248.4432210 (13591)\ttotal: 6m 33s\tremaining: 3m 5s\n",
      "13700:\tlearn: 245.8822249\ttest: 248.2123056\tbest: 248.2122187 (13699)\ttotal: 6m 36s\tremaining: 3m 2s\n",
      "13800:\tlearn: 245.5158104\ttest: 247.9835053\tbest: 247.9835053 (13800)\ttotal: 6m 40s\tremaining: 2m 59s\n",
      "13900:\tlearn: 245.2031150\ttest: 247.7929298\tbest: 247.7929298 (13900)\ttotal: 6m 43s\tremaining: 2m 57s\n",
      "14000:\tlearn: 244.9006099\ttest: 247.5442685\tbest: 247.5415423 (13971)\ttotal: 6m 46s\tremaining: 2m 54s\n",
      "14100:\tlearn: 244.7630252\ttest: 247.4938537\tbest: 247.4938483 (14099)\ttotal: 6m 49s\tremaining: 2m 51s\n",
      "14200:\tlearn: 244.6909801\ttest: 247.4410536\tbest: 247.4410536 (14200)\ttotal: 6m 52s\tremaining: 2m 48s\n",
      "14300:\tlearn: 244.6027570\ttest: 247.4225338\tbest: 247.4218040 (14294)\ttotal: 6m 54s\tremaining: 2m 45s\n",
      "14400:\tlearn: 244.4257229\ttest: 247.3035651\tbest: 247.3035598 (14399)\ttotal: 6m 57s\tremaining: 2m 42s\n",
      "14500:\tlearn: 244.1921719\ttest: 247.1615008\tbest: 247.1615008 (14500)\ttotal: 7m\tremaining: 2m 39s\n",
      "14600:\tlearn: 243.9622773\ttest: 246.9756073\tbest: 246.9756073 (14600)\ttotal: 7m 3s\tremaining: 2m 36s\n",
      "14700:\tlearn: 243.8617883\ttest: 246.8951404\tbest: 246.8950108 (14698)\ttotal: 7m 6s\tremaining: 2m 33s\n",
      "14800:\tlearn: 243.7035771\ttest: 246.8179924\tbest: 246.8179898 (14799)\ttotal: 7m 8s\tremaining: 2m 30s\n",
      "14900:\tlearn: 243.5678852\ttest: 246.7089744\tbest: 246.7089744 (14900)\ttotal: 7m 11s\tremaining: 2m 27s\n",
      "15000:\tlearn: 243.4268430\ttest: 246.6473681\tbest: 246.6472806 (14990)\ttotal: 7m 14s\tremaining: 2m 24s\n",
      "15100:\tlearn: 243.3820294\ttest: 246.5997469\tbest: 246.5997467 (15098)\ttotal: 7m 16s\tremaining: 2m 21s\n",
      "15200:\tlearn: 243.2295629\ttest: 246.5004771\tbest: 246.5004476 (15199)\ttotal: 7m 19s\tremaining: 2m 18s\n",
      "15300:\tlearn: 243.1091010\ttest: 246.4158003\tbest: 246.4155372 (15294)\ttotal: 7m 22s\tremaining: 2m 15s\n",
      "15400:\tlearn: 242.9898690\ttest: 246.3086547\tbest: 246.3081334 (15391)\ttotal: 7m 25s\tremaining: 2m 13s\n",
      "15500:\tlearn: 242.9712747\ttest: 246.3002888\tbest: 246.3002888 (15500)\ttotal: 7m 27s\tremaining: 2m 10s\n",
      "15600:\tlearn: 242.8707894\ttest: 246.2276353\tbest: 246.2276353 (15600)\ttotal: 7m 30s\tremaining: 2m 7s\n",
      "15700:\tlearn: 242.7441414\ttest: 246.1466733\tbest: 246.1466733 (15700)\ttotal: 7m 33s\tremaining: 2m 4s\n",
      "15800:\tlearn: 242.5265441\ttest: 246.0386081\tbest: 246.0386081 (15800)\ttotal: 7m 36s\tremaining: 2m 1s\n",
      "15900:\tlearn: 242.4154744\ttest: 246.0154154\tbest: 246.0153670 (15898)\ttotal: 7m 39s\tremaining: 1m 58s\n",
      "16000:\tlearn: 242.0958856\ttest: 245.8394145\tbest: 245.8393947 (15998)\ttotal: 7m 42s\tremaining: 1m 55s\n",
      "16100:\tlearn: 241.9628529\ttest: 245.7600138\tbest: 245.7594781 (16096)\ttotal: 7m 45s\tremaining: 1m 52s\n",
      "16200:\tlearn: 241.8597965\ttest: 245.7027296\tbest: 245.7027296 (16200)\ttotal: 7m 48s\tremaining: 1m 49s\n",
      "16300:\tlearn: 241.6124545\ttest: 245.5264560\tbest: 245.5264560 (16300)\ttotal: 7m 51s\tremaining: 1m 46s\n",
      "16400:\tlearn: 241.4612065\ttest: 245.3961223\tbest: 245.3961223 (16400)\ttotal: 7m 54s\tremaining: 1m 44s\n",
      "16500:\tlearn: 241.2403665\ttest: 245.2657585\tbest: 245.2656630 (16498)\ttotal: 7m 57s\tremaining: 1m 41s\n",
      "16600:\tlearn: 241.0638295\ttest: 245.1848949\tbest: 245.1848949 (16600)\ttotal: 8m\tremaining: 1m 38s\n",
      "16700:\tlearn: 240.8109967\ttest: 245.0345575\tbest: 245.0320824 (16698)\ttotal: 8m 3s\tremaining: 1m 35s\n",
      "16800:\tlearn: 240.6567947\ttest: 244.9036484\tbest: 244.9035178 (16791)\ttotal: 8m 7s\tremaining: 1m 32s\n",
      "16900:\tlearn: 240.5096772\ttest: 244.8032581\tbest: 244.8032581 (16900)\ttotal: 8m 10s\tremaining: 1m 29s\n",
      "17000:\tlearn: 240.4452332\ttest: 244.7647855\tbest: 244.7631750 (16989)\ttotal: 8m 12s\tremaining: 1m 26s\n",
      "17100:\tlearn: 240.2783857\ttest: 244.6278843\tbest: 244.6278843 (17100)\ttotal: 8m 15s\tremaining: 1m 24s\n",
      "17200:\tlearn: 240.1587431\ttest: 244.5626643\tbest: 244.5598184 (17179)\ttotal: 8m 18s\tremaining: 1m 21s\n",
      "17300:\tlearn: 240.0077201\ttest: 244.4704226\tbest: 244.4698465 (17292)\ttotal: 8m 21s\tremaining: 1m 18s\n",
      "17400:\tlearn: 239.8419504\ttest: 244.3865943\tbest: 244.3865943 (17400)\ttotal: 8m 25s\tremaining: 1m 15s\n",
      "17500:\tlearn: 239.6550326\ttest: 244.2452637\tbest: 244.2452637 (17500)\ttotal: 8m 28s\tremaining: 1m 12s\n",
      "17600:\tlearn: 239.4574507\ttest: 244.0850857\tbest: 244.0850857 (17600)\ttotal: 8m 31s\tremaining: 1m 9s\n",
      "17700:\tlearn: 239.1587246\ttest: 243.8578590\tbest: 243.8578590 (17700)\ttotal: 8m 35s\tremaining: 1m 6s\n",
      "17800:\tlearn: 239.0129006\ttest: 243.7738889\tbest: 243.7718244 (17787)\ttotal: 8m 38s\tremaining: 1m 4s\n",
      "17900:\tlearn: 238.8881642\ttest: 243.7086350\tbest: 243.7073713 (17895)\ttotal: 8m 41s\tremaining: 1m 1s\n",
      "18000:\tlearn: 238.7736967\ttest: 243.6235864\tbest: 243.6235864 (18000)\ttotal: 8m 44s\tremaining: 58.3s\n",
      "18100:\tlearn: 238.6033511\ttest: 243.4840711\tbest: 243.4829214 (18096)\ttotal: 8m 48s\tremaining: 55.4s\n",
      "18200:\tlearn: 238.4866496\ttest: 243.3953884\tbest: 243.3929198 (18197)\ttotal: 8m 51s\tremaining: 52.5s\n",
      "18300:\tlearn: 238.2521743\ttest: 243.2495589\tbest: 243.2494987 (18299)\ttotal: 8m 54s\tremaining: 49.6s\n",
      "18400:\tlearn: 238.0632078\ttest: 243.1413757\tbest: 243.1413582 (18399)\ttotal: 8m 57s\tremaining: 46.7s\n",
      "18500:\tlearn: 237.8055844\ttest: 242.9583634\tbest: 242.9583634 (18500)\ttotal: 9m 1s\tremaining: 43.9s\n",
      "18600:\tlearn: 237.6548258\ttest: 242.8654295\tbest: 242.8626560 (18583)\ttotal: 9m 4s\tremaining: 41s\n",
      "18700:\tlearn: 237.5612023\ttest: 242.8409168\tbest: 242.8371960 (18679)\ttotal: 9m 7s\tremaining: 38.1s\n",
      "18800:\tlearn: 237.5220277\ttest: 242.8250657\tbest: 242.8250644 (18798)\ttotal: 9m 10s\tremaining: 35.1s\n",
      "18900:\tlearn: 237.4806801\ttest: 242.7983278\tbest: 242.7983277 (18898)\ttotal: 9m 13s\tremaining: 32.2s\n",
      "19000:\tlearn: 237.3433311\ttest: 242.7238109\tbest: 242.7238098 (18998)\ttotal: 9m 16s\tremaining: 29.2s\n",
      "19100:\tlearn: 237.2403030\ttest: 242.6423441\tbest: 242.6423095 (19099)\ttotal: 9m 19s\tremaining: 26.3s\n",
      "19200:\tlearn: 237.1172625\ttest: 242.5715804\tbest: 242.5715803 (19198)\ttotal: 9m 22s\tremaining: 23.4s\n",
      "19300:\tlearn: 237.0423906\ttest: 242.5550213\tbest: 242.5550213 (19300)\ttotal: 9m 26s\tremaining: 20.5s\n",
      "19400:\tlearn: 236.9649750\ttest: 242.5011617\tbest: 242.5005970 (19392)\ttotal: 9m 29s\tremaining: 17.6s\n",
      "19500:\tlearn: 236.9140102\ttest: 242.4630502\tbest: 242.4607184 (19493)\ttotal: 9m 32s\tremaining: 14.7s\n",
      "19600:\tlearn: 236.8052202\ttest: 242.3867602\tbest: 242.3867602 (19600)\ttotal: 9m 36s\tremaining: 11.7s\n",
      "19700:\tlearn: 236.6125962\ttest: 242.2795878\tbest: 242.2793991 (19699)\ttotal: 9m 39s\tremaining: 8.79s\n",
      "19800:\tlearn: 236.4140124\ttest: 242.1277146\tbest: 242.1275613 (19791)\ttotal: 9m 42s\tremaining: 5.86s\n",
      "19900:\tlearn: 236.1561297\ttest: 241.9549200\tbest: 241.9546064 (19899)\ttotal: 9m 45s\tremaining: 2.92s\n",
      "19999:\tlearn: 235.9791527\ttest: 241.8404824\tbest: 241.8385361 (19993)\ttotal: 9m 49s\tremaining: 0us\n",
      "\n",
      "bestTest = 241.8385361\n",
      "bestIteration = 19993\n",
      "\n",
      "Shrink model to first 19994 iterations.",
      "\n",
      "0:\tlearn: 983.5631227\ttest: 980.4202629\tbest: 980.4202629 (0)\ttotal: 36.6ms\tremaining: 12m 12s\n",
      "100:\tlearn: 616.2471563\ttest: 611.0979222\tbest: 611.0979222 (100)\ttotal: 3.24s\tremaining: 10m 37s\n",
      "200:\tlearn: 495.2161501\ttest: 496.6021502\tbest: 496.6021502 (200)\ttotal: 6.69s\tremaining: 10m 59s\n",
      "300:\tlearn: 437.5779684\ttest: 441.0417063\tbest: 441.0417063 (300)\ttotal: 10.1s\tremaining: 11m 2s\n",
      "400:\tlearn: 412.8477839\ttest: 417.8147983\tbest: 417.8147983 (400)\ttotal: 13.7s\tremaining: 11m 7s\n",
      "500:\tlearn: 397.9982864\ttest: 403.9018870\tbest: 403.9018870 (500)\ttotal: 16.8s\tremaining: 10m 55s\n",
      "600:\tlearn: 387.0097965\ttest: 394.5856715\tbest: 394.5856715 (600)\ttotal: 19.9s\tremaining: 10m 40s\n",
      "700:\tlearn: 379.2500095\ttest: 387.9413880\tbest: 387.9413880 (700)\ttotal: 22.9s\tremaining: 10m 29s\n",
      "800:\tlearn: 371.7802234\ttest: 381.1044371\tbest: 381.1044371 (800)\ttotal: 26.1s\tremaining: 10m 26s\n",
      "900:\tlearn: 364.8009357\ttest: 375.0626535\tbest: 375.0626535 (900)\ttotal: 29.1s\tremaining: 10m 16s\n",
      "1000:\tlearn: 358.4345174\ttest: 369.3725635\tbest: 369.3725635 (1000)\ttotal: 32.3s\tremaining: 10m 13s\n",
      "1100:\tlearn: 350.4245815\ttest: 361.8699473\tbest: 361.8699473 (1100)\ttotal: 35.7s\tremaining: 10m 13s\n",
      "1200:\tlearn: 343.5431216\ttest: 355.1828413\tbest: 355.1828413 (1200)\ttotal: 39.1s\tremaining: 10m 11s\n",
      "1300:\tlearn: 336.6772349\ttest: 348.4268389\tbest: 348.4268389 (1300)\ttotal: 42.5s\tremaining: 10m 10s\n",
      "1400:\tlearn: 331.1002030\ttest: 342.7075300\tbest: 342.7075300 (1400)\ttotal: 45.9s\tremaining: 10m 8s\n",
      "1500:\tlearn: 326.3989854\ttest: 337.6239291\tbest: 337.6239291 (1500)\ttotal: 49.2s\tremaining: 10m 6s\n",
      "1600:\tlearn: 321.2049947\ttest: 332.5849376\tbest: 332.5849376 (1600)\ttotal: 52.8s\tremaining: 10m 6s\n",
      "1700:\tlearn: 317.7479395\ttest: 329.1875714\tbest: 329.1875714 (1700)\ttotal: 56.4s\tremaining: 10m 6s\n",
      "1800:\tlearn: 314.4521969\ttest: 326.0599361\tbest: 326.0581479 (1798)\ttotal: 59.7s\tremaining: 10m 3s\n",
      "1900:\tlearn: 311.6585984\ttest: 323.2119740\tbest: 323.2119740 (1900)\ttotal: 1m 2s\tremaining: 9m 59s\n",
      "2000:\tlearn: 309.0821737\ttest: 320.9252235\tbest: 320.9252235 (2000)\ttotal: 1m 6s\tremaining: 9m 55s\n",
      "2100:\tlearn: 306.5380121\ttest: 318.3566487\tbest: 318.3566487 (2100)\ttotal: 1m 9s\tremaining: 9m 54s\n",
      "2200:\tlearn: 304.5718925\ttest: 316.3496988\tbest: 316.3496988 (2200)\ttotal: 1m 13s\tremaining: 9m 52s\n",
      "2300:\tlearn: 302.6636115\ttest: 314.4438642\tbest: 314.4438642 (2300)\ttotal: 1m 16s\tremaining: 9m 49s\n",
      "2400:\tlearn: 300.7387594\ttest: 312.4017336\tbest: 312.4017336 (2400)\ttotal: 1m 19s\tremaining: 9m 45s\n",
      "2500:\tlearn: 298.8686057\ttest: 310.8475165\tbest: 310.8475165 (2500)\ttotal: 1m 23s\tremaining: 9m 41s\n",
      "2600:\tlearn: 297.2959712\ttest: 309.2594236\tbest: 309.2594236 (2600)\ttotal: 1m 26s\tremaining: 9m 36s\n",
      "2700:\tlearn: 295.6385924\ttest: 307.8025491\tbest: 307.8025491 (2700)\ttotal: 1m 29s\tremaining: 9m 31s\n",
      "2800:\tlearn: 294.6660114\ttest: 306.9131201\tbest: 306.9131201 (2800)\ttotal: 1m 32s\tremaining: 9m 28s\n",
      "2900:\tlearn: 293.4057838\ttest: 305.8029871\tbest: 305.8029871 (2900)\ttotal: 1m 36s\tremaining: 9m 30s\n",
      "3000:\tlearn: 292.3459577\ttest: 304.7260874\tbest: 304.7260874 (3000)\ttotal: 1m 40s\tremaining: 9m 27s\n",
      "3100:\tlearn: 291.1349790\ttest: 303.7402425\tbest: 303.7402425 (3100)\ttotal: 1m 43s\tremaining: 9m 22s\n",
      "3200:\tlearn: 290.0143021\ttest: 302.7542542\tbest: 302.7542542 (3200)\ttotal: 1m 46s\tremaining: 9m 18s\n",
      "3300:\tlearn: 289.0083374\ttest: 301.7750921\tbest: 301.7750921 (3300)\ttotal: 1m 49s\tremaining: 9m 11s\n",
      "3400:\tlearn: 287.8283193\ttest: 300.7925468\tbest: 300.7925015 (3399)\ttotal: 1m 52s\tremaining: 9m 7s\n",
      "3500:\tlearn: 286.6789579\ttest: 299.7275569\tbest: 299.7275569 (3500)\ttotal: 1m 55s\tremaining: 9m 3s\n",
      "3600:\tlearn: 285.5953794\ttest: 298.8190999\tbest: 298.8182974 (3594)\ttotal: 1m 58s\tremaining: 8m 58s\n",
      "3700:\tlearn: 284.6645687\ttest: 297.8373218\tbest: 297.8362769 (3699)\ttotal: 2m 1s\tremaining: 8m 54s\n",
      "3800:\tlearn: 283.6004528\ttest: 296.9420244\tbest: 296.9420244 (3800)\ttotal: 2m 4s\tremaining: 8m 49s\n",
      "3900:\tlearn: 282.4781841\ttest: 296.0906682\tbest: 296.0906682 (3900)\ttotal: 2m 7s\tremaining: 8m 44s\n",
      "4000:\tlearn: 281.2524266\ttest: 295.0878429\tbest: 295.0851311 (3997)\ttotal: 2m 10s\tremaining: 8m 40s\n",
      "4100:\tlearn: 280.0892638\ttest: 294.0206358\tbest: 294.0205354 (4099)\ttotal: 2m 13s\tremaining: 8m 36s\n",
      "4200:\tlearn: 279.1305788\ttest: 293.1397552\tbest: 293.1397552 (4200)\ttotal: 2m 16s\tremaining: 8m 33s\n",
      "4300:\tlearn: 278.5600033\ttest: 292.6127926\tbest: 292.6127926 (4300)\ttotal: 2m 19s\tremaining: 8m 28s\n",
      "4400:\tlearn: 277.8261070\ttest: 292.0401829\tbest: 292.0401829 (4400)\ttotal: 2m 22s\tremaining: 8m 25s\n",
      "4500:\tlearn: 276.9587473\ttest: 291.0627341\tbest: 291.0627341 (4500)\ttotal: 2m 26s\tremaining: 8m 23s\n",
      "4600:\tlearn: 276.0494427\ttest: 290.3974618\tbest: 290.3974618 (4600)\ttotal: 2m 29s\tremaining: 8m 20s\n",
      "4700:\tlearn: 275.1403237\ttest: 289.5752918\tbest: 289.5752918 (4700)\ttotal: 2m 33s\tremaining: 8m 18s\n",
      "4800:\tlearn: 274.4215069\ttest: 289.0375232\tbest: 289.0373809 (4798)\ttotal: 2m 36s\tremaining: 8m 16s\n",
      "4900:\tlearn: 273.6877336\ttest: 288.3870233\tbest: 288.3870233 (4900)\ttotal: 2m 40s\tremaining: 8m 15s\n",
      "5000:\tlearn: 272.9606266\ttest: 287.6504002\tbest: 287.6504002 (5000)\ttotal: 2m 44s\tremaining: 8m 13s\n",
      "5100:\tlearn: 272.3335587\ttest: 287.1575041\tbest: 287.1575041 (5100)\ttotal: 2m 47s\tremaining: 8m 10s\n",
      "5200:\tlearn: 271.6780834\ttest: 286.5938675\tbest: 286.5938675 (5200)\ttotal: 2m 51s\tremaining: 8m 6s\n",
      "5300:\tlearn: 271.0103138\ttest: 285.8798623\tbest: 285.8798623 (5300)\ttotal: 2m 54s\tremaining: 8m 3s\n",
      "5400:\tlearn: 270.5789787\ttest: 285.5560926\tbest: 285.5560926 (5400)\ttotal: 2m 57s\tremaining: 7m 59s\n",
      "5500:\tlearn: 269.8707859\ttest: 284.9859831\tbest: 284.9840454 (5497)\ttotal: 3m\tremaining: 7m 56s\n",
      "5600:\tlearn: 269.2754642\ttest: 284.5124149\tbest: 284.5124149 (5600)\ttotal: 3m 4s\tremaining: 7m 53s\n",
      "5700:\tlearn: 268.8156660\ttest: 284.1429681\tbest: 284.1428743 (5690)\ttotal: 3m 6s\tremaining: 7m 47s\n",
      "5800:\tlearn: 268.4054230\ttest: 283.8040603\tbest: 283.8040603 (5800)\ttotal: 3m 9s\tremaining: 7m 42s\n",
      "5900:\tlearn: 267.8006488\ttest: 283.2228342\tbest: 283.2198757 (5890)\ttotal: 3m 12s\tremaining: 7m 38s\n",
      "6000:\tlearn: 267.3606480\ttest: 282.7744066\tbest: 282.7744066 (6000)\ttotal: 3m 15s\tremaining: 7m 35s\n",
      "6100:\tlearn: 266.8028808\ttest: 282.2910211\tbest: 282.2906998 (6094)\ttotal: 3m 18s\tremaining: 7m 32s\n",
      "6200:\tlearn: 266.1997320\ttest: 281.8207940\tbest: 281.8189076 (6197)\ttotal: 3m 21s\tremaining: 7m 28s\n",
      "6300:\tlearn: 265.6292845\ttest: 281.4402493\tbest: 281.4402493 (6300)\ttotal: 3m 24s\tremaining: 7m 25s\n",
      "6400:\tlearn: 265.1085998\ttest: 281.0501133\tbest: 281.0501133 (6400)\ttotal: 3m 28s\tremaining: 7m 21s\n",
      "6500:\tlearn: 264.7095873\ttest: 280.7108912\tbest: 280.7108912 (6500)\ttotal: 3m 31s\tremaining: 7m 18s\n",
      "6600:\tlearn: 264.2144659\ttest: 280.3341962\tbest: 280.3337546 (6594)\ttotal: 3m 34s\tremaining: 7m 15s\n",
      "6700:\tlearn: 263.7089609\ttest: 279.9375063\tbest: 279.9351951 (6693)\ttotal: 3m 38s\tremaining: 7m 13s\n",
      "6800:\tlearn: 263.2879336\ttest: 279.6867559\tbest: 279.6867524 (6799)\ttotal: 3m 41s\tremaining: 7m 9s\n",
      "6900:\tlearn: 262.8706386\ttest: 279.3834169\tbest: 279.3834169 (6900)\ttotal: 3m 44s\tremaining: 7m 5s\n",
      "7000:\tlearn: 262.5192523\ttest: 279.1227413\tbest: 279.1227413 (7000)\ttotal: 3m 47s\tremaining: 7m 2s\n",
      "7100:\tlearn: 262.1495780\ttest: 278.8785352\tbest: 278.8785352 (7100)\ttotal: 3m 50s\tremaining: 6m 58s\n",
      "7200:\tlearn: 261.6511090\ttest: 278.4534520\tbest: 278.4534520 (7200)\ttotal: 3m 53s\tremaining: 6m 55s\n",
      "7300:\tlearn: 261.1954950\ttest: 278.0307597\tbest: 278.0301994 (7284)\ttotal: 3m 56s\tremaining: 6m 51s\n",
      "7400:\tlearn: 260.8835724\ttest: 277.8303019\tbest: 277.8303019 (7400)\ttotal: 3m 59s\tremaining: 6m 48s\n",
      "7500:\tlearn: 260.3962446\ttest: 277.4298823\tbest: 277.4298823 (7500)\ttotal: 4m 3s\tremaining: 6m 45s\n",
      "7600:\tlearn: 260.0034198\ttest: 277.0331594\tbest: 277.0331594 (7600)\ttotal: 4m 6s\tremaining: 6m 41s\n",
      "7700:\tlearn: 259.8384246\ttest: 276.8768113\tbest: 276.8768113 (7700)\ttotal: 4m 9s\tremaining: 6m 37s\n",
      "7800:\tlearn: 259.4602223\ttest: 276.5483777\tbest: 276.5483597 (7799)\ttotal: 4m 12s\tremaining: 6m 34s\n",
      "7900:\tlearn: 259.0244818\ttest: 276.1546117\tbest: 276.1546117 (7900)\ttotal: 4m 15s\tremaining: 6m 30s\n",
      "8000:\tlearn: 258.6564529\ttest: 275.7865015\tbest: 275.7861753 (7993)\ttotal: 4m 18s\tremaining: 6m 27s\n",
      "8100:\tlearn: 258.0679784\ttest: 275.3144810\tbest: 275.3144810 (8100)\ttotal: 4m 21s\tremaining: 6m 24s\n",
      "8200:\tlearn: 257.8086241\ttest: 275.1411205\tbest: 275.1392326 (8195)\ttotal: 4m 24s\tremaining: 6m 20s\n",
      "8300:\tlearn: 257.4459321\ttest: 274.9268076\tbest: 274.9266779 (8297)\ttotal: 4m 27s\tremaining: 6m 17s\n",
      "8400:\tlearn: 257.0117704\ttest: 274.6274478\tbest: 274.6220772 (8396)\ttotal: 4m 30s\tremaining: 6m 13s\n",
      "8500:\tlearn: 256.7295695\ttest: 274.3563555\tbest: 274.3540956 (8496)\ttotal: 4m 33s\tremaining: 6m 9s\n",
      "8600:\tlearn: 256.4503295\ttest: 274.1782433\tbest: 274.1782433 (8600)\ttotal: 4m 36s\tremaining: 6m 6s\n",
      "8700:\tlearn: 256.2136359\ttest: 274.0074473\tbest: 274.0074473 (8700)\ttotal: 4m 39s\tremaining: 6m 2s\n",
      "8800:\tlearn: 255.8996007\ttest: 273.7323916\tbest: 273.7323916 (8800)\ttotal: 4m 42s\tremaining: 5m 59s\n",
      "8900:\tlearn: 255.5128346\ttest: 273.4742915\tbest: 273.4742915 (8900)\ttotal: 4m 45s\tremaining: 5m 55s\n",
      "9000:\tlearn: 255.0735395\ttest: 273.1280006\tbest: 273.1280006 (9000)\ttotal: 4m 48s\tremaining: 5m 52s\n",
      "9100:\tlearn: 254.8273700\ttest: 272.9555010\tbest: 272.9555010 (9100)\ttotal: 4m 51s\tremaining: 5m 48s\n",
      "9200:\tlearn: 254.4683832\ttest: 272.7010480\tbest: 272.7010480 (9200)\ttotal: 4m 54s\tremaining: 5m 45s\n",
      "9300:\tlearn: 254.1314918\ttest: 272.4007311\tbest: 272.4007311 (9300)\ttotal: 4m 57s\tremaining: 5m 41s\n",
      "9400:\tlearn: 253.6671616\ttest: 271.9974797\tbest: 271.9974578 (9398)\ttotal: 5m\tremaining: 5m 38s\n",
      "9500:\tlearn: 253.1871384\ttest: 271.6014018\tbest: 271.6013141 (9499)\ttotal: 5m 3s\tremaining: 5m 35s\n",
      "9600:\tlearn: 252.8534182\ttest: 271.3816706\tbest: 271.3816706 (9600)\ttotal: 5m 6s\tremaining: 5m 31s\n",
      "9700:\tlearn: 252.5498556\ttest: 271.1497328\tbest: 271.1497328 (9700)\ttotal: 5m 9s\tremaining: 5m 28s\n",
      "9800:\tlearn: 252.2736583\ttest: 270.9993504\tbest: 270.9992733 (9796)\ttotal: 5m 12s\tremaining: 5m 24s\n",
      "9900:\tlearn: 251.9067387\ttest: 270.7577460\tbest: 270.7577460 (9900)\ttotal: 5m 15s\tremaining: 5m 21s\n",
      "10000:\tlearn: 251.6738939\ttest: 270.5924090\tbest: 270.5901779 (9987)\ttotal: 5m 18s\tremaining: 5m 18s\n",
      "10100:\tlearn: 251.4193818\ttest: 270.4259885\tbest: 270.4259885 (10100)\ttotal: 5m 21s\tremaining: 5m 15s\n",
      "10200:\tlearn: 251.2100851\ttest: 270.2847560\tbest: 270.2838740 (10192)\ttotal: 5m 24s\tremaining: 5m 11s\n",
      "10300:\tlearn: 250.9689286\ttest: 270.0701486\tbest: 270.0701051 (10299)\ttotal: 5m 27s\tremaining: 5m 8s\n",
      "10400:\tlearn: 250.7037511\ttest: 269.8660539\tbest: 269.8635289 (10397)\ttotal: 5m 30s\tremaining: 5m 4s\n",
      "10500:\tlearn: 250.4561105\ttest: 269.7230479\tbest: 269.7230479 (10500)\ttotal: 5m 33s\tremaining: 5m 1s\n",
      "10600:\tlearn: 250.1820103\ttest: 269.5286387\tbest: 269.5286387 (10600)\ttotal: 5m 36s\tremaining: 4m 58s\n",
      "10700:\tlearn: 249.8583075\ttest: 269.3311400\tbest: 269.3310640 (10699)\ttotal: 5m 39s\tremaining: 4m 55s\n",
      "10800:\tlearn: 249.5810196\ttest: 269.1714865\tbest: 269.1710926 (10796)\ttotal: 5m 42s\tremaining: 4m 51s\n",
      "10900:\tlearn: 249.3381958\ttest: 269.0301251\tbest: 269.0301251 (10900)\ttotal: 5m 45s\tremaining: 4m 48s\n",
      "11000:\tlearn: 249.0618311\ttest: 268.7861975\tbest: 268.7861975 (11000)\ttotal: 5m 48s\tremaining: 4m 45s\n",
      "11100:\tlearn: 248.8238143\ttest: 268.5896418\tbest: 268.5896418 (11100)\ttotal: 5m 51s\tremaining: 4m 41s\n",
      "11200:\tlearn: 248.5608036\ttest: 268.4812449\tbest: 268.4812449 (11200)\ttotal: 5m 54s\tremaining: 4m 38s\n",
      "11300:\tlearn: 248.2581826\ttest: 268.2717480\tbest: 268.2717480 (11300)\ttotal: 5m 57s\tremaining: 4m 35s\n",
      "11400:\tlearn: 247.9660764\ttest: 268.0224765\tbest: 268.0216709 (11396)\ttotal: 6m 1s\tremaining: 4m 32s\n",
      "11500:\tlearn: 247.7700435\ttest: 267.8776181\tbest: 267.8775431 (11498)\ttotal: 6m 4s\tremaining: 4m 29s\n",
      "11600:\tlearn: 247.5336220\ttest: 267.7211721\tbest: 267.7210451 (11596)\ttotal: 6m 7s\tremaining: 4m 26s\n",
      "11700:\tlearn: 247.1826404\ttest: 267.3949861\tbest: 267.3949861 (11700)\ttotal: 6m 11s\tremaining: 4m 23s\n",
      "11800:\tlearn: 246.9381601\ttest: 267.1956006\tbest: 267.1956006 (11800)\ttotal: 6m 14s\tremaining: 4m 20s\n",
      "11900:\tlearn: 246.7179504\ttest: 267.0363015\tbest: 267.0361282 (11897)\ttotal: 6m 17s\tremaining: 4m 16s\n",
      "12000:\tlearn: 246.5874528\ttest: 266.9030532\tbest: 266.9025460 (11995)\ttotal: 6m 20s\tremaining: 4m 13s\n",
      "12100:\tlearn: 246.3023547\ttest: 266.7370377\tbest: 266.7369810 (12098)\ttotal: 6m 23s\tremaining: 4m 10s\n",
      "12200:\tlearn: 246.1392024\ttest: 266.6472784\tbest: 266.6470175 (12191)\ttotal: 6m 26s\tremaining: 4m 7s\n",
      "12300:\tlearn: 245.9294190\ttest: 266.5252929\tbest: 266.5200704 (12288)\ttotal: 6m 29s\tremaining: 4m 3s\n",
      "12400:\tlearn: 245.7304160\ttest: 266.3839210\tbest: 266.3838450 (12395)\ttotal: 6m 32s\tremaining: 4m\n",
      "12500:\tlearn: 245.5452929\ttest: 266.2089949\tbest: 266.2089949 (12500)\ttotal: 6m 35s\tremaining: 3m 57s\n",
      "12600:\tlearn: 245.3122710\ttest: 266.0316656\tbest: 266.0316090 (12598)\ttotal: 6m 38s\tremaining: 3m 54s\n",
      "12700:\tlearn: 245.1319806\ttest: 265.8864076\tbest: 265.8863907 (12699)\ttotal: 6m 41s\tremaining: 3m 50s\n",
      "12800:\tlearn: 244.8279935\ttest: 265.6741172\tbest: 265.6728345 (12795)\ttotal: 6m 44s\tremaining: 3m 47s\n",
      "12900:\tlearn: 244.5994592\ttest: 265.4861436\tbest: 265.4860755 (12897)\ttotal: 6m 47s\tremaining: 3m 44s\n",
      "13000:\tlearn: 244.4037720\ttest: 265.3529529\tbest: 265.3510844 (12971)\ttotal: 6m 49s\tremaining: 3m 40s\n",
      "13100:\tlearn: 244.2036102\ttest: 265.1893969\tbest: 265.1860955 (13097)\ttotal: 6m 52s\tremaining: 3m 37s\n",
      "13200:\tlearn: 244.0440915\ttest: 265.0852025\tbest: 265.0848427 (13197)\ttotal: 6m 55s\tremaining: 3m 34s\n",
      "13300:\tlearn: 243.8856120\ttest: 265.0056923\tbest: 265.0056923 (13300)\ttotal: 6m 58s\tremaining: 3m 30s\n",
      "13400:\tlearn: 243.8024112\ttest: 264.9729662\tbest: 264.9700512 (13359)\ttotal: 7m 1s\tremaining: 3m 27s\n",
      "13500:\tlearn: 243.6472863\ttest: 264.8884603\tbest: 264.8884603 (13500)\ttotal: 7m 4s\tremaining: 3m 24s\n",
      "13600:\tlearn: 243.3804131\ttest: 264.7246678\tbest: 264.7244890 (13595)\ttotal: 7m 6s\tremaining: 3m 20s\n",
      "13700:\tlearn: 243.1602172\ttest: 264.5673094\tbest: 264.5673094 (13700)\ttotal: 7m 9s\tremaining: 3m 17s\n",
      "13800:\tlearn: 242.9203287\ttest: 264.3910159\tbest: 264.3910159 (13800)\ttotal: 7m 12s\tremaining: 3m 14s\n",
      "13900:\tlearn: 242.7709436\ttest: 264.3172665\tbest: 264.3172262 (13899)\ttotal: 7m 15s\tremaining: 3m 11s\n",
      "14000:\tlearn: 242.6478375\ttest: 264.1963255\tbest: 264.1959767 (13998)\ttotal: 7m 18s\tremaining: 3m 7s\n",
      "14100:\tlearn: 242.4487339\ttest: 264.0786953\tbest: 264.0785913 (14099)\ttotal: 7m 21s\tremaining: 3m 4s\n",
      "14200:\tlearn: 242.3001932\ttest: 263.9728630\tbest: 263.9723114 (14198)\ttotal: 7m 24s\tremaining: 3m 1s\n",
      "14300:\tlearn: 242.1589359\ttest: 263.8760574\tbest: 263.8760574 (14300)\ttotal: 7m 27s\tremaining: 2m 58s\n",
      "14400:\tlearn: 242.0596814\ttest: 263.8282916\tbest: 263.8254817 (14379)\ttotal: 7m 29s\tremaining: 2m 54s\n",
      "14500:\tlearn: 241.9378011\ttest: 263.7332705\tbest: 263.7324000 (14498)\ttotal: 7m 32s\tremaining: 2m 51s\n",
      "14600:\tlearn: 241.6932508\ttest: 263.5835394\tbest: 263.5835394 (14600)\ttotal: 7m 35s\tremaining: 2m 48s\n",
      "14700:\tlearn: 241.4795083\ttest: 263.4401909\tbest: 263.4401467 (14699)\ttotal: 7m 38s\tremaining: 2m 45s\n",
      "14800:\tlearn: 241.2407253\ttest: 263.2744982\tbest: 263.2744307 (14799)\ttotal: 7m 41s\tremaining: 2m 42s\n",
      "14900:\tlearn: 241.1035557\ttest: 263.1866369\tbest: 263.1861830 (14899)\ttotal: 7m 44s\tremaining: 2m 38s\n",
      "15000:\tlearn: 240.9624449\ttest: 263.0882650\tbest: 263.0882650 (15000)\ttotal: 7m 47s\tremaining: 2m 35s\n",
      "15100:\tlearn: 240.7375690\ttest: 262.9602692\tbest: 262.9602692 (15100)\ttotal: 7m 50s\tremaining: 2m 32s\n",
      "15200:\tlearn: 240.5919181\ttest: 262.8829534\tbest: 262.8798680 (15190)\ttotal: 7m 53s\tremaining: 2m 29s\n",
      "15300:\tlearn: 240.4431734\ttest: 262.6861060\tbest: 262.6858783 (15297)\ttotal: 7m 56s\tremaining: 2m 26s\n",
      "15400:\tlearn: 240.2403829\ttest: 262.5495140\tbest: 262.5489191 (15397)\ttotal: 7m 59s\tremaining: 2m 23s\n",
      "15500:\tlearn: 240.0526406\ttest: 262.4575584\tbest: 262.4545727 (15496)\ttotal: 8m 2s\tremaining: 2m 20s\n",
      "15600:\tlearn: 239.9380765\ttest: 262.3663785\tbest: 262.3651394 (15591)\ttotal: 8m 5s\tremaining: 2m 16s\n",
      "15700:\tlearn: 239.6937932\ttest: 262.1783345\tbest: 262.1780856 (15697)\ttotal: 8m 8s\tremaining: 2m 13s\n",
      "15800:\tlearn: 239.5709448\ttest: 262.0847218\tbest: 262.0829040 (15777)\ttotal: 8m 11s\tremaining: 2m 10s\n",
      "15900:\tlearn: 239.4144477\ttest: 262.0045412\tbest: 262.0037079 (15896)\ttotal: 8m 13s\tremaining: 2m 7s\n",
      "16000:\tlearn: 239.2945710\ttest: 261.9184586\tbest: 261.9145930 (15992)\ttotal: 8m 16s\tremaining: 2m 4s\n",
      "16100:\tlearn: 239.1986347\ttest: 261.8743283\tbest: 261.8742691 (16099)\ttotal: 8m 19s\tremaining: 2m\n",
      "16200:\tlearn: 239.0962625\ttest: 261.8102727\tbest: 261.8097737 (16192)\ttotal: 8m 21s\tremaining: 1m 57s\n",
      "16300:\tlearn: 238.9052149\ttest: 261.6923400\tbest: 261.6916223 (16297)\ttotal: 8m 24s\tremaining: 1m 54s\n",
      "16400:\tlearn: 238.7107832\ttest: 261.5491317\tbest: 261.5483548 (16395)\ttotal: 8m 27s\tremaining: 1m 51s\n",
      "16500:\tlearn: 238.5634374\ttest: 261.4416728\tbest: 261.4397516 (16490)\ttotal: 8m 30s\tremaining: 1m 48s\n",
      "16600:\tlearn: 238.4068488\ttest: 261.3714753\tbest: 261.3714753 (16600)\ttotal: 8m 33s\tremaining: 1m 45s\n",
      "16700:\tlearn: 238.1875782\ttest: 261.1967914\tbest: 261.1967519 (16698)\ttotal: 8m 36s\tremaining: 1m 41s\n",
      "16800:\tlearn: 238.0639795\ttest: 261.1513496\tbest: 261.1479289 (16789)\ttotal: 8m 38s\tremaining: 1m 38s\n",
      "16900:\tlearn: 237.9344987\ttest: 261.0910494\tbest: 261.0903255 (16892)\ttotal: 8m 41s\tremaining: 1m 35s\n",
      "17000:\tlearn: 237.7551726\ttest: 260.9344211\tbest: 260.9339930 (16995)\ttotal: 8m 44s\tremaining: 1m 32s\n",
      "17100:\tlearn: 237.6611699\ttest: 260.9053592\tbest: 260.9053472 (17099)\ttotal: 8m 47s\tremaining: 1m 29s\n",
      "17200:\tlearn: 237.4861955\ttest: 260.7715517\tbest: 260.7715312 (17199)\ttotal: 8m 50s\tremaining: 1m 26s\n",
      "17300:\tlearn: 237.3819036\ttest: 260.7109467\tbest: 260.7101498 (17282)\ttotal: 8m 53s\tremaining: 1m 23s\n",
      "17400:\tlearn: 237.2684004\ttest: 260.6629027\tbest: 260.6629027 (17400)\ttotal: 8m 56s\tremaining: 1m 20s\n",
      "17500:\tlearn: 237.1348165\ttest: 260.5840202\tbest: 260.5838895 (17498)\ttotal: 8m 59s\tremaining: 1m 16s\n",
      "17600:\tlearn: 237.0170140\ttest: 260.5123231\tbest: 260.5105125 (17589)\ttotal: 9m 2s\tremaining: 1m 13s\n",
      "17700:\tlearn: 236.9389609\ttest: 260.4614466\tbest: 260.4614254 (17698)\ttotal: 9m 4s\tremaining: 1m 10s\n",
      "17800:\tlearn: 236.9174822\ttest: 260.4522706\tbest: 260.4519365 (17783)\ttotal: 9m 7s\tremaining: 1m 7s\n",
      "17900:\tlearn: 236.7983440\ttest: 260.3534986\tbest: 260.3534986 (17900)\ttotal: 9m 10s\tremaining: 1m 4s\n",
      "18000:\tlearn: 236.6152994\ttest: 260.2446081\tbest: 260.2430536 (17995)\ttotal: 9m 13s\tremaining: 1m 1s\n",
      "18100:\tlearn: 236.5128523\ttest: 260.1716692\tbest: 260.1715977 (18097)\ttotal: 9m 16s\tremaining: 58.4s\n",
      "18200:\tlearn: 236.4282884\ttest: 260.1444471\tbest: 260.1432236 (18188)\ttotal: 9m 19s\tremaining: 55.3s\n",
      "18300:\tlearn: 236.2860934\ttest: 260.0724099\tbest: 260.0719269 (18295)\ttotal: 9m 22s\tremaining: 52.2s\n",
      "18400:\tlearn: 236.1490970\ttest: 259.9504509\tbest: 259.9504509 (18400)\ttotal: 9m 25s\tremaining: 49.1s\n",
      "18500:\tlearn: 236.0000631\ttest: 259.8885239\tbest: 259.8885239 (18500)\ttotal: 9m 28s\tremaining: 46s\n",
      "18600:\tlearn: 235.8895834\ttest: 259.8367906\tbest: 259.8355352 (18576)\ttotal: 9m 31s\tremaining: 43s\n",
      "18700:\tlearn: 235.7272931\ttest: 259.7421498\tbest: 259.7421498 (18700)\ttotal: 9m 34s\tremaining: 39.9s\n",
      "18800:\tlearn: 235.5620087\ttest: 259.6248889\tbest: 259.6235760 (18797)\ttotal: 9m 37s\tremaining: 36.8s\n",
      "18900:\tlearn: 235.3478945\ttest: 259.4858165\tbest: 259.4813661 (18884)\ttotal: 9m 40s\tremaining: 33.8s\n",
      "19000:\tlearn: 235.2126157\ttest: 259.4056147\tbest: 259.4056147 (19000)\ttotal: 9m 43s\tremaining: 30.7s\n",
      "19100:\tlearn: 235.0167923\ttest: 259.2449172\tbest: 259.2448320 (19098)\ttotal: 9m 46s\tremaining: 27.6s\n",
      "19200:\tlearn: 234.8928084\ttest: 259.2012207\tbest: 259.2012207 (19200)\ttotal: 9m 49s\tremaining: 24.5s\n",
      "19300:\tlearn: 234.7773053\ttest: 259.1012843\tbest: 259.1002115 (19290)\ttotal: 9m 52s\tremaining: 21.5s\n",
      "19400:\tlearn: 234.6708069\ttest: 259.0094155\tbest: 259.0094155 (19400)\ttotal: 9m 55s\tremaining: 18.4s\n",
      "19500:\tlearn: 234.5887518\ttest: 258.9780960\tbest: 258.9780960 (19500)\ttotal: 9m 58s\tremaining: 15.3s\n",
      "19600:\tlearn: 234.4231869\ttest: 258.8652873\tbest: 258.8652873 (19600)\ttotal: 10m 1s\tremaining: 12.2s\n",
      "19700:\tlearn: 234.3130070\ttest: 258.7621176\tbest: 258.7619605 (19698)\ttotal: 10m 4s\tremaining: 9.17s\n",
      "19800:\tlearn: 234.1200320\ttest: 258.6230921\tbest: 258.6230921 (19800)\ttotal: 10m 7s\tremaining: 6.1s\n",
      "19900:\tlearn: 233.9949858\ttest: 258.5425551\tbest: 258.5425253 (19897)\ttotal: 10m 10s\tremaining: 3.04s\n",
      "19999:\tlearn: 233.9221403\ttest: 258.5095174\tbest: 258.5087249 (19988)\ttotal: 10m 13s\tremaining: 0us\n",
      "\n",
      "bestTest = 258.5087249\n",
      "bestIteration = 19988\n",
      "\n",
      "Shrink model to first 19989 iterations.",
      "\n",
      "0:\tlearn: 971.0182814\ttest: 1026.1242912\tbest: 1026.1242912 (0)\ttotal: 33.6ms\tremaining: 11m 11s\n",
      "100:\tlearn: 601.3412833\ttest: 656.2789696\tbest: 656.2789696 (100)\ttotal: 3.47s\tremaining: 11m 24s\n",
      "200:\tlearn: 485.7953704\ttest: 534.9966753\tbest: 534.9966753 (200)\ttotal: 7.1s\tremaining: 11m 39s\n",
      "300:\tlearn: 433.8064917\ttest: 477.2793677\tbest: 477.2793677 (300)\ttotal: 10.6s\tremaining: 11m 32s\n",
      "400:\tlearn: 411.8088144\ttest: 450.8540036\tbest: 450.8540036 (400)\ttotal: 14.2s\tremaining: 11m 36s\n",
      "500:\tlearn: 398.0477465\ttest: 434.2713522\tbest: 434.2713522 (500)\ttotal: 17.7s\tremaining: 11m 30s\n",
      "600:\tlearn: 388.7951259\ttest: 423.0387904\tbest: 423.0387904 (600)\ttotal: 20.9s\tremaining: 11m 13s\n",
      "700:\tlearn: 382.9403976\ttest: 415.9160695\tbest: 415.9160695 (700)\ttotal: 23.2s\tremaining: 10m 39s\n",
      "800:\tlearn: 373.8173297\ttest: 404.0255178\tbest: 404.0255178 (800)\ttotal: 25.9s\tremaining: 10m 19s\n",
      "900:\tlearn: 368.5858997\ttest: 397.1527035\tbest: 397.1527035 (900)\ttotal: 28.2s\tremaining: 9m 57s\n",
      "1000:\tlearn: 362.0431615\ttest: 388.3902423\tbest: 388.3902423 (1000)\ttotal: 30.7s\tremaining: 9m 42s\n",
      "1100:\tlearn: 355.5912203\ttest: 380.1735426\tbest: 380.1735426 (1100)\ttotal: 33.6s\tremaining: 9m 37s\n",
      "1200:\tlearn: 349.5916600\ttest: 372.5669072\tbest: 372.5669072 (1200)\ttotal: 36.7s\tremaining: 9m 34s\n",
      "1300:\tlearn: 343.5509023\ttest: 365.4017788\tbest: 365.4017788 (1300)\ttotal: 39.4s\tremaining: 9m 25s\n",
      "1400:\tlearn: 338.5666761\ttest: 359.5767702\tbest: 359.5767702 (1400)\ttotal: 42s\tremaining: 9m 17s\n",
      "1500:\tlearn: 333.5806457\ttest: 354.0248982\tbest: 354.0248982 (1500)\ttotal: 44.7s\tremaining: 9m 10s\n",
      "1600:\tlearn: 330.7339896\ttest: 350.4859095\tbest: 350.4859095 (1600)\ttotal: 47s\tremaining: 9m\n",
      "1700:\tlearn: 327.0719508\ttest: 346.2146904\tbest: 346.2146904 (1700)\ttotal: 49.7s\tremaining: 8m 54s\n",
      "1800:\tlearn: 324.1864317\ttest: 343.0765706\tbest: 343.0765706 (1800)\ttotal: 52.1s\tremaining: 8m 46s\n",
      "1900:\tlearn: 320.9538849\ttest: 339.4695693\tbest: 339.4695693 (1900)\ttotal: 54.8s\tremaining: 8m 41s\n",
      "2000:\tlearn: 318.3681885\ttest: 336.5954168\tbest: 336.5954168 (2000)\ttotal: 57s\tremaining: 8m 33s\n",
      "2100:\tlearn: 316.5014429\ttest: 334.6083323\tbest: 334.6083323 (2100)\ttotal: 59.4s\tremaining: 8m 26s\n",
      "2200:\tlearn: 314.0642210\ttest: 332.0132636\tbest: 332.0132636 (2200)\ttotal: 1m 2s\tremaining: 8m 21s\n",
      "2300:\tlearn: 312.3826999\ttest: 330.2821702\tbest: 330.2820328 (2295)\ttotal: 1m 4s\tremaining: 8m 15s\n",
      "2400:\tlearn: 310.9393200\ttest: 328.6607741\tbest: 328.6607741 (2400)\ttotal: 1m 6s\tremaining: 8m 7s\n",
      "2500:\tlearn: 310.0422206\ttest: 327.6227584\tbest: 327.6226343 (2495)\ttotal: 1m 8s\tremaining: 7m 59s\n",
      "2600:\tlearn: 308.8474901\ttest: 326.4448435\tbest: 326.4448435 (2600)\ttotal: 1m 10s\tremaining: 7m 51s\n",
      "2700:\tlearn: 307.8904610\ttest: 325.5450963\tbest: 325.5450963 (2700)\ttotal: 1m 12s\tremaining: 7m 45s\n",
      "2800:\tlearn: 307.2369982\ttest: 324.8790032\tbest: 324.8790032 (2800)\ttotal: 1m 14s\tremaining: 7m 38s\n",
      "2900:\tlearn: 306.0705908\ttest: 323.6297949\tbest: 323.6297949 (2900)\ttotal: 1m 16s\tremaining: 7m 33s\n",
      "3000:\tlearn: 304.3888026\ttest: 321.9318479\tbest: 321.9318479 (3000)\ttotal: 1m 20s\tremaining: 7m 34s\n",
      "3100:\tlearn: 303.2301531\ttest: 320.7471042\tbest: 320.7471042 (3100)\ttotal: 1m 22s\tremaining: 7m 32s\n",
      "3200:\tlearn: 301.8897786\ttest: 319.4046510\tbest: 319.4046510 (3200)\ttotal: 1m 25s\tremaining: 7m 29s\n",
      "3300:\tlearn: 299.9365164\ttest: 317.4746915\tbest: 317.4746915 (3300)\ttotal: 1m 28s\tremaining: 7m 29s\n",
      "3400:\tlearn: 298.2126034\ttest: 315.6900831\tbest: 315.6900831 (3400)\ttotal: 1m 32s\tremaining: 7m 29s\n",
      "3500:\tlearn: 296.3266294\ttest: 313.8284655\tbest: 313.8283153 (3499)\ttotal: 1m 35s\tremaining: 7m 31s\n",
      "3600:\tlearn: 294.6712542\ttest: 312.2788674\tbest: 312.2788674 (3600)\ttotal: 1m 38s\tremaining: 7m 30s\n",
      "3700:\tlearn: 294.1283067\ttest: 311.8669640\tbest: 311.8669640 (3700)\ttotal: 1m 41s\tremaining: 7m 27s\n",
      "3800:\tlearn: 292.8767987\ttest: 310.6757920\tbest: 310.6757920 (3800)\ttotal: 1m 44s\tremaining: 7m 25s\n",
      "3900:\tlearn: 291.6058033\ttest: 309.3301717\tbest: 309.3301717 (3900)\ttotal: 1m 48s\tremaining: 7m 26s\n",
      "4000:\tlearn: 289.7558659\ttest: 307.7059230\tbest: 307.7059230 (4000)\ttotal: 1m 51s\tremaining: 7m 26s\n",
      "4100:\tlearn: 288.1761735\ttest: 306.1847076\tbest: 306.1756480 (4099)\ttotal: 1m 55s\tremaining: 7m 26s\n",
      "4200:\tlearn: 286.4241732\ttest: 304.4738998\tbest: 304.4738998 (4200)\ttotal: 1m 58s\tremaining: 7m 25s\n",
      "4300:\tlearn: 284.8244018\ttest: 302.9360928\tbest: 302.9360928 (4300)\ttotal: 2m 1s\tremaining: 7m 24s\n",
      "4400:\tlearn: 283.7814857\ttest: 301.8878037\tbest: 301.8878037 (4400)\ttotal: 2m 4s\tremaining: 7m 22s\n",
      "4500:\tlearn: 282.1894410\ttest: 300.5330351\tbest: 300.5330351 (4500)\ttotal: 2m 8s\tremaining: 7m 21s\n",
      "4600:\tlearn: 280.9108880\ttest: 299.4788209\tbest: 299.4788209 (4600)\ttotal: 2m 11s\tremaining: 7m 20s\n",
      "4700:\tlearn: 279.9603374\ttest: 298.7644873\tbest: 298.7644873 (4700)\ttotal: 2m 14s\tremaining: 7m 17s\n",
      "4800:\tlearn: 278.7507459\ttest: 297.5612641\tbest: 297.5612641 (4800)\ttotal: 2m 17s\tremaining: 7m 16s\n",
      "4900:\tlearn: 278.0215615\ttest: 296.9301978\tbest: 296.9301978 (4900)\ttotal: 2m 20s\tremaining: 7m 13s\n",
      "5000:\tlearn: 277.2416845\ttest: 296.2676913\tbest: 296.2656423 (4994)\ttotal: 2m 23s\tremaining: 7m 11s\n",
      "5100:\tlearn: 276.6852792\ttest: 295.8318594\tbest: 295.8318594 (5100)\ttotal: 2m 26s\tremaining: 7m 9s\n",
      "5200:\tlearn: 275.9283785\ttest: 295.1930086\tbest: 295.1930086 (5200)\ttotal: 2m 30s\tremaining: 7m 7s\n",
      "5300:\tlearn: 274.9473228\ttest: 294.3035444\tbest: 294.3035444 (5300)\ttotal: 2m 33s\tremaining: 7m 5s\n",
      "5400:\tlearn: 274.2216650\ttest: 293.6284554\tbest: 293.6281397 (5398)\ttotal: 2m 36s\tremaining: 7m 3s\n",
      "5500:\tlearn: 273.3339554\ttest: 292.9040305\tbest: 292.9032592 (5499)\ttotal: 2m 39s\tremaining: 7m 1s\n",
      "5600:\tlearn: 272.7810160\ttest: 292.4562736\tbest: 292.4562736 (5600)\ttotal: 2m 43s\tremaining: 6m 59s\n",
      "5700:\tlearn: 271.9937593\ttest: 291.8474649\tbest: 291.8474649 (5700)\ttotal: 2m 45s\tremaining: 6m 56s\n",
      "5800:\tlearn: 271.4903060\ttest: 291.5345738\tbest: 291.5321862 (5793)\ttotal: 2m 49s\tremaining: 6m 53s\n",
      "5900:\tlearn: 270.9232833\ttest: 291.0426974\tbest: 291.0426974 (5900)\ttotal: 2m 51s\tremaining: 6m 50s\n",
      "6000:\tlearn: 270.5415850\ttest: 290.6647135\tbest: 290.6647135 (6000)\ttotal: 2m 54s\tremaining: 6m 47s\n",
      "6100:\tlearn: 270.0657578\ttest: 290.2385297\tbest: 290.2384149 (6099)\ttotal: 2m 57s\tremaining: 6m 44s\n",
      "6200:\tlearn: 269.3888264\ttest: 289.7839200\tbest: 289.7752016 (6199)\ttotal: 3m\tremaining: 6m 42s\n",
      "6300:\tlearn: 268.7236509\ttest: 289.2665131\tbest: 289.2665131 (6300)\ttotal: 3m 3s\tremaining: 6m 39s\n",
      "6400:\tlearn: 267.8074845\ttest: 288.4935271\tbest: 288.4935271 (6400)\ttotal: 3m 7s\tremaining: 6m 37s\n",
      "6500:\tlearn: 267.2739147\ttest: 287.9987444\tbest: 287.9982227 (6497)\ttotal: 3m 10s\tremaining: 6m 35s\n",
      "6600:\tlearn: 266.7536150\ttest: 287.4989962\tbest: 287.4989468 (6597)\ttotal: 3m 13s\tremaining: 6m 33s\n",
      "6700:\tlearn: 266.0896620\ttest: 287.0548893\tbest: 287.0547106 (6697)\ttotal: 3m 16s\tremaining: 6m 30s\n",
      "6800:\tlearn: 265.5576419\ttest: 286.6357109\tbest: 286.6357109 (6800)\ttotal: 3m 20s\tremaining: 6m 28s\n",
      "6900:\tlearn: 265.1516774\ttest: 286.3398971\tbest: 286.3389834 (6897)\ttotal: 3m 23s\tremaining: 6m 26s\n",
      "7000:\tlearn: 264.5847909\ttest: 285.9397539\tbest: 285.9335319 (6988)\ttotal: 3m 26s\tremaining: 6m 23s\n",
      "7100:\tlearn: 264.1566539\ttest: 285.5771549\tbest: 285.5771549 (7100)\ttotal: 3m 29s\tremaining: 6m 20s\n",
      "7200:\tlearn: 263.7229760\ttest: 285.1783500\tbest: 285.1769380 (7197)\ttotal: 3m 32s\tremaining: 6m 18s\n",
      "7300:\tlearn: 263.3250899\ttest: 284.7809201\tbest: 284.7809021 (7298)\ttotal: 3m 35s\tremaining: 6m 14s\n",
      "7400:\tlearn: 262.9415832\ttest: 284.4758856\tbest: 284.4758856 (7400)\ttotal: 3m 38s\tremaining: 6m 12s\n",
      "7500:\tlearn: 262.5795638\ttest: 284.1675348\tbest: 284.1665623 (7480)\ttotal: 3m 41s\tremaining: 6m 8s\n",
      "7600:\tlearn: 262.2453298\ttest: 283.8040936\tbest: 283.8040134 (7596)\ttotal: 3m 43s\tremaining: 6m 5s\n",
      "7700:\tlearn: 262.0019156\ttest: 283.5836744\tbest: 283.5819185 (7695)\ttotal: 3m 46s\tremaining: 6m 2s\n",
      "7800:\tlearn: 261.4444652\ttest: 283.0681684\tbest: 283.0678698 (7799)\ttotal: 3m 49s\tremaining: 5m 59s\n",
      "7900:\tlearn: 261.1672597\ttest: 282.8678786\tbest: 282.8677852 (7899)\ttotal: 3m 52s\tremaining: 5m 56s\n",
      "8000:\tlearn: 260.7093347\ttest: 282.4696353\tbest: 282.4684230 (7999)\ttotal: 3m 56s\tremaining: 5m 54s\n",
      "8100:\tlearn: 260.2897307\ttest: 282.1419075\tbest: 282.1418531 (8098)\ttotal: 3m 59s\tremaining: 5m 51s\n",
      "8200:\tlearn: 259.9703906\ttest: 281.9372080\tbest: 281.9372080 (8200)\ttotal: 4m 2s\tremaining: 5m 48s\n",
      "8300:\tlearn: 259.8054049\ttest: 281.8121335\tbest: 281.8121044 (8298)\ttotal: 4m 4s\tremaining: 5m 45s\n",
      "8400:\tlearn: 259.6344855\ttest: 281.7236430\tbest: 281.7236430 (8400)\ttotal: 4m 7s\tremaining: 5m 42s\n",
      "8500:\tlearn: 259.3070887\ttest: 281.4355609\tbest: 281.4355609 (8500)\ttotal: 4m 10s\tremaining: 5m 38s\n",
      "8600:\tlearn: 259.1875733\ttest: 281.3685051\tbest: 281.3685051 (8600)\ttotal: 4m 12s\tremaining: 5m 34s\n",
      "8700:\tlearn: 259.1044101\ttest: 281.3282953\tbest: 281.3238642 (8675)\ttotal: 4m 15s\tremaining: 5m 31s\n",
      "8800:\tlearn: 258.9683869\ttest: 281.2348336\tbest: 281.2342872 (8797)\ttotal: 4m 17s\tremaining: 5m 28s\n",
      "8900:\tlearn: 258.7724986\ttest: 281.1096182\tbest: 281.1096182 (8900)\ttotal: 4m 20s\tremaining: 5m 24s\n",
      "9000:\tlearn: 258.5784968\ttest: 280.9602844\tbest: 280.9602844 (9000)\ttotal: 4m 22s\tremaining: 5m 21s\n",
      "9100:\tlearn: 258.4976930\ttest: 280.9094702\tbest: 280.9091161 (9056)\ttotal: 4m 25s\tremaining: 5m 17s\n",
      "9200:\tlearn: 258.3596466\ttest: 280.7772080\tbest: 280.7771498 (9195)\ttotal: 4m 27s\tremaining: 5m 14s\n",
      "9300:\tlearn: 258.0996394\ttest: 280.5598050\tbest: 280.5598050 (9300)\ttotal: 4m 30s\tremaining: 5m 11s\n",
      "9400:\tlearn: 257.9586709\ttest: 280.4197856\tbest: 280.4196887 (9399)\ttotal: 4m 33s\tremaining: 5m 8s\n",
      "9500:\tlearn: 257.8282318\ttest: 280.3263876\tbest: 280.3263876 (9500)\ttotal: 4m 35s\tremaining: 5m 4s\n",
      "9600:\tlearn: 257.6192005\ttest: 280.1072961\tbest: 280.1072179 (9598)\ttotal: 4m 38s\tremaining: 5m 1s\n",
      "9700:\tlearn: 257.4477545\ttest: 279.9638619\tbest: 279.9625491 (9690)\ttotal: 4m 41s\tremaining: 4m 58s\n",
      "9800:\tlearn: 257.3710562\ttest: 279.8846360\tbest: 279.8845215 (9797)\ttotal: 4m 44s\tremaining: 4m 55s\n",
      "9900:\tlearn: 257.2109300\ttest: 279.7656828\tbest: 279.7655021 (9897)\ttotal: 4m 47s\tremaining: 4m 52s\n",
      "10000:\tlearn: 256.9949885\ttest: 279.5652400\tbest: 279.5648258 (9997)\ttotal: 4m 50s\tremaining: 4m 50s\n",
      "10100:\tlearn: 256.8547255\ttest: 279.4487722\tbest: 279.4468837 (10092)\ttotal: 4m 53s\tremaining: 4m 47s\n",
      "10200:\tlearn: 256.6308431\ttest: 279.2976104\tbest: 279.2971438 (10199)\ttotal: 4m 56s\tremaining: 4m 45s\n",
      "10300:\tlearn: 256.3722627\ttest: 279.1576757\tbest: 279.1566217 (10284)\ttotal: 4m 59s\tremaining: 4m 42s\n",
      "10400:\tlearn: 256.2341601\ttest: 279.0481574\tbest: 279.0479077 (10398)\ttotal: 5m 2s\tremaining: 4m 39s\n",
      "10500:\tlearn: 255.9058491\ttest: 278.7388855\tbest: 278.7388855 (10500)\ttotal: 5m 6s\tremaining: 4m 37s\n",
      "10600:\tlearn: 255.6870452\ttest: 278.5288585\tbest: 278.5288585 (10600)\ttotal: 5m 10s\tremaining: 4m 34s\n",
      "10700:\tlearn: 255.3136026\ttest: 278.2839701\tbest: 278.2839701 (10700)\ttotal: 5m 13s\tremaining: 4m 32s\n",
      "10800:\tlearn: 255.1240714\ttest: 278.1423239\tbest: 278.1422223 (10795)\ttotal: 5m 17s\tremaining: 4m 30s\n",
      "10900:\tlearn: 254.9975214\ttest: 278.0243624\tbest: 278.0239402 (10897)\ttotal: 5m 19s\tremaining: 4m 26s\n",
      "11000:\tlearn: 254.8258208\ttest: 277.9072267\tbest: 277.9046793 (10992)\ttotal: 5m 22s\tremaining: 4m 24s\n",
      "11100:\tlearn: 254.7355110\ttest: 277.8095259\tbest: 277.8081216 (11095)\ttotal: 5m 25s\tremaining: 4m 20s\n",
      "11200:\tlearn: 254.6633677\ttest: 277.7553731\tbest: 277.7553731 (11200)\ttotal: 5m 28s\tremaining: 4m 17s\n",
      "11300:\tlearn: 254.5208256\ttest: 277.6614181\tbest: 277.6556987 (11291)\ttotal: 5m 31s\tremaining: 4m 14s\n",
      "11400:\tlearn: 254.2340565\ttest: 277.4536963\tbest: 277.4536963 (11400)\ttotal: 5m 34s\tremaining: 4m 12s\n",
      "11500:\tlearn: 253.9332689\ttest: 277.2139431\tbest: 277.2139431 (11500)\ttotal: 5m 37s\tremaining: 4m 9s\n",
      "11600:\tlearn: 253.7654086\ttest: 277.1021426\tbest: 277.1019852 (11596)\ttotal: 5m 40s\tremaining: 4m 6s\n",
      "11700:\tlearn: 253.5218667\ttest: 276.9408516\tbest: 276.9334863 (11693)\ttotal: 5m 44s\tremaining: 4m 4s\n",
      "11800:\tlearn: 253.4271950\ttest: 276.8434755\tbest: 276.8426900 (11791)\ttotal: 5m 47s\tremaining: 4m 1s\n",
      "11900:\tlearn: 253.1299773\ttest: 276.5866023\tbest: 276.5866023 (11900)\ttotal: 5m 50s\tremaining: 3m 58s\n",
      "12000:\tlearn: 252.8951680\ttest: 276.3701011\tbest: 276.3684831 (11996)\ttotal: 5m 53s\tremaining: 3m 55s\n",
      "12100:\tlearn: 252.7582344\ttest: 276.2766317\tbest: 276.2766317 (12100)\ttotal: 5m 56s\tremaining: 3m 52s\n",
      "12200:\tlearn: 252.4849492\ttest: 276.0937147\tbest: 276.0933354 (12199)\ttotal: 5m 59s\tremaining: 3m 50s\n",
      "12300:\tlearn: 252.3491050\ttest: 275.9654876\tbest: 275.9648817 (12292)\ttotal: 6m 2s\tremaining: 3m 47s\n",
      "12400:\tlearn: 252.1055623\ttest: 275.7620232\tbest: 275.7585343 (12395)\ttotal: 6m 6s\tremaining: 3m 44s\n",
      "12500:\tlearn: 251.8949794\ttest: 275.6244407\tbest: 275.6244407 (12500)\ttotal: 6m 9s\tremaining: 3m 41s\n",
      "12600:\tlearn: 251.7119781\ttest: 275.4456625\tbest: 275.4422723 (12590)\ttotal: 6m 13s\tremaining: 3m 39s\n",
      "12700:\tlearn: 251.4887351\ttest: 275.2620469\tbest: 275.2616228 (12697)\ttotal: 6m 16s\tremaining: 3m 36s\n",
      "12800:\tlearn: 251.2183488\ttest: 274.9613735\tbest: 274.9613199 (12799)\ttotal: 6m 19s\tremaining: 3m 33s\n",
      "12900:\tlearn: 251.0898248\ttest: 274.9077896\tbest: 274.9077708 (12899)\ttotal: 6m 22s\tremaining: 3m 30s\n",
      "13000:\tlearn: 251.0108121\ttest: 274.8307445\tbest: 274.8306998 (12999)\ttotal: 6m 25s\tremaining: 3m 27s\n",
      "13100:\tlearn: 250.9665469\ttest: 274.8181080\tbest: 274.8148238 (13052)\ttotal: 6m 27s\tremaining: 3m 24s\n",
      "13200:\tlearn: 250.8761187\ttest: 274.7457395\tbest: 274.7437884 (13188)\ttotal: 6m 30s\tremaining: 3m 21s\n",
      "13300:\tlearn: 250.7154342\ttest: 274.6167923\tbest: 274.6167923 (13300)\ttotal: 6m 33s\tremaining: 3m 18s\n",
      "13400:\tlearn: 250.5400503\ttest: 274.4713057\tbest: 274.4693519 (13380)\ttotal: 6m 36s\tremaining: 3m 15s\n",
      "13500:\tlearn: 250.5012146\ttest: 274.4548571\tbest: 274.4539435 (13490)\ttotal: 6m 39s\tremaining: 3m 12s\n",
      "13600:\tlearn: 250.3810306\ttest: 274.3438786\tbest: 274.3438228 (13598)\ttotal: 6m 42s\tremaining: 3m 9s\n",
      "13700:\tlearn: 250.2656007\ttest: 274.2793534\tbest: 274.2706441 (13680)\ttotal: 6m 45s\tremaining: 3m 6s\n",
      "13800:\tlearn: 250.0160576\ttest: 274.0856006\tbest: 274.0855009 (13798)\ttotal: 6m 48s\tremaining: 3m 3s\n",
      "13900:\tlearn: 249.8676329\ttest: 273.9464767\tbest: 273.9464767 (13900)\ttotal: 6m 51s\tremaining: 3m\n",
      "14000:\tlearn: 249.7108046\ttest: 273.8190991\tbest: 273.8189969 (13997)\ttotal: 6m 55s\tremaining: 2m 57s\n",
      "14100:\tlearn: 249.5962987\ttest: 273.7436516\tbest: 273.7429241 (14079)\ttotal: 6m 58s\tremaining: 2m 54s\n",
      "14200:\tlearn: 249.4785645\ttest: 273.6537633\tbest: 273.6537633 (14200)\ttotal: 7m 1s\tremaining: 2m 51s\n",
      "14300:\tlearn: 249.2199120\ttest: 273.4206814\tbest: 273.4198882 (14295)\ttotal: 7m 4s\tremaining: 2m 49s\n",
      "14400:\tlearn: 249.1020248\ttest: 273.2969675\tbest: 273.2968581 (14399)\ttotal: 7m 7s\tremaining: 2m 46s\n",
      "14500:\tlearn: 248.9167002\ttest: 273.1380240\tbest: 273.1378158 (14495)\ttotal: 7m 10s\tremaining: 2m 43s\n",
      "14600:\tlearn: 248.7556432\ttest: 272.9889361\tbest: 272.9883735 (14590)\ttotal: 7m 14s\tremaining: 2m 40s\n",
      "14700:\tlearn: 248.6087484\ttest: 272.8947550\tbest: 272.8946148 (14699)\ttotal: 7m 17s\tremaining: 2m 37s\n",
      "14800:\tlearn: 248.5004068\ttest: 272.8465557\tbest: 272.8464253 (14799)\ttotal: 7m 19s\tremaining: 2m 34s\n",
      "14900:\tlearn: 248.4125842\ttest: 272.7829832\tbest: 272.7815786 (14883)\ttotal: 7m 22s\tremaining: 2m 31s\n",
      "15000:\tlearn: 248.2960162\ttest: 272.6771590\tbest: 272.6771590 (15000)\ttotal: 7m 26s\tremaining: 2m 28s\n",
      "15100:\tlearn: 248.2411766\ttest: 272.6331657\tbest: 272.6331278 (15099)\ttotal: 7m 29s\tremaining: 2m 25s\n",
      "15200:\tlearn: 248.1574011\ttest: 272.5669623\tbest: 272.5669623 (15200)\ttotal: 7m 32s\tremaining: 2m 22s\n",
      "15300:\tlearn: 248.0375589\ttest: 272.4982052\tbest: 272.4918735 (15257)\ttotal: 7m 35s\tremaining: 2m 19s\n",
      "15400:\tlearn: 247.8333739\ttest: 272.3501918\tbest: 272.3499896 (15395)\ttotal: 7m 38s\tremaining: 2m 16s\n",
      "15500:\tlearn: 247.6731314\ttest: 272.1896142\tbest: 272.1895853 (15499)\ttotal: 7m 41s\tremaining: 2m 14s\n",
      "15600:\tlearn: 247.5466893\ttest: 272.1089177\tbest: 272.1088715 (15593)\ttotal: 7m 45s\tremaining: 2m 11s\n",
      "15700:\tlearn: 247.3188127\ttest: 271.9235109\tbest: 271.9234608 (15699)\ttotal: 7m 48s\tremaining: 2m 8s\n",
      "15800:\tlearn: 247.2629082\ttest: 271.8935557\tbest: 271.8931289 (15795)\ttotal: 7m 51s\tremaining: 2m 5s\n",
      "15900:\tlearn: 247.1931953\ttest: 271.8399580\tbest: 271.8240153 (15867)\ttotal: 7m 54s\tremaining: 2m 2s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 271.8240153\n",
      "bestIteration = 15867\n",
      "\n",
      "Shrink model to first 15868 iterations.",
      "\n",
      "0:\tlearn: 992.1696571\ttest: 944.8653055\tbest: 944.8653055 (0)\ttotal: 37.9ms\tremaining: 12m 38s\n",
      "100:\tlearn: 615.3563096\ttest: 564.9821382\tbest: 564.9821382 (100)\ttotal: 3.94s\tremaining: 12m 56s\n",
      "200:\tlearn: 501.8150934\ttest: 462.1287929\tbest: 462.1287929 (200)\ttotal: 7.83s\tremaining: 12m 51s\n",
      "300:\tlearn: 442.1353209\ttest: 407.0916620\tbest: 407.0916620 (300)\ttotal: 11.5s\tremaining: 12m 32s\n",
      "400:\tlearn: 418.5685370\ttest: 386.2329342\tbest: 386.2329342 (400)\ttotal: 15.2s\tremaining: 12m 22s\n",
      "500:\tlearn: 402.4581473\ttest: 372.6302799\tbest: 372.6302799 (500)\ttotal: 19s\tremaining: 12m 21s\n",
      "600:\tlearn: 390.6918277\ttest: 362.7691328\tbest: 362.7691328 (600)\ttotal: 22.7s\tremaining: 12m 13s\n",
      "700:\tlearn: 379.8179007\ttest: 354.1600066\tbest: 354.1600066 (700)\ttotal: 26.1s\tremaining: 11m 57s\n",
      "800:\tlearn: 369.7065350\ttest: 346.6144729\tbest: 346.6144729 (800)\ttotal: 29.6s\tremaining: 11m 50s\n",
      "900:\tlearn: 361.5411416\ttest: 339.8910724\tbest: 339.8910724 (900)\ttotal: 32.9s\tremaining: 11m 36s\n",
      "1000:\tlearn: 355.0054485\ttest: 334.5634696\tbest: 334.5634696 (1000)\ttotal: 36.2s\tremaining: 11m 26s\n",
      "1100:\tlearn: 349.3559344\ttest: 330.1288128\tbest: 330.1288128 (1100)\ttotal: 39.5s\tremaining: 11m 18s\n",
      "1200:\tlearn: 343.3038832\ttest: 325.1362019\tbest: 325.1362019 (1200)\ttotal: 43s\tremaining: 11m 12s\n",
      "1300:\tlearn: 337.7948649\ttest: 320.5873403\tbest: 320.5873403 (1300)\ttotal: 46.5s\tremaining: 11m 8s\n",
      "1400:\tlearn: 333.5164565\ttest: 317.1484989\tbest: 317.1484989 (1400)\ttotal: 50.3s\tremaining: 11m 7s\n",
      "1500:\tlearn: 328.6843759\ttest: 312.7546289\tbest: 312.7546289 (1500)\ttotal: 54s\tremaining: 11m 5s\n",
      "1600:\tlearn: 324.1750274\ttest: 308.8171524\tbest: 308.8171524 (1600)\ttotal: 57.5s\tremaining: 11m 1s\n",
      "1700:\tlearn: 319.6664085\ttest: 305.1945541\tbest: 305.1945541 (1700)\ttotal: 1m 1s\tremaining: 11m\n",
      "1800:\tlearn: 315.7108221\ttest: 301.8485196\tbest: 301.8485196 (1800)\ttotal: 1m 4s\tremaining: 10m 56s\n",
      "1900:\tlearn: 312.5417829\ttest: 299.2443507\tbest: 299.2443507 (1900)\ttotal: 1m 8s\tremaining: 10m 52s\n",
      "2000:\tlearn: 309.2902866\ttest: 296.5370527\tbest: 296.5370527 (2000)\ttotal: 1m 12s\tremaining: 10m 48s\n",
      "2100:\tlearn: 307.1362504\ttest: 294.9659288\tbest: 294.9659288 (2100)\ttotal: 1m 15s\tremaining: 10m 44s\n",
      "2200:\tlearn: 305.2480943\ttest: 293.4697491\tbest: 293.4695211 (2199)\ttotal: 1m 19s\tremaining: 10m 39s\n",
      "2300:\tlearn: 303.1535817\ttest: 291.7898253\tbest: 291.7898253 (2300)\ttotal: 1m 22s\tremaining: 10m 34s\n",
      "2400:\tlearn: 301.3944250\ttest: 290.6240039\tbest: 290.6240039 (2400)\ttotal: 1m 25s\tremaining: 10m 29s\n",
      "2500:\tlearn: 299.6603456\ttest: 289.2531729\tbest: 289.2531729 (2500)\ttotal: 1m 29s\tremaining: 10m 23s\n",
      "2600:\tlearn: 298.0270692\ttest: 288.1261684\tbest: 288.1261684 (2600)\ttotal: 1m 32s\tremaining: 10m 17s\n",
      "2700:\tlearn: 296.6423591\ttest: 287.2207370\tbest: 287.2207370 (2700)\ttotal: 1m 35s\tremaining: 10m 14s\n",
      "2800:\tlearn: 295.1105061\ttest: 286.0058902\tbest: 286.0058902 (2800)\ttotal: 1m 39s\tremaining: 10m 10s\n",
      "2900:\tlearn: 293.7866970\ttest: 285.1168126\tbest: 285.1168126 (2900)\ttotal: 1m 42s\tremaining: 10m 6s\n",
      "3000:\tlearn: 292.7065946\ttest: 284.2870721\tbest: 284.2870721 (3000)\ttotal: 1m 46s\tremaining: 10m\n",
      "3100:\tlearn: 291.1998626\ttest: 283.1599926\tbest: 283.1599926 (3100)\ttotal: 1m 49s\tremaining: 9m 56s\n",
      "3200:\tlearn: 290.1647685\ttest: 282.4167777\tbest: 282.4165266 (3198)\ttotal: 1m 52s\tremaining: 9m 51s\n",
      "3300:\tlearn: 289.2326048\ttest: 281.7275452\tbest: 281.7262743 (3299)\ttotal: 1m 55s\tremaining: 9m 45s\n",
      "3400:\tlearn: 287.8371950\ttest: 280.7600121\tbest: 280.7600121 (3400)\ttotal: 1m 59s\tremaining: 9m 42s\n",
      "3500:\tlearn: 286.7386171\ttest: 279.9234116\tbest: 279.9222247 (3499)\ttotal: 2m 2s\tremaining: 9m 37s\n",
      "3600:\tlearn: 285.9777277\ttest: 279.5166424\tbest: 279.5166424 (3600)\ttotal: 2m 5s\tremaining: 9m 32s\n",
      "3700:\tlearn: 284.8463716\ttest: 278.7414350\tbest: 278.7414350 (3700)\ttotal: 2m 8s\tremaining: 9m 28s\n",
      "3800:\tlearn: 284.0260793\ttest: 278.1244297\tbest: 278.1244297 (3800)\ttotal: 2m 12s\tremaining: 9m 24s\n",
      "3900:\tlearn: 282.9777856\ttest: 277.4851420\tbest: 277.4840437 (3897)\ttotal: 2m 15s\tremaining: 9m 20s\n",
      "4000:\tlearn: 282.1316695\ttest: 276.9125303\tbest: 276.9125303 (4000)\ttotal: 2m 18s\tremaining: 9m 15s\n",
      "4100:\tlearn: 281.3081967\ttest: 276.3472368\tbest: 276.3472368 (4100)\ttotal: 2m 22s\tremaining: 9m 12s\n",
      "4200:\tlearn: 280.7633174\ttest: 275.9294455\tbest: 275.9294455 (4200)\ttotal: 2m 25s\tremaining: 9m 6s\n",
      "4300:\tlearn: 279.7062943\ttest: 275.0908718\tbest: 275.0908718 (4300)\ttotal: 2m 28s\tremaining: 9m 3s\n",
      "4400:\tlearn: 278.7189111\ttest: 274.4470058\tbest: 274.4459607 (4398)\ttotal: 2m 32s\tremaining: 8m 59s\n",
      "4500:\tlearn: 277.6519774\ttest: 273.5693993\tbest: 273.5693993 (4500)\ttotal: 2m 35s\tremaining: 8m 55s\n",
      "4600:\tlearn: 276.9024778\ttest: 272.8897120\tbest: 272.8876075 (4599)\ttotal: 2m 38s\tremaining: 8m 50s\n",
      "4700:\tlearn: 275.9826289\ttest: 272.1813759\tbest: 272.1813759 (4700)\ttotal: 2m 41s\tremaining: 8m 45s\n",
      "4800:\tlearn: 275.4151117\ttest: 271.7531358\tbest: 271.7531358 (4800)\ttotal: 2m 44s\tremaining: 8m 40s\n",
      "4900:\tlearn: 274.7139039\ttest: 271.2473020\tbest: 271.2473020 (4900)\ttotal: 2m 47s\tremaining: 8m 37s\n",
      "5000:\tlearn: 274.1461779\ttest: 270.8709190\tbest: 270.8709190 (5000)\ttotal: 2m 51s\tremaining: 8m 33s\n",
      "5100:\tlearn: 273.5176003\ttest: 270.4915015\tbest: 270.4915015 (5100)\ttotal: 2m 54s\tremaining: 8m 29s\n",
      "5200:\tlearn: 272.6478595\ttest: 269.9895848\tbest: 269.9895848 (5200)\ttotal: 2m 57s\tremaining: 8m 25s\n",
      "5300:\tlearn: 272.2504158\ttest: 269.7349948\tbest: 269.7349948 (5300)\ttotal: 3m\tremaining: 8m 21s\n",
      "5400:\tlearn: 271.7790248\ttest: 269.3758568\tbest: 269.3739999 (5399)\ttotal: 3m 3s\tremaining: 8m 16s\n",
      "5500:\tlearn: 271.3031059\ttest: 269.1240944\tbest: 269.1240944 (5500)\ttotal: 3m 6s\tremaining: 8m 11s\n",
      "5600:\tlearn: 270.9150991\ttest: 268.7861170\tbest: 268.7860196 (5598)\ttotal: 3m 9s\tremaining: 8m 7s\n",
      "5700:\tlearn: 270.4271445\ttest: 268.5106532\tbest: 268.5106532 (5700)\ttotal: 3m 12s\tremaining: 8m 3s\n",
      "5800:\tlearn: 269.7970938\ttest: 268.0943725\tbest: 268.0942210 (5798)\ttotal: 3m 15s\tremaining: 7m 59s\n",
      "5900:\tlearn: 269.3612899\ttest: 267.8258176\tbest: 267.8186237 (5898)\ttotal: 3m 18s\tremaining: 7m 55s\n",
      "6000:\tlearn: 268.8458907\ttest: 267.4938074\tbest: 267.4938074 (6000)\ttotal: 3m 22s\tremaining: 7m 51s\n",
      "6100:\tlearn: 268.2487026\ttest: 267.0616921\tbest: 267.0616921 (6100)\ttotal: 3m 25s\tremaining: 7m 48s\n",
      "6200:\tlearn: 267.4846561\ttest: 266.6106359\tbest: 266.6106359 (6200)\ttotal: 3m 28s\tremaining: 7m 44s\n",
      "6300:\tlearn: 266.8618358\ttest: 266.1747361\tbest: 266.1747361 (6300)\ttotal: 3m 32s\tremaining: 7m 41s\n",
      "6400:\tlearn: 266.4681081\ttest: 265.8683829\tbest: 265.8683829 (6400)\ttotal: 3m 35s\tremaining: 7m 37s\n",
      "6500:\tlearn: 266.0175602\ttest: 265.5629279\tbest: 265.5543646 (6496)\ttotal: 3m 38s\tremaining: 7m 33s\n",
      "6600:\tlearn: 265.4908534\ttest: 265.2022268\tbest: 265.2016097 (6598)\ttotal: 3m 41s\tremaining: 7m 29s\n",
      "6700:\tlearn: 264.8530566\ttest: 264.8427176\tbest: 264.8427176 (6700)\ttotal: 3m 44s\tremaining: 7m 25s\n",
      "6800:\tlearn: 264.4219487\ttest: 264.5100144\tbest: 264.5066990 (6799)\ttotal: 3m 47s\tremaining: 7m 22s\n",
      "6900:\tlearn: 264.0471284\ttest: 264.2645019\tbest: 264.2645019 (6900)\ttotal: 3m 50s\tremaining: 7m 18s\n",
      "7000:\tlearn: 263.5365678\ttest: 263.9393832\tbest: 263.9393832 (7000)\ttotal: 3m 53s\tremaining: 7m 13s\n",
      "7100:\tlearn: 263.1458465\ttest: 263.6921695\tbest: 263.6916343 (7098)\ttotal: 3m 56s\tremaining: 7m 10s\n",
      "7200:\tlearn: 262.7538065\ttest: 263.3979988\tbest: 263.3973614 (7198)\ttotal: 4m\tremaining: 7m 6s\n",
      "7300:\tlearn: 262.2780142\ttest: 263.0523961\tbest: 263.0523961 (7300)\ttotal: 4m 3s\tremaining: 7m 3s\n",
      "7400:\tlearn: 261.7957613\ttest: 262.7547432\tbest: 262.7547432 (7400)\ttotal: 4m 6s\tremaining: 6m 59s\n",
      "7500:\tlearn: 261.2947681\ttest: 262.4280781\tbest: 262.4280115 (7498)\ttotal: 4m 9s\tremaining: 6m 56s\n",
      "7600:\tlearn: 260.7555427\ttest: 262.0623401\tbest: 262.0623401 (7600)\ttotal: 4m 12s\tremaining: 6m 52s\n",
      "7700:\tlearn: 260.3787528\ttest: 261.8829392\tbest: 261.8814356 (7699)\ttotal: 4m 15s\tremaining: 6m 48s\n",
      "7800:\tlearn: 259.7833133\ttest: 261.4701023\tbest: 261.4693505 (7799)\ttotal: 4m 19s\tremaining: 6m 45s\n",
      "7900:\tlearn: 259.3702452\ttest: 261.1557382\tbest: 261.1557382 (7900)\ttotal: 4m 22s\tremaining: 6m 41s\n",
      "8000:\tlearn: 258.8455602\ttest: 260.8946863\tbest: 260.8946863 (8000)\ttotal: 4m 25s\tremaining: 6m 38s\n",
      "8100:\tlearn: 258.4322117\ttest: 260.6751472\tbest: 260.6751472 (8100)\ttotal: 4m 28s\tremaining: 6m 34s\n",
      "8200:\tlearn: 257.8885633\ttest: 260.3080226\tbest: 260.3080226 (8200)\ttotal: 4m 32s\tremaining: 6m 31s\n",
      "8300:\tlearn: 257.1974119\ttest: 259.8359562\tbest: 259.8359363 (8299)\ttotal: 4m 35s\tremaining: 6m 28s\n",
      "8400:\tlearn: 256.7818537\ttest: 259.5735964\tbest: 259.5711935 (8399)\ttotal: 4m 38s\tremaining: 6m 25s\n",
      "8500:\tlearn: 256.3856349\ttest: 259.3170602\tbest: 259.3170602 (8500)\ttotal: 4m 42s\tremaining: 6m 21s\n",
      "8600:\tlearn: 255.7934379\ttest: 258.9057891\tbest: 258.9057891 (8600)\ttotal: 4m 45s\tremaining: 6m 18s\n",
      "8700:\tlearn: 255.3818902\ttest: 258.5900055\tbest: 258.5898474 (8699)\ttotal: 4m 49s\tremaining: 6m 15s\n",
      "8800:\tlearn: 254.9572976\ttest: 258.3279852\tbest: 258.3279285 (8797)\ttotal: 4m 52s\tremaining: 6m 12s\n",
      "8900:\tlearn: 254.4705491\ttest: 257.9626272\tbest: 257.9618012 (8897)\ttotal: 4m 55s\tremaining: 6m 8s\n",
      "9000:\tlearn: 253.8885184\ttest: 257.4910631\tbest: 257.4891041 (8996)\ttotal: 4m 59s\tremaining: 6m 5s\n",
      "9100:\tlearn: 253.5394743\ttest: 257.3113674\tbest: 257.3113674 (9100)\ttotal: 5m 2s\tremaining: 6m 2s\n",
      "9200:\tlearn: 253.1636140\ttest: 257.0277020\tbest: 257.0273460 (9199)\ttotal: 5m 5s\tremaining: 5m 58s\n",
      "9300:\tlearn: 252.6279884\ttest: 256.6939616\tbest: 256.6939616 (9300)\ttotal: 5m 8s\tremaining: 5m 55s\n",
      "9400:\tlearn: 252.0803356\ttest: 256.2921009\tbest: 256.2921009 (9400)\ttotal: 5m 12s\tremaining: 5m 52s\n",
      "9500:\tlearn: 251.8396029\ttest: 256.1855997\tbest: 256.1855989 (9499)\ttotal: 5m 16s\tremaining: 5m 49s\n",
      "9600:\tlearn: 251.2786509\ttest: 255.8065544\tbest: 255.8061983 (9596)\ttotal: 5m 19s\tremaining: 5m 46s\n",
      "9700:\tlearn: 250.9443932\ttest: 255.5724813\tbest: 255.5710247 (9696)\ttotal: 5m 23s\tremaining: 5m 43s\n",
      "9800:\tlearn: 250.5235066\ttest: 255.2729864\tbest: 255.2713460 (9798)\ttotal: 5m 26s\tremaining: 5m 40s\n",
      "9900:\tlearn: 250.1095990\ttest: 255.0176028\tbest: 255.0175124 (9899)\ttotal: 5m 30s\tremaining: 5m 37s\n",
      "10000:\tlearn: 249.8108890\ttest: 254.7837095\tbest: 254.7837095 (10000)\ttotal: 5m 34s\tremaining: 5m 34s\n",
      "10100:\tlearn: 249.4679715\ttest: 254.5781448\tbest: 254.5772992 (10099)\ttotal: 5m 38s\tremaining: 5m 31s\n",
      "10200:\tlearn: 248.9983443\ttest: 254.3760237\tbest: 254.3760237 (10200)\ttotal: 5m 42s\tremaining: 5m 28s\n",
      "10300:\tlearn: 248.4976499\ttest: 254.0517945\tbest: 254.0517945 (10300)\ttotal: 5m 45s\tremaining: 5m 25s\n",
      "10400:\tlearn: 248.0274401\ttest: 253.7077263\tbest: 253.7077263 (10400)\ttotal: 5m 49s\tremaining: 5m 22s\n",
      "10500:\tlearn: 247.5718589\ttest: 253.3775326\tbest: 253.3775326 (10500)\ttotal: 5m 52s\tremaining: 5m 18s\n",
      "10600:\tlearn: 247.3173912\ttest: 253.1697577\tbest: 253.1688144 (10592)\ttotal: 5m 55s\tremaining: 5m 15s\n",
      "10700:\tlearn: 246.9281483\ttest: 252.9129609\tbest: 252.9127792 (10695)\ttotal: 5m 59s\tremaining: 5m 12s\n",
      "10800:\tlearn: 246.6285831\ttest: 252.7650123\tbest: 252.7650123 (10800)\ttotal: 6m 2s\tremaining: 5m 8s\n",
      "10900:\tlearn: 246.2922514\ttest: 252.5506635\tbest: 252.5483799 (10888)\ttotal: 6m 6s\tremaining: 5m 5s\n",
      "11000:\tlearn: 245.8758629\ttest: 252.3032204\tbest: 252.3032020 (10997)\ttotal: 6m 9s\tremaining: 5m 2s\n",
      "11100:\tlearn: 245.4443499\ttest: 252.0511317\tbest: 252.0504900 (11099)\ttotal: 6m 13s\tremaining: 4m 59s\n",
      "11200:\tlearn: 245.0612394\ttest: 251.8001354\tbest: 251.7976482 (11189)\ttotal: 6m 16s\tremaining: 4m 55s\n",
      "11300:\tlearn: 244.6588528\ttest: 251.5396660\tbest: 251.5392830 (11296)\ttotal: 6m 19s\tremaining: 4m 52s\n",
      "11400:\tlearn: 244.3714131\ttest: 251.3484336\tbest: 251.3484336 (11400)\ttotal: 6m 22s\tremaining: 4m 48s\n",
      "11500:\tlearn: 244.0796823\ttest: 251.1216787\tbest: 251.1212760 (11494)\ttotal: 6m 25s\tremaining: 4m 45s\n",
      "11600:\tlearn: 243.8475746\ttest: 250.9583493\tbest: 250.9583493 (11600)\ttotal: 6m 29s\tremaining: 4m 41s\n",
      "11700:\tlearn: 243.5047015\ttest: 250.7074003\tbest: 250.7070605 (11695)\ttotal: 6m 32s\tremaining: 4m 38s\n",
      "11800:\tlearn: 243.1906629\ttest: 250.4675507\tbest: 250.4675068 (11798)\ttotal: 6m 35s\tremaining: 4m 34s\n",
      "11900:\tlearn: 242.9343488\ttest: 250.2724912\tbest: 250.2720710 (11894)\ttotal: 6m 38s\tremaining: 4m 31s\n",
      "12000:\tlearn: 242.6331792\ttest: 250.0680734\tbest: 250.0680734 (12000)\ttotal: 6m 42s\tremaining: 4m 28s\n",
      "12100:\tlearn: 242.2283492\ttest: 249.7639037\tbest: 249.7638595 (12099)\ttotal: 6m 45s\tremaining: 4m 24s\n",
      "12200:\tlearn: 242.1125860\ttest: 249.6840143\tbest: 249.6840143 (12200)\ttotal: 6m 48s\tremaining: 4m 21s\n",
      "12300:\tlearn: 241.9569204\ttest: 249.5705265\tbest: 249.5705265 (12300)\ttotal: 6m 51s\tremaining: 4m 17s\n",
      "12400:\tlearn: 241.5811182\ttest: 249.2568438\tbest: 249.2568438 (12400)\ttotal: 6m 54s\tremaining: 4m 14s\n",
      "12500:\tlearn: 241.2245152\ttest: 249.0142343\tbest: 249.0139554 (12498)\ttotal: 6m 58s\tremaining: 4m 10s\n",
      "12600:\tlearn: 240.9677406\ttest: 248.8684229\tbest: 248.8682726 (12597)\ttotal: 7m 1s\tremaining: 4m 7s\n",
      "12700:\tlearn: 240.7269398\ttest: 248.7020732\tbest: 248.7013826 (12694)\ttotal: 7m 4s\tremaining: 4m 3s\n",
      "12800:\tlearn: 240.4875074\ttest: 248.5218529\tbest: 248.5211043 (12796)\ttotal: 7m 7s\tremaining: 4m\n",
      "12900:\tlearn: 240.2796526\ttest: 248.4371198\tbest: 248.4371111 (12899)\ttotal: 7m 10s\tremaining: 3m 56s\n",
      "13000:\tlearn: 239.9897944\ttest: 248.2383371\tbest: 248.2379758 (12998)\ttotal: 7m 13s\tremaining: 3m 53s\n",
      "13100:\tlearn: 239.6540810\ttest: 247.9894714\tbest: 247.9894714 (13100)\ttotal: 7m 16s\tremaining: 3m 50s\n",
      "13200:\tlearn: 239.3331789\ttest: 247.8358366\tbest: 247.8357103 (13199)\ttotal: 7m 20s\tremaining: 3m 46s\n",
      "13300:\tlearn: 239.1063309\ttest: 247.7160481\tbest: 247.7160481 (13300)\ttotal: 7m 23s\tremaining: 3m 43s\n",
      "13400:\tlearn: 238.6466329\ttest: 247.4483120\tbest: 247.4483116 (13398)\ttotal: 7m 26s\tremaining: 3m 40s\n",
      "13500:\tlearn: 238.3088455\ttest: 247.2430650\tbest: 247.2430650 (13500)\ttotal: 7m 29s\tremaining: 3m 36s\n",
      "13600:\tlearn: 238.0479947\ttest: 247.0918595\tbest: 247.0918595 (13600)\ttotal: 7m 33s\tremaining: 3m 33s\n",
      "13700:\tlearn: 237.7677478\ttest: 246.9176093\tbest: 246.9175854 (13698)\ttotal: 7m 36s\tremaining: 3m 29s\n",
      "13800:\tlearn: 237.4580471\ttest: 246.7229947\tbest: 246.7229947 (13800)\ttotal: 7m 39s\tremaining: 3m 26s\n",
      "13900:\tlearn: 237.1471133\ttest: 246.5541084\tbest: 246.5541084 (13900)\ttotal: 7m 43s\tremaining: 3m 23s\n",
      "14000:\tlearn: 236.9358378\ttest: 246.4256050\tbest: 246.4255587 (13996)\ttotal: 7m 46s\tremaining: 3m 19s\n",
      "14100:\tlearn: 236.7213399\ttest: 246.2595024\tbest: 246.2595024 (14100)\ttotal: 7m 49s\tremaining: 3m 16s\n",
      "14200:\tlearn: 236.4687763\ttest: 246.1632541\tbest: 246.1632541 (14200)\ttotal: 7m 52s\tremaining: 3m 13s\n",
      "14300:\tlearn: 236.3414865\ttest: 246.0704734\tbest: 246.0704734 (14300)\ttotal: 7m 56s\tremaining: 3m 9s\n",
      "14400:\tlearn: 236.1400261\ttest: 245.9525217\tbest: 245.9525217 (14400)\ttotal: 7m 59s\tremaining: 3m 6s\n",
      "14500:\tlearn: 235.9667575\ttest: 245.8819790\tbest: 245.8813738 (14490)\ttotal: 8m 2s\tremaining: 3m 2s\n",
      "14600:\tlearn: 235.8077646\ttest: 245.7564842\tbest: 245.7564586 (14599)\ttotal: 8m 5s\tremaining: 2m 59s\n",
      "14700:\tlearn: 235.6692669\ttest: 245.6701522\tbest: 245.6700528 (14696)\ttotal: 8m 8s\tremaining: 2m 56s\n",
      "14800:\tlearn: 235.5202128\ttest: 245.5956575\tbest: 245.5956575 (14800)\ttotal: 8m 12s\tremaining: 2m 52s\n",
      "14900:\tlearn: 235.3717021\ttest: 245.4993449\tbest: 245.4991849 (14893)\ttotal: 8m 15s\tremaining: 2m 49s\n",
      "15000:\tlearn: 235.1065920\ttest: 245.3277265\tbest: 245.3269529 (14998)\ttotal: 8m 18s\tremaining: 2m 46s\n",
      "15100:\tlearn: 234.8731889\ttest: 245.2007064\tbest: 245.2007064 (15100)\ttotal: 8m 21s\tremaining: 2m 42s\n",
      "15200:\tlearn: 234.5542222\ttest: 245.0483748\tbest: 245.0483748 (15200)\ttotal: 8m 25s\tremaining: 2m 39s\n",
      "15300:\tlearn: 234.3553741\ttest: 244.9195426\tbest: 244.9085056 (15294)\ttotal: 8m 28s\tremaining: 2m 36s\n",
      "15400:\tlearn: 234.1359855\ttest: 244.7888283\tbest: 244.7887214 (15398)\ttotal: 8m 31s\tremaining: 2m 32s\n",
      "15500:\tlearn: 233.9553411\ttest: 244.7143133\tbest: 244.7109471 (15496)\ttotal: 8m 35s\tremaining: 2m 29s\n",
      "15600:\tlearn: 233.7538872\ttest: 244.6167736\tbest: 244.6112638 (15595)\ttotal: 8m 38s\tremaining: 2m 26s\n",
      "15700:\tlearn: 233.4458333\ttest: 244.4226046\tbest: 244.4226046 (15700)\ttotal: 8m 42s\tremaining: 2m 22s\n",
      "15800:\tlearn: 233.2845940\ttest: 244.3108657\tbest: 244.3108657 (15800)\ttotal: 8m 45s\tremaining: 2m 19s\n",
      "15900:\tlearn: 233.0397189\ttest: 244.1102669\tbest: 244.1101913 (15898)\ttotal: 8m 48s\tremaining: 2m 16s\n",
      "16000:\tlearn: 232.8659210\ttest: 244.0177414\tbest: 244.0177414 (16000)\ttotal: 8m 51s\tremaining: 2m 12s\n",
      "16100:\tlearn: 232.6545191\ttest: 243.9191413\tbest: 243.9190440 (16099)\ttotal: 8m 55s\tremaining: 2m 9s\n",
      "16200:\tlearn: 232.4435182\ttest: 243.8315843\tbest: 243.8315843 (16200)\ttotal: 8m 58s\tremaining: 2m 6s\n",
      "16300:\tlearn: 232.2391650\ttest: 243.6815295\tbest: 243.6815295 (16300)\ttotal: 9m 1s\tremaining: 2m 2s\n",
      "16400:\tlearn: 232.0494327\ttest: 243.5739663\tbest: 243.5739663 (16400)\ttotal: 9m 4s\tremaining: 1m 59s\n",
      "16500:\tlearn: 231.8537691\ttest: 243.4607188\tbest: 243.4607188 (16500)\ttotal: 9m 8s\tremaining: 1m 56s\n",
      "16600:\tlearn: 231.6699537\ttest: 243.3385684\tbest: 243.3383945 (16599)\ttotal: 9m 11s\tremaining: 1m 52s\n",
      "16700:\tlearn: 231.4826651\ttest: 243.2657774\tbest: 243.2657462 (16698)\ttotal: 9m 14s\tremaining: 1m 49s\n",
      "16800:\tlearn: 231.2851450\ttest: 243.1184913\tbest: 243.1184913 (16800)\ttotal: 9m 18s\tremaining: 1m 46s\n",
      "16900:\tlearn: 231.0854298\ttest: 242.9713251\tbest: 242.9711766 (16896)\ttotal: 9m 21s\tremaining: 1m 42s\n",
      "17000:\tlearn: 230.8981060\ttest: 242.8810341\tbest: 242.8778238 (16995)\ttotal: 9m 24s\tremaining: 1m 39s\n",
      "17100:\tlearn: 230.7821976\ttest: 242.7910074\tbest: 242.7910074 (17100)\ttotal: 9m 27s\tremaining: 1m 36s\n",
      "17200:\tlearn: 230.6284290\ttest: 242.6766886\tbest: 242.6766623 (17198)\ttotal: 9m 31s\tremaining: 1m 32s\n",
      "17300:\tlearn: 230.4378032\ttest: 242.5220735\tbest: 242.5210702 (17297)\ttotal: 9m 34s\tremaining: 1m 29s\n",
      "17400:\tlearn: 230.3366172\ttest: 242.4585516\tbest: 242.4584338 (17399)\ttotal: 9m 37s\tremaining: 1m 26s\n",
      "17500:\tlearn: 230.2418574\ttest: 242.3821045\tbest: 242.3807059 (17495)\ttotal: 9m 40s\tremaining: 1m 22s\n",
      "17600:\tlearn: 230.1334456\ttest: 242.3043202\tbest: 242.3043202 (17600)\ttotal: 9m 43s\tremaining: 1m 19s\n",
      "17700:\tlearn: 230.0205497\ttest: 242.2312245\tbest: 242.2305764 (17694)\ttotal: 9m 47s\tremaining: 1m 16s\n",
      "17800:\tlearn: 229.9316422\ttest: 242.1563095\tbest: 242.1562845 (17799)\ttotal: 9m 50s\tremaining: 1m 12s\n",
      "17900:\tlearn: 229.8242502\ttest: 242.0773726\tbest: 242.0773726 (17900)\ttotal: 9m 53s\tremaining: 1m 9s\n",
      "18000:\tlearn: 229.7028648\ttest: 242.0118549\tbest: 242.0114837 (17997)\ttotal: 9m 56s\tremaining: 1m 6s\n",
      "18100:\tlearn: 229.5962813\ttest: 241.9608415\tbest: 241.9605986 (18098)\ttotal: 10m\tremaining: 1m 2s\n",
      "18200:\tlearn: 229.5023138\ttest: 241.9205768\tbest: 241.9205768 (18200)\ttotal: 10m 3s\tremaining: 59.6s\n",
      "18300:\tlearn: 229.2934202\ttest: 241.8198384\tbest: 241.8186644 (18287)\ttotal: 10m 6s\tremaining: 56.3s\n",
      "18400:\tlearn: 229.1993754\ttest: 241.7831188\tbest: 241.7813990 (18392)\ttotal: 10m 10s\tremaining: 53s\n",
      "18500:\tlearn: 229.0711530\ttest: 241.7655544\tbest: 241.7575182 (18471)\ttotal: 10m 13s\tremaining: 49.7s\n",
      "18600:\tlearn: 228.9400280\ttest: 241.7022027\tbest: 241.7022027 (18600)\ttotal: 10m 16s\tremaining: 46.4s\n",
      "18700:\tlearn: 228.7677801\ttest: 241.5975624\tbest: 241.5975624 (18700)\ttotal: 10m 20s\tremaining: 43.1s\n",
      "18800:\tlearn: 228.6199692\ttest: 241.5536831\tbest: 241.5536831 (18800)\ttotal: 10m 23s\tremaining: 39.8s\n",
      "18900:\tlearn: 228.4765618\ttest: 241.4828055\tbest: 241.4828055 (18900)\ttotal: 10m 26s\tremaining: 36.4s\n",
      "19000:\tlearn: 228.3796347\ttest: 241.4369634\tbest: 241.4364925 (18985)\ttotal: 10m 29s\tremaining: 33.1s\n",
      "19100:\tlearn: 228.2628522\ttest: 241.3600501\tbest: 241.3600501 (19100)\ttotal: 10m 32s\tremaining: 29.8s\n",
      "19200:\tlearn: 228.1273153\ttest: 241.2630268\tbest: 241.2613482 (19184)\ttotal: 10m 36s\tremaining: 26.5s\n",
      "19300:\tlearn: 228.0027105\ttest: 241.1938262\tbest: 241.1938262 (19300)\ttotal: 10m 39s\tremaining: 23.2s\n",
      "19400:\tlearn: 227.8824870\ttest: 241.1416358\tbest: 241.1416041 (19399)\ttotal: 10m 42s\tremaining: 19.8s\n",
      "19500:\tlearn: 227.7557913\ttest: 241.0876742\tbest: 241.0865172 (19498)\ttotal: 10m 45s\tremaining: 16.5s\n",
      "19600:\tlearn: 227.6499263\ttest: 241.0391602\tbest: 241.0378016 (19593)\ttotal: 10m 49s\tremaining: 13.2s\n",
      "19700:\tlearn: 227.5765412\ttest: 240.9956430\tbest: 240.9949678 (19697)\ttotal: 10m 52s\tremaining: 9.9s\n",
      "19800:\tlearn: 227.4804451\ttest: 240.9526765\tbest: 240.9520816 (19792)\ttotal: 10m 55s\tremaining: 6.59s\n",
      "19900:\tlearn: 227.4013886\ttest: 240.9246619\tbest: 240.9188768 (19893)\ttotal: 10m 59s\tremaining: 3.28s\n",
      "19999:\tlearn: 227.2352289\ttest: 240.8143621\tbest: 240.8143373 (19998)\ttotal: 11m 2s\tremaining: 0us\n",
      "\n",
      "bestTest = 240.8143373\n",
      "bestIteration = 19998\n",
      "\n",
      "Shrink model to first 19999 iterations.",
      "\n",
      "0:\tlearn: 973.6291203\ttest: 1019.3759199\tbest: 1019.3759199 (0)\ttotal: 29.4ms\tremaining: 9m 48s\n",
      "100:\tlearn: 605.8131932\ttest: 657.3896172\tbest: 657.3896172 (100)\ttotal: 3.42s\tremaining: 11m 12s\n",
      "200:\tlearn: 493.8000123\ttest: 532.1503087\tbest: 532.1503087 (200)\ttotal: 6.99s\tremaining: 11m 28s\n",
      "300:\tlearn: 438.9512296\ttest: 464.0444782\tbest: 464.0444782 (300)\ttotal: 10.5s\tremaining: 11m 28s\n",
      "400:\tlearn: 416.9843232\ttest: 432.8066870\tbest: 432.8066870 (400)\ttotal: 13.8s\tremaining: 11m 14s\n",
      "500:\tlearn: 402.2520367\ttest: 411.6698861\tbest: 411.6698861 (500)\ttotal: 17.2s\tremaining: 11m 11s\n",
      "600:\tlearn: 391.2291905\ttest: 397.0311726\tbest: 397.0311726 (600)\ttotal: 20.4s\tremaining: 10m 58s\n",
      "700:\tlearn: 379.7352012\ttest: 381.8690071\tbest: 381.8690071 (700)\ttotal: 23.9s\tremaining: 10m 57s\n",
      "800:\tlearn: 372.1212643\ttest: 372.1369578\tbest: 372.1369578 (800)\ttotal: 27s\tremaining: 10m 48s\n",
      "900:\tlearn: 364.0823964\ttest: 362.5016472\tbest: 362.5016472 (900)\ttotal: 30.5s\tremaining: 10m 47s\n",
      "1000:\tlearn: 356.9158674\ttest: 353.0984894\tbest: 353.0984894 (1000)\ttotal: 33.8s\tremaining: 10m 41s\n",
      "1100:\tlearn: 349.8951584\ttest: 344.7121409\tbest: 344.7121409 (1100)\ttotal: 37.2s\tremaining: 10m 38s\n",
      "1200:\tlearn: 343.4753505\ttest: 337.8754679\tbest: 337.8754679 (1200)\ttotal: 40.5s\tremaining: 10m 34s\n",
      "1300:\tlearn: 337.8334214\ttest: 331.8555427\tbest: 331.8555427 (1300)\ttotal: 44s\tremaining: 10m 32s\n",
      "1400:\tlearn: 332.6318231\ttest: 326.2039380\tbest: 326.2039380 (1400)\ttotal: 47.4s\tremaining: 10m 29s\n",
      "1500:\tlearn: 327.9481140\ttest: 321.3466059\tbest: 321.3466059 (1500)\ttotal: 51s\tremaining: 10m 28s\n",
      "1600:\tlearn: 324.3483047\ttest: 317.7827052\tbest: 317.7827052 (1600)\ttotal: 54.4s\tremaining: 10m 25s\n",
      "1700:\tlearn: 320.4029351\ttest: 314.0480271\tbest: 314.0480271 (1700)\ttotal: 57.9s\tremaining: 10m 22s\n",
      "1800:\tlearn: 317.0654291\ttest: 311.0020678\tbest: 311.0020678 (1800)\ttotal: 1m 1s\tremaining: 10m 18s\n",
      "1900:\tlearn: 314.3168075\ttest: 308.5864853\tbest: 308.5864853 (1900)\ttotal: 1m 4s\tremaining: 10m 15s\n",
      "2000:\tlearn: 311.5884330\ttest: 305.9926522\tbest: 305.9926522 (2000)\ttotal: 1m 8s\tremaining: 10m 11s\n",
      "2100:\tlearn: 309.0263076\ttest: 303.4319205\tbest: 303.4319205 (2100)\ttotal: 1m 11s\tremaining: 10m 7s\n",
      "2200:\tlearn: 306.7374508\ttest: 301.5284965\tbest: 301.5284965 (2200)\ttotal: 1m 14s\tremaining: 10m 3s\n",
      "2300:\tlearn: 305.0283651\ttest: 300.1792360\tbest: 300.1792360 (2300)\ttotal: 1m 17s\tremaining: 9m 58s\n",
      "2400:\tlearn: 303.2308473\ttest: 298.6520881\tbest: 298.6520881 (2400)\ttotal: 1m 20s\tremaining: 9m 53s\n",
      "2500:\tlearn: 301.4362285\ttest: 297.2495224\tbest: 297.2495224 (2500)\ttotal: 1m 24s\tremaining: 9m 48s\n",
      "2600:\tlearn: 299.9087675\ttest: 295.9457662\tbest: 295.9457580 (2599)\ttotal: 1m 27s\tremaining: 9m 42s\n",
      "2700:\tlearn: 298.4155761\ttest: 294.7590063\tbest: 294.7590063 (2700)\ttotal: 1m 30s\tremaining: 9m 36s\n",
      "2800:\tlearn: 297.4330595\ttest: 294.0498959\tbest: 294.0498959 (2800)\ttotal: 1m 32s\tremaining: 9m 30s\n",
      "2900:\tlearn: 296.2697701\ttest: 293.0331793\tbest: 293.0331793 (2900)\ttotal: 1m 35s\tremaining: 9m 24s\n",
      "3000:\tlearn: 295.1348039\ttest: 292.2110882\tbest: 292.2110882 (3000)\ttotal: 1m 38s\tremaining: 9m 18s\n",
      "3100:\tlearn: 293.8703508\ttest: 291.2020565\tbest: 291.2018350 (3097)\ttotal: 1m 41s\tremaining: 9m 13s\n",
      "3200:\tlearn: 292.7161026\ttest: 290.3736464\tbest: 290.3736464 (3200)\ttotal: 1m 44s\tremaining: 9m 8s\n",
      "3300:\tlearn: 291.6094049\ttest: 289.5427478\tbest: 289.5427478 (3300)\ttotal: 1m 47s\tremaining: 9m 4s\n",
      "3400:\tlearn: 290.4686973\ttest: 288.6404267\tbest: 288.6404267 (3400)\ttotal: 1m 50s\tremaining: 8m 59s\n",
      "3500:\tlearn: 289.0033040\ttest: 287.3489453\tbest: 287.3489453 (3500)\ttotal: 1m 53s\tremaining: 8m 55s\n",
      "3600:\tlearn: 288.0781140\ttest: 286.7562680\tbest: 286.7562680 (3600)\ttotal: 1m 56s\tremaining: 8m 50s\n",
      "3700:\tlearn: 287.1500306\ttest: 286.0255448\tbest: 286.0255448 (3700)\ttotal: 1m 59s\tremaining: 8m 46s\n",
      "3800:\tlearn: 286.4250241\ttest: 285.5147813\tbest: 285.5147800 (3799)\ttotal: 2m 2s\tremaining: 8m 42s\n",
      "3900:\tlearn: 285.7099642\ttest: 284.9285809\tbest: 284.9285809 (3900)\ttotal: 2m 5s\tremaining: 8m 37s\n",
      "4000:\tlearn: 284.9526915\ttest: 284.4135520\tbest: 284.4131742 (3999)\ttotal: 2m 8s\tremaining: 8m 32s\n",
      "4100:\tlearn: 283.9256858\ttest: 283.5671101\tbest: 283.5671101 (4100)\ttotal: 2m 11s\tremaining: 8m 28s\n",
      "4200:\tlearn: 282.9867235\ttest: 282.8886426\tbest: 282.8878194 (4196)\ttotal: 2m 13s\tremaining: 8m 23s\n",
      "4300:\tlearn: 282.3760630\ttest: 282.3839431\tbest: 282.3836335 (4299)\ttotal: 2m 16s\tremaining: 8m 18s\n",
      "4400:\tlearn: 281.7527048\ttest: 281.9667315\tbest: 281.9667315 (4400)\ttotal: 2m 19s\tremaining: 8m 14s\n",
      "4500:\tlearn: 280.7755005\ttest: 281.1893395\tbest: 281.1893395 (4500)\ttotal: 2m 22s\tremaining: 8m 10s\n",
      "4600:\tlearn: 279.4829102\ttest: 280.3027819\tbest: 280.2973599 (4599)\ttotal: 2m 25s\tremaining: 8m 8s\n",
      "4700:\tlearn: 278.6671625\ttest: 279.7485364\tbest: 279.7482975 (4698)\ttotal: 2m 28s\tremaining: 8m 4s\n",
      "4800:\tlearn: 277.7857767\ttest: 279.0852528\tbest: 279.0846774 (4799)\ttotal: 2m 31s\tremaining: 8m 1s\n",
      "4900:\tlearn: 277.0606342\ttest: 278.5972787\tbest: 278.5960806 (4899)\ttotal: 2m 34s\tremaining: 7m 57s\n",
      "5000:\tlearn: 276.0747786\ttest: 277.9012936\tbest: 277.9011781 (4998)\ttotal: 2m 38s\tremaining: 7m 54s\n",
      "5100:\tlearn: 275.1588150\ttest: 277.3073020\tbest: 277.3073020 (5100)\ttotal: 2m 41s\tremaining: 7m 50s\n",
      "5200:\tlearn: 274.3789918\ttest: 276.8748143\tbest: 276.8748143 (5200)\ttotal: 2m 44s\tremaining: 7m 46s\n",
      "5300:\tlearn: 273.0725953\ttest: 275.9724967\tbest: 275.9724967 (5300)\ttotal: 2m 47s\tremaining: 7m 43s\n",
      "5400:\tlearn: 272.2659181\ttest: 275.4538515\tbest: 275.4538515 (5400)\ttotal: 2m 50s\tremaining: 7m 41s\n",
      "5500:\tlearn: 271.3369599\ttest: 274.8661538\tbest: 274.8661538 (5500)\ttotal: 2m 53s\tremaining: 7m 37s\n",
      "5600:\tlearn: 270.8194664\ttest: 274.5924434\tbest: 274.5924434 (5600)\ttotal: 2m 56s\tremaining: 7m 34s\n",
      "5700:\tlearn: 269.9060721\ttest: 274.0230960\tbest: 274.0215793 (5693)\ttotal: 2m 59s\tremaining: 7m 30s\n",
      "5800:\tlearn: 269.1626585\ttest: 273.5663570\tbest: 273.5660099 (5794)\ttotal: 3m 2s\tremaining: 7m 26s\n",
      "5900:\tlearn: 268.3496046\ttest: 273.0709664\tbest: 273.0709664 (5900)\ttotal: 3m 5s\tremaining: 7m 22s\n",
      "6000:\tlearn: 267.6220845\ttest: 272.5115909\tbest: 272.5107931 (5998)\ttotal: 3m 8s\tremaining: 7m 19s\n",
      "6100:\tlearn: 267.1323879\ttest: 272.1983973\tbest: 272.1922988 (6092)\ttotal: 3m 11s\tremaining: 7m 16s\n",
      "6200:\tlearn: 266.5220050\ttest: 271.8063260\tbest: 271.8063260 (6200)\ttotal: 3m 14s\tremaining: 7m 12s\n",
      "6300:\tlearn: 266.0932283\ttest: 271.4955256\tbest: 271.4928940 (6297)\ttotal: 3m 17s\tremaining: 7m 9s\n",
      "6400:\tlearn: 265.6238386\ttest: 271.1735912\tbest: 271.1735912 (6400)\ttotal: 3m 20s\tremaining: 7m 5s\n",
      "6500:\tlearn: 265.2034581\ttest: 270.8559555\tbest: 270.8559555 (6500)\ttotal: 3m 23s\tremaining: 7m 1s\n",
      "6600:\tlearn: 264.7247638\ttest: 270.5762021\tbest: 270.5751919 (6597)\ttotal: 3m 25s\tremaining: 6m 58s\n",
      "6700:\tlearn: 264.0173281\ttest: 270.0704496\tbest: 270.0704496 (6700)\ttotal: 3m 28s\tremaining: 6m 54s\n",
      "6800:\tlearn: 263.6047455\ttest: 269.8149869\tbest: 269.8099776 (6799)\ttotal: 3m 31s\tremaining: 6m 50s\n",
      "6900:\tlearn: 263.2617717\ttest: 269.6143381\tbest: 269.6143381 (6900)\ttotal: 3m 34s\tremaining: 6m 46s\n",
      "7000:\tlearn: 262.8300734\ttest: 269.2781095\tbest: 269.2781095 (7000)\ttotal: 3m 36s\tremaining: 6m 42s\n",
      "7100:\tlearn: 262.4584720\ttest: 269.0191438\tbest: 269.0191438 (7100)\ttotal: 3m 39s\tremaining: 6m 39s\n",
      "7200:\tlearn: 262.0318259\ttest: 268.7343814\tbest: 268.7343814 (7200)\ttotal: 3m 42s\tremaining: 6m 35s\n",
      "7300:\tlearn: 261.5915045\ttest: 268.3980607\tbest: 268.3978586 (7296)\ttotal: 3m 44s\tremaining: 6m 31s\n",
      "7400:\tlearn: 261.2993860\ttest: 268.1990618\tbest: 268.1990618 (7400)\ttotal: 3m 47s\tremaining: 6m 26s\n",
      "7500:\tlearn: 261.0710305\ttest: 268.0529051\tbest: 268.0529045 (7499)\ttotal: 3m 49s\tremaining: 6m 22s\n",
      "7600:\tlearn: 260.7265156\ttest: 267.8429426\tbest: 267.8429426 (7600)\ttotal: 3m 52s\tremaining: 6m 18s\n",
      "7700:\tlearn: 260.4274437\ttest: 267.6457237\tbest: 267.6450359 (7687)\ttotal: 3m 54s\tremaining: 6m 15s\n",
      "7800:\tlearn: 259.9474803\ttest: 267.3494640\tbest: 267.3494640 (7800)\ttotal: 3m 57s\tremaining: 6m 11s\n",
      "7900:\tlearn: 259.5279528\ttest: 266.9952584\tbest: 266.9952584 (7900)\ttotal: 4m\tremaining: 6m 8s\n",
      "8000:\tlearn: 259.2649406\ttest: 266.8285921\tbest: 266.8279219 (7986)\ttotal: 4m 3s\tremaining: 6m 4s\n",
      "8100:\tlearn: 258.8839555\ttest: 266.5349842\tbest: 266.5342497 (8096)\ttotal: 4m 5s\tremaining: 6m 1s\n",
      "8200:\tlearn: 258.6628138\ttest: 266.3481889\tbest: 266.3481889 (8200)\ttotal: 4m 8s\tremaining: 5m 57s\n",
      "8300:\tlearn: 258.4068901\ttest: 266.1567422\tbest: 266.1567422 (8300)\ttotal: 4m 11s\tremaining: 5m 53s\n",
      "8400:\tlearn: 258.0769237\ttest: 265.9649109\tbest: 265.9647080 (8395)\ttotal: 4m 13s\tremaining: 5m 50s\n",
      "8500:\tlearn: 257.6280324\ttest: 265.6658546\tbest: 265.6658546 (8500)\ttotal: 4m 16s\tremaining: 5m 47s\n",
      "8600:\tlearn: 257.1314156\ttest: 265.2498613\tbest: 265.2497562 (8598)\ttotal: 4m 19s\tremaining: 5m 44s\n",
      "8700:\tlearn: 256.4602688\ttest: 264.6924955\tbest: 264.6920190 (8697)\ttotal: 4m 22s\tremaining: 5m 40s\n",
      "8800:\tlearn: 255.7572082\ttest: 264.0665822\tbest: 264.0665822 (8800)\ttotal: 4m 25s\tremaining: 5m 37s\n",
      "8900:\tlearn: 255.0877380\ttest: 263.5100427\tbest: 263.5100427 (8900)\ttotal: 4m 28s\tremaining: 5m 34s\n",
      "9000:\tlearn: 254.4389934\ttest: 263.0912121\tbest: 263.0912121 (9000)\ttotal: 4m 31s\tremaining: 5m 31s\n",
      "9100:\tlearn: 253.9797548\ttest: 262.8269453\tbest: 262.8262611 (9095)\ttotal: 4m 34s\tremaining: 5m 28s\n",
      "9200:\tlearn: 253.5118445\ttest: 262.4813009\tbest: 262.4802452 (9199)\ttotal: 4m 37s\tremaining: 5m 25s\n",
      "9300:\tlearn: 253.1657457\ttest: 262.2380185\tbest: 262.2367171 (9294)\ttotal: 4m 39s\tremaining: 5m 22s\n",
      "9400:\tlearn: 252.8377842\ttest: 261.9559345\tbest: 261.9475912 (9396)\ttotal: 4m 42s\tremaining: 5m 19s\n",
      "9500:\tlearn: 252.6066660\ttest: 261.8462716\tbest: 261.8462716 (9500)\ttotal: 4m 45s\tremaining: 5m 16s\n",
      "9600:\tlearn: 252.0316063\ttest: 261.4319693\tbest: 261.4319693 (9600)\ttotal: 4m 48s\tremaining: 5m 12s\n",
      "9700:\tlearn: 251.4252190\ttest: 260.9358634\tbest: 260.9358634 (9700)\ttotal: 4m 51s\tremaining: 5m 9s\n",
      "9800:\tlearn: 251.0502841\ttest: 260.6816121\tbest: 260.6816121 (9800)\ttotal: 4m 54s\tremaining: 5m 6s\n",
      "9900:\tlearn: 250.7140160\ttest: 260.4171221\tbest: 260.4170856 (9899)\ttotal: 4m 57s\tremaining: 5m 3s\n",
      "10000:\tlearn: 250.4469395\ttest: 260.2387566\tbest: 260.2387566 (10000)\ttotal: 5m\tremaining: 5m\n",
      "10100:\tlearn: 250.0717413\ttest: 259.9475793\tbest: 259.9475793 (10100)\ttotal: 5m 3s\tremaining: 4m 57s\n",
      "10200:\tlearn: 249.6904347\ttest: 259.7584703\tbest: 259.7584703 (10200)\ttotal: 5m 6s\tremaining: 4m 54s\n",
      "10300:\tlearn: 249.2664151\ttest: 259.3737121\tbest: 259.3737121 (10300)\ttotal: 5m 9s\tremaining: 4m 51s\n",
      "10400:\tlearn: 248.8232071\ttest: 259.0660767\tbest: 259.0660767 (10400)\ttotal: 5m 13s\tremaining: 4m 49s\n",
      "10500:\tlearn: 248.5075816\ttest: 258.8205412\tbest: 258.8188688 (10494)\ttotal: 5m 16s\tremaining: 4m 46s\n",
      "10600:\tlearn: 248.0430329\ttest: 258.4910894\tbest: 258.4910894 (10600)\ttotal: 5m 20s\tremaining: 4m 43s\n",
      "10700:\tlearn: 247.7541215\ttest: 258.3325585\tbest: 258.3284119 (10691)\ttotal: 5m 23s\tremaining: 4m 41s\n",
      "10800:\tlearn: 247.4784400\ttest: 258.1350229\tbest: 258.1316357 (10789)\ttotal: 5m 26s\tremaining: 4m 38s\n",
      "10900:\tlearn: 247.1010619\ttest: 257.9442505\tbest: 257.9442505 (10900)\ttotal: 5m 30s\tremaining: 4m 35s\n",
      "11000:\tlearn: 246.8060630\ttest: 257.7285333\tbest: 257.7285333 (11000)\ttotal: 5m 33s\tremaining: 4m 32s\n",
      "11100:\tlearn: 246.5305319\ttest: 257.5312871\tbest: 257.5294539 (11094)\ttotal: 5m 36s\tremaining: 4m 29s\n",
      "11200:\tlearn: 246.3181995\ttest: 257.3530086\tbest: 257.3516982 (11195)\ttotal: 5m 39s\tremaining: 4m 26s\n",
      "11300:\tlearn: 245.9925934\ttest: 257.0619711\tbest: 257.0619711 (11300)\ttotal: 5m 43s\tremaining: 4m 24s\n",
      "11400:\tlearn: 245.5799374\ttest: 256.7813163\tbest: 256.7735952 (11394)\ttotal: 5m 46s\tremaining: 4m 21s\n",
      "11500:\tlearn: 245.1405495\ttest: 256.4609624\tbest: 256.4609624 (11500)\ttotal: 5m 50s\tremaining: 4m 18s\n",
      "11600:\tlearn: 244.8397246\ttest: 256.2968790\tbest: 256.2968790 (11600)\ttotal: 5m 53s\tremaining: 4m 15s\n",
      "11700:\tlearn: 244.6711302\ttest: 256.1989077\tbest: 256.1986464 (11697)\ttotal: 5m 56s\tremaining: 4m 13s\n",
      "11800:\tlearn: 244.3764047\ttest: 256.0171596\tbest: 256.0052888 (11795)\ttotal: 6m\tremaining: 4m 10s\n",
      "11900:\tlearn: 244.2106243\ttest: 255.9314513\tbest: 255.9313882 (11899)\ttotal: 6m 3s\tremaining: 4m 7s\n",
      "12000:\tlearn: 243.9440143\ttest: 255.7694758\tbest: 255.7693792 (11999)\ttotal: 6m 6s\tremaining: 4m 4s\n",
      "12100:\tlearn: 243.6895279\ttest: 255.6085959\tbest: 255.6085959 (12100)\ttotal: 6m 10s\tremaining: 4m 1s\n",
      "12200:\tlearn: 243.3630130\ttest: 255.3555836\tbest: 255.3555836 (12200)\ttotal: 6m 13s\tremaining: 3m 58s\n",
      "12300:\tlearn: 243.0621721\ttest: 255.1673903\tbest: 255.1673903 (12300)\ttotal: 6m 16s\tremaining: 3m 55s\n",
      "12400:\tlearn: 242.8447099\ttest: 255.0838257\tbest: 255.0838257 (12400)\ttotal: 6m 20s\tremaining: 3m 52s\n",
      "12500:\tlearn: 242.6438569\ttest: 254.9602411\tbest: 254.9595335 (12498)\ttotal: 6m 23s\tremaining: 3m 49s\n",
      "12600:\tlearn: 242.2974883\ttest: 254.7646413\tbest: 254.7618651 (12591)\ttotal: 6m 27s\tremaining: 3m 47s\n",
      "12700:\tlearn: 242.0306717\ttest: 254.6590031\tbest: 254.6590031 (12700)\ttotal: 6m 30s\tremaining: 3m 44s\n",
      "12800:\tlearn: 241.7025265\ttest: 254.4796063\tbest: 254.4793975 (12798)\ttotal: 6m 34s\tremaining: 3m 41s\n",
      "12900:\tlearn: 241.3909959\ttest: 254.3340857\tbest: 254.3335501 (12898)\ttotal: 6m 37s\tremaining: 3m 38s\n",
      "13000:\tlearn: 241.1059996\ttest: 254.1544446\tbest: 254.1544446 (13000)\ttotal: 6m 40s\tremaining: 3m 35s\n",
      "13100:\tlearn: 240.8857152\ttest: 254.1008904\tbest: 254.1005765 (13048)\ttotal: 6m 43s\tremaining: 3m 32s\n",
      "13200:\tlearn: 240.6559929\ttest: 253.9469090\tbest: 253.9468756 (13199)\ttotal: 6m 46s\tremaining: 3m 29s\n",
      "13300:\tlearn: 240.3671541\ttest: 253.8443467\tbest: 253.8424848 (13296)\ttotal: 6m 49s\tremaining: 3m 26s\n",
      "13400:\tlearn: 240.1446374\ttest: 253.7356016\tbest: 253.7287420 (13394)\ttotal: 6m 52s\tremaining: 3m 23s\n",
      "13500:\tlearn: 239.8663935\ttest: 253.5513651\tbest: 253.5482352 (13490)\ttotal: 6m 56s\tremaining: 3m 20s\n",
      "13600:\tlearn: 239.5669086\ttest: 253.3557005\tbest: 253.3557005 (13600)\ttotal: 6m 59s\tremaining: 3m 17s\n",
      "13700:\tlearn: 239.3675113\ttest: 253.2454815\tbest: 253.2444538 (13696)\ttotal: 7m 3s\tremaining: 3m 14s\n",
      "13800:\tlearn: 239.0348382\ttest: 253.0464606\tbest: 253.0464606 (13800)\ttotal: 7m 6s\tremaining: 3m 11s\n",
      "13900:\tlearn: 238.8179313\ttest: 252.9044623\tbest: 252.9044623 (13900)\ttotal: 7m 9s\tremaining: 3m 8s\n",
      "14000:\tlearn: 238.5904655\ttest: 252.7539183\tbest: 252.7539183 (14000)\ttotal: 7m 12s\tremaining: 3m 5s\n",
      "14100:\tlearn: 238.3686975\ttest: 252.6338426\tbest: 252.6336226 (14099)\ttotal: 7m 15s\tremaining: 3m 2s\n",
      "14200:\tlearn: 238.1815128\ttest: 252.4925945\tbest: 252.4925606 (14198)\ttotal: 7m 18s\tremaining: 2m 59s\n",
      "14300:\tlearn: 237.9612908\ttest: 252.3603877\tbest: 252.3603877 (14300)\ttotal: 7m 21s\tremaining: 2m 56s\n",
      "14400:\tlearn: 237.7457037\ttest: 252.2106841\tbest: 252.2106841 (14400)\ttotal: 7m 25s\tremaining: 2m 53s\n",
      "14500:\tlearn: 237.6154989\ttest: 252.1372374\tbest: 252.1372374 (14500)\ttotal: 7m 28s\tremaining: 2m 49s\n",
      "14600:\tlearn: 237.5040604\ttest: 252.0486592\tbest: 252.0484466 (14599)\ttotal: 7m 31s\tremaining: 2m 46s\n",
      "14700:\tlearn: 237.3305416\ttest: 251.9426361\tbest: 251.9426361 (14700)\ttotal: 7m 34s\tremaining: 2m 43s\n",
      "14800:\tlearn: 237.1320651\ttest: 251.7920400\tbest: 251.7893823 (14799)\ttotal: 7m 37s\tremaining: 2m 40s\n",
      "14900:\tlearn: 236.9733435\ttest: 251.6743040\tbest: 251.6737178 (14898)\ttotal: 7m 40s\tremaining: 2m 37s\n",
      "15000:\tlearn: 236.8232679\ttest: 251.5777775\tbest: 251.5757965 (14989)\ttotal: 7m 43s\tremaining: 2m 34s\n",
      "15100:\tlearn: 236.5974238\ttest: 251.4621172\tbest: 251.4621172 (15100)\ttotal: 7m 46s\tremaining: 2m 31s\n",
      "15200:\tlearn: 236.4160884\ttest: 251.3347016\tbest: 251.3310725 (15178)\ttotal: 7m 49s\tremaining: 2m 28s\n",
      "15300:\tlearn: 236.2193903\ttest: 251.2610791\tbest: 251.2610791 (15300)\ttotal: 7m 52s\tremaining: 2m 25s\n",
      "15400:\tlearn: 236.0528346\ttest: 251.1854280\tbest: 251.1847697 (15398)\ttotal: 7m 55s\tremaining: 2m 21s\n",
      "15500:\tlearn: 235.8629030\ttest: 251.0422555\tbest: 251.0422555 (15500)\ttotal: 7m 58s\tremaining: 2m 18s\n",
      "15600:\tlearn: 235.6844163\ttest: 250.9144956\tbest: 250.9144956 (15600)\ttotal: 8m 1s\tremaining: 2m 15s\n",
      "15700:\tlearn: 235.5330676\ttest: 250.7917081\tbest: 250.7868269 (15699)\ttotal: 8m 4s\tremaining: 2m 12s\n",
      "15800:\tlearn: 235.3482621\ttest: 250.6243758\tbest: 250.6243758 (15800)\ttotal: 8m 7s\tremaining: 2m 9s\n",
      "15900:\tlearn: 235.1788638\ttest: 250.4921876\tbest: 250.4921876 (15900)\ttotal: 8m 10s\tremaining: 2m 6s\n",
      "16000:\tlearn: 234.9829782\ttest: 250.3545464\tbest: 250.3545464 (16000)\ttotal: 8m 13s\tremaining: 2m 3s\n",
      "16100:\tlearn: 234.8724584\ttest: 250.2932080\tbest: 250.2931281 (16099)\ttotal: 8m 16s\tremaining: 2m\n",
      "16200:\tlearn: 234.6907491\ttest: 250.1954093\tbest: 250.1950758 (16199)\ttotal: 8m 19s\tremaining: 1m 57s\n",
      "16300:\tlearn: 234.5450293\ttest: 250.1029854\tbest: 250.0942601 (16294)\ttotal: 8m 22s\tremaining: 1m 53s\n",
      "16400:\tlearn: 234.3852020\ttest: 250.0012261\tbest: 250.0006034 (16398)\ttotal: 8m 25s\tremaining: 1m 50s\n",
      "16500:\tlearn: 234.2391871\ttest: 249.8865471\tbest: 249.8865471 (16500)\ttotal: 8m 28s\tremaining: 1m 47s\n",
      "16600:\tlearn: 234.1188252\ttest: 249.7773317\tbest: 249.7773317 (16600)\ttotal: 8m 31s\tremaining: 1m 44s\n",
      "16700:\tlearn: 233.9389211\ttest: 249.7161676\tbest: 249.7129222 (16683)\ttotal: 8m 34s\tremaining: 1m 41s\n",
      "16800:\tlearn: 233.7676626\ttest: 249.5990485\tbest: 249.5990485 (16800)\ttotal: 8m 37s\tremaining: 1m 38s\n",
      "16900:\tlearn: 233.5613675\ttest: 249.4761491\tbest: 249.4751615 (16896)\ttotal: 8m 40s\tremaining: 1m 35s\n",
      "17000:\tlearn: 233.4005951\ttest: 249.4023852\tbest: 249.4023852 (17000)\ttotal: 8m 43s\tremaining: 1m 32s\n",
      "17100:\tlearn: 233.2244181\ttest: 249.2853304\tbest: 249.2853304 (17100)\ttotal: 8m 46s\tremaining: 1m 29s\n",
      "17200:\tlearn: 233.0628742\ttest: 249.1605052\tbest: 249.1605052 (17200)\ttotal: 8m 49s\tremaining: 1m 26s\n",
      "17300:\tlearn: 232.8403013\ttest: 249.0165697\tbest: 249.0059151 (17267)\ttotal: 8m 52s\tremaining: 1m 23s\n",
      "17400:\tlearn: 232.6456147\ttest: 248.8862648\tbest: 248.8862636 (17399)\ttotal: 8m 55s\tremaining: 1m 20s\n",
      "17500:\tlearn: 232.4842287\ttest: 248.7882051\tbest: 248.7882051 (17500)\ttotal: 8m 58s\tremaining: 1m 16s\n",
      "17600:\tlearn: 232.3323131\ttest: 248.6933482\tbest: 248.6907973 (17579)\ttotal: 9m 1s\tremaining: 1m 13s\n",
      "17700:\tlearn: 232.2396455\ttest: 248.6328248\tbest: 248.6327950 (17699)\ttotal: 9m 4s\tremaining: 1m 10s\n",
      "17800:\tlearn: 232.1479834\ttest: 248.5844291\tbest: 248.5843483 (17798)\ttotal: 9m 7s\tremaining: 1m 7s\n",
      "17900:\tlearn: 232.0445124\ttest: 248.5150173\tbest: 248.5150173 (17900)\ttotal: 9m 10s\tremaining: 1m 4s\n",
      "18000:\tlearn: 231.9464290\ttest: 248.4825842\tbest: 248.4792302 (17986)\ttotal: 9m 13s\tremaining: 1m 1s\n",
      "18100:\tlearn: 231.7771396\ttest: 248.4004202\tbest: 248.4004202 (18100)\ttotal: 9m 16s\tremaining: 58.4s\n",
      "18200:\tlearn: 231.6500052\ttest: 248.3395078\tbest: 248.3395078 (18200)\ttotal: 9m 19s\tremaining: 55.3s\n",
      "18300:\tlearn: 231.5720811\ttest: 248.2666607\tbest: 248.2666607 (18300)\ttotal: 9m 22s\tremaining: 52.2s\n",
      "18400:\tlearn: 231.3360569\ttest: 248.1534934\tbest: 248.1534934 (18400)\ttotal: 9m 25s\tremaining: 49.2s\n",
      "18500:\tlearn: 231.2128623\ttest: 248.0965547\tbest: 248.0965547 (18500)\ttotal: 9m 29s\tremaining: 46.1s\n",
      "18600:\tlearn: 231.0994453\ttest: 248.0474449\tbest: 248.0445406 (18587)\ttotal: 9m 32s\tremaining: 43s\n",
      "18700:\tlearn: 230.9579846\ttest: 247.9607228\tbest: 247.9607228 (18700)\ttotal: 9m 35s\tremaining: 40s\n",
      "18800:\tlearn: 230.8638762\ttest: 247.9039463\tbest: 247.9039463 (18800)\ttotal: 9m 38s\tremaining: 36.9s\n",
      "18900:\tlearn: 230.7963527\ttest: 247.8633947\tbest: 247.8618689 (18898)\ttotal: 9m 41s\tremaining: 33.8s\n",
      "19000:\tlearn: 230.7412123\ttest: 247.8150662\tbest: 247.8145441 (18997)\ttotal: 9m 45s\tremaining: 30.8s\n",
      "19100:\tlearn: 230.5867562\ttest: 247.7108729\tbest: 247.7108729 (19100)\ttotal: 9m 48s\tremaining: 27.7s\n",
      "19200:\tlearn: 230.4861001\ttest: 247.6189011\tbest: 247.6178505 (19194)\ttotal: 9m 51s\tremaining: 24.6s\n",
      "19300:\tlearn: 230.3986412\ttest: 247.5526588\tbest: 247.5526330 (19299)\ttotal: 9m 54s\tremaining: 21.5s\n",
      "19400:\tlearn: 230.2825974\ttest: 247.4678354\tbest: 247.4678354 (19400)\ttotal: 9m 57s\tremaining: 18.4s\n",
      "19500:\tlearn: 230.1785079\ttest: 247.4196596\tbest: 247.4196596 (19500)\ttotal: 10m\tremaining: 15.4s\n",
      "19600:\tlearn: 230.0935463\ttest: 247.3535394\tbest: 247.3533359 (19597)\ttotal: 10m 3s\tremaining: 12.3s\n",
      "19700:\tlearn: 229.9801764\ttest: 247.2619041\tbest: 247.2614895 (19697)\ttotal: 10m 6s\tremaining: 9.21s\n",
      "19800:\tlearn: 229.9066788\ttest: 247.2401078\tbest: 247.2392162 (19774)\ttotal: 10m 9s\tremaining: 6.13s\n",
      "19900:\tlearn: 229.7629746\ttest: 247.1413864\tbest: 247.1413864 (19900)\ttotal: 10m 13s\tremaining: 3.05s\n",
      "19999:\tlearn: 229.6568348\ttest: 247.1198008\tbest: 247.1198008 (19999)\ttotal: 10m 16s\tremaining: 0us\n",
      "\n",
      "bestTest = 247.1198008\n",
      "bestIteration = 19999\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "ctb_model = CatBoostRegressor(iterations=20000,learning_rate=0.01,loss_function=\"RMSE\")\n",
    "data_ctb_01, predict_label_01 = get_predict_w(ctb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019,model_type='ctb')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0:\tlearn: 979.7329647\ttest: 926.5130836\tbest: 926.5130836 (0)\ttotal: 29.5ms\tremaining: 14m 43s\n",
      "100:\tlearn: 441.7731645\ttest: 400.7756110\tbest: 400.7756110 (100)\ttotal: 3.32s\tremaining: 16m 23s\n",
      "200:\tlearn: 391.3831055\ttest: 353.5643746\tbest: 353.5643746 (200)\ttotal: 6.58s\tremaining: 16m 15s\n",
      "300:\tlearn: 368.7231480\ttest: 336.0041145\tbest: 336.0041145 (300)\ttotal: 9.7s\tremaining: 15m 57s\n",
      "400:\tlearn: 347.6329050\ttest: 320.2515051\tbest: 320.2515051 (400)\ttotal: 13.1s\tremaining: 16m 9s\n",
      "500:\tlearn: 330.8920428\ttest: 308.7225969\tbest: 308.7225969 (500)\ttotal: 16.5s\tremaining: 16m 12s\n",
      "600:\tlearn: 319.0123137\ttest: 300.1165721\tbest: 300.1165721 (600)\ttotal: 19.8s\tremaining: 16m 9s\n",
      "700:\tlearn: 311.1466984\ttest: 293.6337677\tbest: 293.6337677 (700)\ttotal: 23.4s\tremaining: 16m 18s\n",
      "800:\tlearn: 306.1443342\ttest: 289.6560534\tbest: 289.6553129 (798)\ttotal: 26.5s\tremaining: 16m 4s\n",
      "900:\tlearn: 299.3733776\ttest: 284.1340223\tbest: 284.1340223 (900)\ttotal: 29.9s\tremaining: 16m 5s\n",
      "1000:\tlearn: 294.6727060\ttest: 280.7769021\tbest: 280.7769021 (1000)\ttotal: 33s\tremaining: 15m 55s\n",
      "1100:\tlearn: 291.8496147\ttest: 278.7537765\tbest: 278.7537765 (1100)\ttotal: 36s\tremaining: 15m 44s\n",
      "1200:\tlearn: 287.5950553\ttest: 275.9995944\tbest: 275.9995944 (1200)\ttotal: 38.8s\tremaining: 15m 30s\n",
      "1300:\tlearn: 285.2011519\ttest: 274.3222180\tbest: 274.3221514 (1298)\ttotal: 41.6s\tremaining: 15m 16s\n",
      "1400:\tlearn: 283.4071424\ttest: 273.2958400\tbest: 273.2958400 (1400)\ttotal: 44s\tremaining: 14m 58s\n",
      "1500:\tlearn: 280.4681139\ttest: 271.1329474\tbest: 271.1329447 (1499)\ttotal: 46.8s\tremaining: 14m 48s\n",
      "1600:\tlearn: 279.1149479\ttest: 270.2944532\tbest: 270.2754249 (1598)\ttotal: 49.1s\tremaining: 14m 31s\n",
      "1700:\tlearn: 278.0303791\ttest: 269.6053947\tbest: 269.6053947 (1700)\ttotal: 51.7s\tremaining: 14m 20s\n",
      "1800:\tlearn: 275.1245006\ttest: 267.6954552\tbest: 267.6954552 (1800)\ttotal: 54.9s\tremaining: 14m 20s\n",
      "1900:\tlearn: 273.3087158\ttest: 266.5854997\tbest: 266.5784922 (1892)\ttotal: 58s\tremaining: 14m 17s\n",
      "2000:\tlearn: 271.6379909\ttest: 265.6878421\tbest: 265.6878421 (2000)\ttotal: 1m\tremaining: 14m 9s\n",
      "2100:\tlearn: 269.3892508\ttest: 263.9330797\tbest: 263.9330797 (2100)\ttotal: 1m 3s\tremaining: 14m 3s\n",
      "2200:\tlearn: 268.1200236\ttest: 263.0624656\tbest: 263.0443286 (2194)\ttotal: 1m 6s\tremaining: 13m 57s\n",
      "2300:\tlearn: 267.7000503\ttest: 262.8703131\tbest: 262.8703131 (2300)\ttotal: 1m 8s\tremaining: 13m 47s\n",
      "2400:\tlearn: 266.4303446\ttest: 262.1115868\tbest: 262.1115868 (2400)\ttotal: 1m 11s\tremaining: 13m 43s\n",
      "2500:\tlearn: 264.9215891\ttest: 261.0408537\tbest: 261.0408537 (2500)\ttotal: 1m 14s\tremaining: 13m 42s\n",
      "2600:\tlearn: 264.2112330\ttest: 260.7241235\tbest: 260.7241235 (2600)\ttotal: 1m 17s\tremaining: 13m 33s\n",
      "2700:\tlearn: 262.5851421\ttest: 259.6460020\tbest: 259.6460020 (2700)\ttotal: 1m 20s\tremaining: 13m 31s\n",
      "2800:\tlearn: 261.4098103\ttest: 258.9841461\tbest: 258.9826870 (2796)\ttotal: 1m 23s\tremaining: 13m 29s\n",
      "2900:\tlearn: 260.9060206\ttest: 258.6718059\tbest: 258.6696757 (2894)\ttotal: 1m 25s\tremaining: 13m 21s\n",
      "3000:\tlearn: 260.1829387\ttest: 258.1619029\tbest: 258.1619029 (3000)\ttotal: 1m 28s\tremaining: 13m 19s\n",
      "3100:\tlearn: 259.4644334\ttest: 257.6758901\tbest: 257.6758901 (3100)\ttotal: 1m 31s\tremaining: 13m 17s\n",
      "3200:\tlearn: 258.7882187\ttest: 257.2183856\tbest: 257.2183856 (3200)\ttotal: 1m 34s\tremaining: 13m 13s\n",
      "3300:\tlearn: 257.4616310\ttest: 256.2669491\tbest: 256.2669491 (3300)\ttotal: 1m 37s\tremaining: 13m 12s\n",
      "3400:\tlearn: 256.3610537\ttest: 255.6575833\tbest: 255.6575816 (3399)\ttotal: 1m 41s\tremaining: 13m 10s\n",
      "3500:\tlearn: 255.0853502\ttest: 254.5977631\tbest: 254.5914426 (3490)\ttotal: 1m 44s\tremaining: 13m 10s\n",
      "3600:\tlearn: 254.2408700\ttest: 253.9954164\tbest: 253.9909045 (3591)\ttotal: 1m 47s\tremaining: 13m 6s\n",
      "3700:\tlearn: 253.4685983\ttest: 253.4562600\tbest: 253.4562600 (3700)\ttotal: 1m 50s\tremaining: 13m 3s\n",
      "3800:\tlearn: 251.9539093\ttest: 252.4623342\tbest: 252.4333428 (3794)\ttotal: 1m 53s\tremaining: 13m 3s\n",
      "3900:\tlearn: 251.0316978\ttest: 251.8012453\tbest: 251.8012044 (3898)\ttotal: 1m 56s\tremaining: 13m 1s\n",
      "4000:\tlearn: 250.4331787\ttest: 251.4277975\tbest: 251.4273862 (3992)\ttotal: 1m 59s\tremaining: 12m 58s\n",
      "4100:\tlearn: 249.3364430\ttest: 250.6803196\tbest: 250.6803196 (4100)\ttotal: 2m 3s\tremaining: 12m 56s\n",
      "4200:\tlearn: 248.4633128\ttest: 250.1950556\tbest: 250.1950556 (4200)\ttotal: 2m 6s\tremaining: 12m 54s\n",
      "4300:\tlearn: 247.3859135\ttest: 249.4076732\tbest: 249.4072136 (4298)\ttotal: 2m 9s\tremaining: 12m 53s\n",
      "4400:\tlearn: 246.5925544\ttest: 248.7685444\tbest: 248.7685444 (4400)\ttotal: 2m 12s\tremaining: 12m 51s\n",
      "4500:\tlearn: 245.3618794\ttest: 247.6805337\tbest: 247.6805337 (4500)\ttotal: 2m 15s\tremaining: 12m 49s\n",
      "4600:\tlearn: 244.6329505\ttest: 247.3164386\tbest: 247.3164386 (4600)\ttotal: 2m 19s\tremaining: 12m 47s\n",
      "4700:\tlearn: 244.0913180\ttest: 246.9666516\tbest: 246.9666516 (4700)\ttotal: 2m 22s\tremaining: 12m 44s\n",
      "4800:\tlearn: 243.3767865\ttest: 246.4239428\tbest: 246.4239428 (4800)\ttotal: 2m 25s\tremaining: 12m 41s\n",
      "4900:\tlearn: 242.7660676\ttest: 246.0829131\tbest: 246.0720785 (4884)\ttotal: 2m 28s\tremaining: 12m 39s\n",
      "5000:\tlearn: 242.2597630\ttest: 245.7834976\tbest: 245.7834976 (5000)\ttotal: 2m 31s\tremaining: 12m 37s\n",
      "5100:\tlearn: 242.0044159\ttest: 245.6159899\tbest: 245.6151339 (5098)\ttotal: 2m 34s\tremaining: 12m 33s\n",
      "5200:\tlearn: 241.5461191\ttest: 245.2386168\tbest: 245.2386168 (5200)\ttotal: 2m 37s\tremaining: 12m 30s\n",
      "5300:\tlearn: 241.1256634\ttest: 245.0547206\tbest: 245.0547206 (5300)\ttotal: 2m 40s\tremaining: 12m 26s\n",
      "5400:\tlearn: 240.4019596\ttest: 244.5650540\tbest: 244.5639984 (5393)\ttotal: 2m 43s\tremaining: 12m 23s\n",
      "5500:\tlearn: 239.9194415\ttest: 244.2607875\tbest: 244.2607875 (5500)\ttotal: 2m 46s\tremaining: 12m 20s\n",
      "5600:\tlearn: 239.3413010\ttest: 243.9305948\tbest: 243.9305251 (5599)\ttotal: 2m 49s\tremaining: 12m 18s\n",
      "5700:\tlearn: 238.9714056\ttest: 243.6481622\tbest: 243.6481622 (5700)\ttotal: 2m 52s\tremaining: 12m 15s\n",
      "5800:\tlearn: 238.6445184\ttest: 243.4535187\tbest: 243.4533437 (5798)\ttotal: 2m 55s\tremaining: 12m 11s\n",
      "5900:\tlearn: 238.3030623\ttest: 243.2156478\tbest: 243.2130367 (5897)\ttotal: 2m 58s\tremaining: 12m 9s\n",
      "6000:\tlearn: 237.9817495\ttest: 243.0301936\tbest: 243.0279676 (5990)\ttotal: 3m 1s\tremaining: 12m 6s\n",
      "6100:\tlearn: 237.6519877\ttest: 242.8087062\tbest: 242.7932679 (6074)\ttotal: 3m 4s\tremaining: 12m 4s\n",
      "6200:\tlearn: 237.1942453\ttest: 242.5599953\tbest: 242.5599953 (6200)\ttotal: 3m 7s\tremaining: 12m 1s\n",
      "6300:\tlearn: 236.9150015\ttest: 242.3784163\tbest: 242.3784163 (6300)\ttotal: 3m 10s\tremaining: 11m 57s\n",
      "6400:\tlearn: 236.5791662\ttest: 242.1127821\tbest: 242.1127821 (6400)\ttotal: 3m 13s\tremaining: 11m 53s\n",
      "6500:\tlearn: 236.2744811\ttest: 241.9548716\tbest: 241.9548716 (6500)\ttotal: 3m 16s\tremaining: 11m 50s\n",
      "6600:\tlearn: 235.9262194\ttest: 241.7605060\tbest: 241.7499369 (6590)\ttotal: 3m 19s\tremaining: 11m 47s\n",
      "6700:\tlearn: 235.6243594\ttest: 241.5990689\tbest: 241.5990654 (6699)\ttotal: 3m 22s\tremaining: 11m 44s\n",
      "6800:\tlearn: 235.2340767\ttest: 241.3001730\tbest: 241.3001730 (6800)\ttotal: 3m 25s\tremaining: 11m 40s\n",
      "6900:\tlearn: 235.0025849\ttest: 241.2285896\tbest: 241.2285896 (6900)\ttotal: 3m 28s\tremaining: 11m 37s\n",
      "7000:\tlearn: 234.6710343\ttest: 241.0151831\tbest: 241.0151831 (7000)\ttotal: 3m 31s\tremaining: 11m 34s\n",
      "7100:\tlearn: 234.4416812\ttest: 240.9535664\tbest: 240.9535664 (7100)\ttotal: 3m 34s\tremaining: 11m 30s\n",
      "7200:\tlearn: 234.1543604\ttest: 240.8217927\tbest: 240.8195332 (7196)\ttotal: 3m 37s\tremaining: 11m 27s\n",
      "7300:\tlearn: 233.8439285\ttest: 240.6728963\tbest: 240.6728963 (7300)\ttotal: 3m 40s\tremaining: 11m 25s\n",
      "7400:\tlearn: 233.4463597\ttest: 240.3704540\tbest: 240.3700938 (7399)\ttotal: 3m 43s\tremaining: 11m 22s\n",
      "7500:\tlearn: 233.2986530\ttest: 240.2890416\tbest: 240.2862521 (7498)\ttotal: 3m 46s\tremaining: 11m 20s\n",
      "7600:\tlearn: 232.9862348\ttest: 240.0748891\tbest: 240.0734001 (7590)\ttotal: 3m 49s\tremaining: 11m 17s\n",
      "7700:\tlearn: 232.7783536\ttest: 239.9939403\tbest: 239.9911320 (7689)\ttotal: 3m 52s\tremaining: 11m 13s\n",
      "7800:\tlearn: 232.4930776\ttest: 239.7268636\tbest: 239.7196705 (7778)\ttotal: 3m 56s\tremaining: 11m 11s\n",
      "7900:\tlearn: 232.0253159\ttest: 239.5261734\tbest: 239.5166971 (7879)\ttotal: 3m 59s\tremaining: 11m 8s\n",
      "8000:\tlearn: 231.7666105\ttest: 239.4584176\tbest: 239.4499958 (7990)\ttotal: 4m 2s\tremaining: 11m 6s\n",
      "8100:\tlearn: 231.4718160\ttest: 239.2611798\tbest: 239.2611798 (8100)\ttotal: 4m 5s\tremaining: 11m 3s\n",
      "8200:\tlearn: 231.1367157\ttest: 239.0487969\tbest: 239.0426522 (8163)\ttotal: 4m 8s\tremaining: 11m\n",
      "8300:\tlearn: 230.9410571\ttest: 238.9113666\tbest: 238.9050197 (8298)\ttotal: 4m 11s\tremaining: 10m 57s\n",
      "8400:\tlearn: 230.7167991\ttest: 238.8219032\tbest: 238.8150668 (8390)\ttotal: 4m 14s\tremaining: 10m 53s\n",
      "8500:\tlearn: 230.5870846\ttest: 238.7321097\tbest: 238.7312076 (8493)\ttotal: 4m 17s\tremaining: 10m 49s\n",
      "8600:\tlearn: 230.3828942\ttest: 238.6811258\tbest: 238.6807195 (8593)\ttotal: 4m 20s\tremaining: 10m 47s\n",
      "8700:\tlearn: 230.0900179\ttest: 238.5529567\tbest: 238.5529551 (8699)\ttotal: 4m 23s\tremaining: 10m 44s\n",
      "8800:\tlearn: 229.8510611\ttest: 238.4291078\tbest: 238.4258758 (8796)\ttotal: 4m 26s\tremaining: 10m 41s\n",
      "8900:\tlearn: 229.7424484\ttest: 238.3837232\tbest: 238.3826377 (8897)\ttotal: 4m 29s\tremaining: 10m 37s\n",
      "9000:\tlearn: 229.5918484\ttest: 238.3097426\tbest: 238.3078267 (8998)\ttotal: 4m 32s\tremaining: 10m 34s\n",
      "9100:\tlearn: 229.4036444\ttest: 238.1448271\tbest: 238.1414435 (9076)\ttotal: 4m 34s\tremaining: 10m 31s\n",
      "9200:\tlearn: 229.2107428\ttest: 238.0519972\tbest: 238.0463873 (9184)\ttotal: 4m 37s\tremaining: 10m 27s\n",
      "9300:\tlearn: 229.1607189\ttest: 238.0167346\tbest: 238.0166499 (9293)\ttotal: 4m 40s\tremaining: 10m 24s\n",
      "9400:\tlearn: 228.7781771\ttest: 237.6185210\tbest: 237.6185210 (9400)\ttotal: 4m 43s\tremaining: 10m 21s\n",
      "9500:\tlearn: 228.5022476\ttest: 237.4003868\tbest: 237.3985324 (9493)\ttotal: 4m 46s\tremaining: 10m 18s\n",
      "9600:\tlearn: 228.2304815\ttest: 237.2922957\tbest: 237.2856899 (9598)\ttotal: 4m 49s\tremaining: 10m 15s\n",
      "9700:\tlearn: 227.9033224\ttest: 237.1299331\tbest: 237.1299119 (9699)\ttotal: 4m 52s\tremaining: 10m 12s\n",
      "9800:\tlearn: 227.7142327\ttest: 237.0111780\tbest: 237.0086894 (9791)\ttotal: 4m 55s\tremaining: 10m 8s\n",
      "9900:\tlearn: 227.5365763\ttest: 236.9169548\tbest: 236.9141033 (9898)\ttotal: 4m 58s\tremaining: 10m 6s\n",
      "10000:\tlearn: 227.3246971\ttest: 236.8653672\tbest: 236.8567986 (9963)\ttotal: 5m 1s\tremaining: 10m 2s\n",
      "10100:\tlearn: 227.1918993\ttest: 236.8412369\tbest: 236.8348590 (10089)\ttotal: 5m 4s\tremaining: 9m 59s\n",
      "10200:\tlearn: 227.0302860\ttest: 236.7268537\tbest: 236.7264793 (10191)\ttotal: 5m 7s\tremaining: 9m 56s\n",
      "10300:\tlearn: 226.5517898\ttest: 236.4728427\tbest: 236.4725238 (10299)\ttotal: 5m 10s\tremaining: 9m 53s\n",
      "10400:\tlearn: 226.3459162\ttest: 236.2845936\tbest: 236.2823369 (10377)\ttotal: 5m 13s\tremaining: 9m 50s\n",
      "10500:\tlearn: 226.1056871\ttest: 236.0852026\tbest: 236.0849609 (10493)\ttotal: 5m 16s\tremaining: 9m 48s\n",
      "10600:\tlearn: 225.8808752\ttest: 236.0283475\tbest: 236.0283475 (10600)\ttotal: 5m 19s\tremaining: 9m 45s\n",
      "10700:\tlearn: 225.7796197\ttest: 235.9893450\tbest: 235.9893450 (10700)\ttotal: 5m 22s\tremaining: 9m 42s\n",
      "10800:\tlearn: 225.6737415\ttest: 235.9114637\tbest: 235.9109902 (10796)\ttotal: 5m 26s\tremaining: 9m 39s\n",
      "10900:\tlearn: 225.4629295\ttest: 235.8162585\tbest: 235.8090534 (10855)\ttotal: 5m 29s\tremaining: 9m 36s\n",
      "11000:\tlearn: 225.1637498\ttest: 235.5123343\tbest: 235.5122153 (10991)\ttotal: 5m 32s\tremaining: 9m 34s\n",
      "11100:\tlearn: 224.8817118\ttest: 235.3233829\tbest: 235.3232691 (11099)\ttotal: 5m 35s\tremaining: 9m 31s\n",
      "11200:\tlearn: 224.5642973\ttest: 235.0833788\tbest: 235.0830783 (11198)\ttotal: 5m 38s\tremaining: 9m 28s\n",
      "11300:\tlearn: 224.3770563\ttest: 234.9544793\tbest: 234.9540463 (11296)\ttotal: 5m 41s\tremaining: 9m 25s\n",
      "11400:\tlearn: 224.2745355\ttest: 234.8668486\tbest: 234.8666622 (11397)\ttotal: 5m 44s\tremaining: 9m 22s\n",
      "11500:\tlearn: 224.0750445\ttest: 234.7259967\tbest: 234.7257346 (11497)\ttotal: 5m 47s\tremaining: 9m 18s\n",
      "11600:\tlearn: 223.6195386\ttest: 234.3311745\tbest: 234.3311745 (11600)\ttotal: 5m 50s\tremaining: 9m 15s\n",
      "11700:\tlearn: 223.3803348\ttest: 234.2103202\tbest: 234.2099691 (11688)\ttotal: 5m 53s\tremaining: 9m 12s\n",
      "11800:\tlearn: 223.2579913\ttest: 234.1384196\tbest: 234.1383966 (11798)\ttotal: 5m 56s\tremaining: 9m 9s\n",
      "11900:\tlearn: 223.0600645\ttest: 234.0334394\tbest: 234.0334394 (11900)\ttotal: 5m 59s\tremaining: 9m 6s\n",
      "12000:\tlearn: 222.6865720\ttest: 233.6892671\tbest: 233.6863877 (11995)\ttotal: 6m 2s\tremaining: 9m 4s\n",
      "12100:\tlearn: 222.2894364\ttest: 233.4339190\tbest: 233.4294745 (12095)\ttotal: 6m 6s\tremaining: 9m 1s\n",
      "12200:\tlearn: 221.7163929\ttest: 233.0523957\tbest: 233.0504426 (12184)\ttotal: 6m 9s\tremaining: 8m 58s\n",
      "12300:\tlearn: 221.5841784\ttest: 233.0012409\tbest: 232.9997377 (12299)\ttotal: 6m 11s\tremaining: 8m 55s\n",
      "12400:\tlearn: 221.3914926\ttest: 232.9061132\tbest: 232.9061132 (12400)\ttotal: 6m 14s\tremaining: 8m 51s\n",
      "12500:\tlearn: 221.2681796\ttest: 232.8461548\tbest: 232.8441800 (12497)\ttotal: 6m 17s\tremaining: 8m 48s\n",
      "12600:\tlearn: 221.0789914\ttest: 232.7077870\tbest: 232.7076480 (12599)\ttotal: 6m 21s\tremaining: 8m 46s\n",
      "12700:\tlearn: 220.8751510\ttest: 232.6438326\tbest: 232.6438326 (12700)\ttotal: 6m 24s\tremaining: 8m 43s\n",
      "12800:\tlearn: 220.7421834\ttest: 232.5912491\tbest: 232.5912491 (12800)\ttotal: 6m 27s\tremaining: 8m 40s\n",
      "12900:\tlearn: 220.5320090\ttest: 232.4102899\tbest: 232.4070629 (12894)\ttotal: 6m 31s\tremaining: 8m 38s\n",
      "13000:\tlearn: 220.0451032\ttest: 232.0655447\tbest: 232.0653780 (12999)\ttotal: 6m 34s\tremaining: 8m 35s\n",
      "13100:\tlearn: 219.7363064\ttest: 231.8301947\tbest: 231.8297785 (13099)\ttotal: 6m 37s\tremaining: 8m 32s\n",
      "13200:\tlearn: 219.5465663\ttest: 231.7185125\tbest: 231.7185125 (13200)\ttotal: 6m 40s\tremaining: 8m 29s\n",
      "13300:\tlearn: 219.4022237\ttest: 231.6093878\tbest: 231.6084552 (13291)\ttotal: 6m 44s\tremaining: 8m 27s\n",
      "13400:\tlearn: 219.2394462\ttest: 231.5471047\tbest: 231.5357089 (13396)\ttotal: 6m 47s\tremaining: 8m 24s\n",
      "13500:\tlearn: 219.1455484\ttest: 231.5062161\tbest: 231.5049671 (13469)\ttotal: 6m 50s\tremaining: 8m 21s\n",
      "13600:\tlearn: 219.0869786\ttest: 231.4835563\tbest: 231.4803075 (13588)\ttotal: 6m 52s\tremaining: 8m 17s\n",
      "13700:\tlearn: 218.9924085\ttest: 231.4623114\tbest: 231.4623114 (13700)\ttotal: 6m 55s\tremaining: 8m 14s\n",
      "13800:\tlearn: 218.9335729\ttest: 231.4233413\tbest: 231.4233413 (13800)\ttotal: 6m 58s\tremaining: 8m 11s\n",
      "13900:\tlearn: 218.8197788\ttest: 231.3664141\tbest: 231.3649708 (13885)\ttotal: 7m 1s\tremaining: 8m 7s\n",
      "14000:\tlearn: 218.5815056\ttest: 231.1874546\tbest: 231.1874461 (13999)\ttotal: 7m 4s\tremaining: 8m 4s\n",
      "14100:\tlearn: 218.4206711\ttest: 231.0953888\tbest: 231.0866881 (14072)\ttotal: 7m 7s\tremaining: 8m 1s\n",
      "14200:\tlearn: 218.2431772\ttest: 230.9470393\tbest: 230.9468959 (14198)\ttotal: 7m 10s\tremaining: 7m 58s\n",
      "14300:\tlearn: 218.1680681\ttest: 230.8814654\tbest: 230.8798046 (14293)\ttotal: 7m 12s\tremaining: 7m 55s\n",
      "14400:\tlearn: 218.1073365\ttest: 230.8231795\tbest: 230.8231795 (14400)\ttotal: 7m 15s\tremaining: 7m 51s\n",
      "14500:\tlearn: 218.0658177\ttest: 230.8123932\tbest: 230.8080199 (14459)\ttotal: 7m 18s\tremaining: 7m 48s\n",
      "14600:\tlearn: 217.9396314\ttest: 230.6791481\tbest: 230.6765555 (14584)\ttotal: 7m 21s\tremaining: 7m 45s\n",
      "14700:\tlearn: 217.7961132\ttest: 230.6166901\tbest: 230.6129501 (14699)\ttotal: 7m 24s\tremaining: 7m 42s\n",
      "14800:\tlearn: 217.6294114\ttest: 230.5538868\tbest: 230.5500579 (14788)\ttotal: 7m 27s\tremaining: 7m 39s\n",
      "14900:\tlearn: 217.5308522\ttest: 230.4962289\tbest: 230.4917539 (14894)\ttotal: 7m 30s\tremaining: 7m 36s\n",
      "15000:\tlearn: 217.3467758\ttest: 230.4186611\tbest: 230.4186611 (15000)\ttotal: 7m 33s\tremaining: 7m 32s\n",
      "15100:\tlearn: 217.2296763\ttest: 230.3789687\tbest: 230.3779362 (15096)\ttotal: 7m 36s\tremaining: 7m 30s\n",
      "15200:\tlearn: 216.9663394\ttest: 230.1810518\tbest: 230.1802110 (15198)\ttotal: 7m 39s\tremaining: 7m 26s\n",
      "15300:\tlearn: 216.8077149\ttest: 230.0762301\tbest: 230.0761920 (15299)\ttotal: 7m 42s\tremaining: 7m 24s\n",
      "15400:\tlearn: 216.5879408\ttest: 229.9240032\tbest: 229.9240032 (15400)\ttotal: 7m 45s\tremaining: 7m 20s\n",
      "15500:\tlearn: 216.3972281\ttest: 229.7572421\tbest: 229.7572417 (15499)\ttotal: 7m 47s\tremaining: 7m 17s\n",
      "15600:\tlearn: 216.2301955\ttest: 229.6799765\tbest: 229.6776597 (15590)\ttotal: 7m 50s\tremaining: 7m 14s\n",
      "15700:\tlearn: 216.0596885\ttest: 229.5331929\tbest: 229.5331929 (15700)\ttotal: 7m 53s\tremaining: 7m 11s\n",
      "15800:\tlearn: 215.8999956\ttest: 229.3891672\tbest: 229.3890561 (15797)\ttotal: 7m 56s\tremaining: 7m 7s\n",
      "15900:\tlearn: 215.7981500\ttest: 229.3109734\tbest: 229.3100901 (15894)\ttotal: 7m 58s\tremaining: 7m 4s\n",
      "16000:\tlearn: 215.5976963\ttest: 229.1769397\tbest: 229.1751842 (15982)\ttotal: 8m 1s\tremaining: 7m 1s\n",
      "16100:\tlearn: 215.4509915\ttest: 229.1021333\tbest: 229.1009083 (16064)\ttotal: 8m 4s\tremaining: 6m 58s\n",
      "16200:\tlearn: 215.2812829\ttest: 229.0400280\tbest: 229.0337770 (16174)\ttotal: 8m 7s\tremaining: 6m 54s\n",
      "16300:\tlearn: 215.0605231\ttest: 228.9114385\tbest: 228.9059141 (16292)\ttotal: 8m 10s\tremaining: 6m 52s\n",
      "16400:\tlearn: 214.8657752\ttest: 228.7542692\tbest: 228.7542692 (16400)\ttotal: 8m 13s\tremaining: 6m 49s\n",
      "16500:\tlearn: 214.7257644\ttest: 228.7155881\tbest: 228.7131078 (16460)\ttotal: 8m 16s\tremaining: 6m 46s\n",
      "16600:\tlearn: 214.5994630\ttest: 228.6025962\tbest: 228.6024513 (16597)\ttotal: 8m 19s\tremaining: 6m 43s\n",
      "16700:\tlearn: 214.4418596\ttest: 228.4508989\tbest: 228.4508989 (16700)\ttotal: 8m 22s\tremaining: 6m 40s\n",
      "16800:\tlearn: 214.3237469\ttest: 228.4113863\tbest: 228.4113863 (16800)\ttotal: 8m 24s\tremaining: 6m 36s\n",
      "16900:\tlearn: 213.8892863\ttest: 228.0464685\tbest: 228.0462770 (16893)\ttotal: 8m 28s\tremaining: 6m 33s\n",
      "17000:\tlearn: 213.7640012\ttest: 228.0077929\tbest: 227.9971704 (16971)\ttotal: 8m 30s\tremaining: 6m 30s\n",
      "17100:\tlearn: 213.6091764\ttest: 227.9092594\tbest: 227.9092237 (17098)\ttotal: 8m 33s\tremaining: 6m 27s\n",
      "17200:\tlearn: 213.3847247\ttest: 227.7756170\tbest: 227.7756170 (17200)\ttotal: 8m 35s\tremaining: 6m 23s\n",
      "17300:\tlearn: 213.3094406\ttest: 227.7567110\tbest: 227.7536248 (17289)\ttotal: 8m 38s\tremaining: 6m 20s\n",
      "17400:\tlearn: 213.1068849\ttest: 227.7001452\tbest: 227.6998735 (17399)\ttotal: 8m 41s\tremaining: 6m 17s\n",
      "17500:\tlearn: 212.9122111\ttest: 227.6106653\tbest: 227.6106163 (17498)\ttotal: 8m 44s\tremaining: 6m 14s\n",
      "17600:\tlearn: 212.7826040\ttest: 227.5124628\tbest: 227.5122427 (17599)\ttotal: 8m 47s\tremaining: 6m 11s\n",
      "17700:\tlearn: 212.6134142\ttest: 227.4157988\tbest: 227.4157988 (17700)\ttotal: 8m 50s\tremaining: 6m 8s\n",
      "17800:\tlearn: 212.4425455\ttest: 227.3062643\tbest: 227.3059520 (17799)\ttotal: 8m 53s\tremaining: 6m 5s\n",
      "17900:\tlearn: 212.2932533\ttest: 227.2051425\tbest: 227.2051425 (17900)\ttotal: 8m 56s\tremaining: 6m 2s\n",
      "18000:\tlearn: 212.1235902\ttest: 227.1061827\tbest: 227.1061825 (17999)\ttotal: 8m 59s\tremaining: 5m 59s\n",
      "18100:\tlearn: 212.0679908\ttest: 227.0788025\tbest: 227.0748350 (18064)\ttotal: 9m 2s\tremaining: 5m 56s\n",
      "18200:\tlearn: 211.8692494\ttest: 226.9296350\tbest: 226.9293123 (18195)\ttotal: 9m 5s\tremaining: 5m 53s\n",
      "18300:\tlearn: 211.6276400\ttest: 226.8201344\tbest: 226.8137973 (18296)\ttotal: 9m 8s\tremaining: 5m 50s\n",
      "18400:\tlearn: 211.4830603\ttest: 226.7292552\tbest: 226.7282951 (18389)\ttotal: 9m 11s\tremaining: 5m 47s\n",
      "18500:\tlearn: 211.3337725\ttest: 226.6402241\tbest: 226.6398699 (18488)\ttotal: 9m 14s\tremaining: 5m 44s\n",
      "18600:\tlearn: 211.1164572\ttest: 226.4644637\tbest: 226.4644637 (18600)\ttotal: 9m 17s\tremaining: 5m 41s\n",
      "18700:\tlearn: 211.0384696\ttest: 226.3983152\tbest: 226.3983152 (18700)\ttotal: 9m 21s\tremaining: 5m 38s\n",
      "18800:\tlearn: 210.9508071\ttest: 226.3193157\tbest: 226.3193157 (18800)\ttotal: 9m 24s\tremaining: 5m 36s\n",
      "18900:\tlearn: 210.8177313\ttest: 226.2024522\tbest: 226.2011555 (18898)\ttotal: 9m 26s\tremaining: 5m 32s\n",
      "19000:\tlearn: 210.6785380\ttest: 226.1395551\tbest: 226.1262425 (18980)\ttotal: 9m 29s\tremaining: 5m 29s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 226.1262425\n",
      "bestIteration = 18980\n",
      "\n",
      "Shrink model to first 18981 iterations.",
      "\n",
      "0:\tlearn: 972.1575271\ttest: 969.0568590\tbest: 969.0568590 (0)\ttotal: 26.8ms\tremaining: 13m 24s\n",
      "100:\tlearn: 435.3096763\ttest: 439.7465335\tbest: 439.7465335 (100)\ttotal: 3.25s\tremaining: 16m\n",
      "200:\tlearn: 387.5200973\ttest: 396.6491450\tbest: 396.6491450 (200)\ttotal: 6.45s\tremaining: 15m 56s\n",
      "300:\tlearn: 366.3288008\ttest: 378.3530359\tbest: 378.3530359 (300)\ttotal: 9.53s\tremaining: 15m 40s\n",
      "400:\tlearn: 346.8384330\ttest: 360.0085101\tbest: 360.0085101 (400)\ttotal: 12.8s\tremaining: 15m 44s\n",
      "500:\tlearn: 332.2643907\ttest: 344.7012363\tbest: 344.7012363 (500)\ttotal: 16s\tremaining: 15m 39s\n",
      "600:\tlearn: 322.8840718\ttest: 335.1381689\tbest: 335.1381689 (600)\ttotal: 19.1s\tremaining: 15m 35s\n",
      "700:\tlearn: 312.5171771\ttest: 324.6716812\tbest: 324.6716812 (700)\ttotal: 22.2s\tremaining: 15m 28s\n",
      "800:\tlearn: 305.1351640\ttest: 318.5220151\tbest: 318.5220151 (800)\ttotal: 25.3s\tremaining: 15m 23s\n",
      "900:\tlearn: 300.2270868\ttest: 314.5195989\tbest: 314.5195989 (900)\ttotal: 28.2s\tremaining: 15m 9s\n",
      "1000:\tlearn: 295.1873606\ttest: 310.0460297\tbest: 310.0460297 (1000)\ttotal: 30.9s\tremaining: 14m 56s\n",
      "1100:\tlearn: 290.5364467\ttest: 304.8190218\tbest: 304.8186102 (1097)\ttotal: 33.8s\tremaining: 14m 47s\n",
      "1200:\tlearn: 287.7893558\ttest: 302.0294392\tbest: 302.0294392 (1200)\ttotal: 36.6s\tremaining: 14m 36s\n",
      "1300:\tlearn: 284.5919850\ttest: 299.3047218\tbest: 299.3043730 (1297)\ttotal: 39.4s\tremaining: 14m 29s\n",
      "1400:\tlearn: 282.6719467\ttest: 297.5119147\tbest: 297.5112326 (1399)\ttotal: 41.9s\tremaining: 14m 15s\n",
      "1500:\tlearn: 280.2226209\ttest: 295.1854158\tbest: 295.1854158 (1500)\ttotal: 45s\tremaining: 14m 14s\n",
      "1600:\tlearn: 277.4532026\ttest: 292.8495733\tbest: 292.8495733 (1600)\ttotal: 48s\tremaining: 14m 11s\n",
      "1700:\tlearn: 275.4494613\ttest: 291.0384764\tbest: 291.0384764 (1700)\ttotal: 51s\tremaining: 14m 7s\n",
      "1800:\tlearn: 273.5314505\ttest: 289.4755493\tbest: 289.4754750 (1799)\ttotal: 54s\tremaining: 14m 4s\n",
      "1900:\tlearn: 271.0801872\ttest: 287.1836203\tbest: 287.1836203 (1900)\ttotal: 57s\tremaining: 14m 2s\n",
      "2000:\tlearn: 268.8841907\ttest: 285.4136117\tbest: 285.4136117 (2000)\ttotal: 1m\tremaining: 14m\n",
      "2100:\tlearn: 267.1273034\ttest: 284.2392762\tbest: 284.2392531 (2099)\ttotal: 1m 2s\tremaining: 13m 54s\n",
      "2200:\tlearn: 265.8250691\ttest: 283.0037198\tbest: 283.0025157 (2198)\ttotal: 1m 5s\tremaining: 13m 52s\n",
      "2300:\tlearn: 263.5300590\ttest: 281.2221829\tbest: 281.2220260 (2299)\ttotal: 1m 8s\tremaining: 13m 50s\n",
      "2400:\tlearn: 262.2230782\ttest: 280.1596036\tbest: 280.1596036 (2400)\ttotal: 1m 11s\tremaining: 13m 46s\n",
      "2500:\tlearn: 260.7423114\ttest: 278.7842341\tbest: 278.7835819 (2498)\ttotal: 1m 14s\tremaining: 13m 44s\n",
      "2600:\tlearn: 258.8851619\ttest: 277.6775262\tbest: 277.6775262 (2600)\ttotal: 1m 17s\tremaining: 13m 40s\n",
      "2700:\tlearn: 257.0742185\ttest: 276.1898097\tbest: 276.1898097 (2700)\ttotal: 1m 21s\tremaining: 13m 38s\n",
      "2800:\tlearn: 255.6387365\ttest: 275.1366195\tbest: 275.1364818 (2799)\ttotal: 1m 24s\tremaining: 13m 38s\n",
      "2900:\tlearn: 254.5970834\ttest: 274.3019663\tbest: 274.3019663 (2900)\ttotal: 1m 27s\tremaining: 13m 35s\n",
      "3000:\tlearn: 252.9661806\ttest: 273.0805799\tbest: 273.0805799 (3000)\ttotal: 1m 30s\tremaining: 13m 32s\n",
      "3100:\tlearn: 251.4147428\ttest: 271.8304075\tbest: 271.8264471 (3098)\ttotal: 1m 33s\tremaining: 13m 30s\n",
      "3200:\tlearn: 250.5495813\ttest: 271.2087601\tbest: 271.2087601 (3200)\ttotal: 1m 36s\tremaining: 13m 27s\n",
      "3300:\tlearn: 249.4375984\ttest: 270.5661201\tbest: 270.5500787 (3299)\ttotal: 1m 39s\tremaining: 13m 25s\n",
      "3400:\tlearn: 248.2763766\ttest: 269.6463781\tbest: 269.6463781 (3400)\ttotal: 1m 42s\tremaining: 13m 23s\n",
      "3500:\tlearn: 247.4829244\ttest: 269.0345999\tbest: 269.0158920 (3485)\ttotal: 1m 45s\tremaining: 13m 19s\n",
      "3600:\tlearn: 246.9586243\ttest: 268.6355245\tbest: 268.6297644 (3598)\ttotal: 1m 48s\tremaining: 13m 16s\n",
      "3700:\tlearn: 246.2839282\ttest: 268.1787815\tbest: 268.1717670 (3696)\ttotal: 1m 51s\tremaining: 13m 12s\n",
      "3800:\tlearn: 245.5509929\ttest: 267.6886875\tbest: 267.6885728 (3799)\ttotal: 1m 54s\tremaining: 13m 10s\n",
      "3900:\tlearn: 244.7512031\ttest: 267.1141817\tbest: 267.1125791 (3896)\ttotal: 1m 57s\tremaining: 13m 8s\n",
      "4000:\tlearn: 243.8914233\ttest: 266.5090569\tbest: 266.5086556 (3998)\ttotal: 2m\tremaining: 13m 5s\n",
      "4100:\tlearn: 243.1851210\ttest: 265.9843861\tbest: 265.9843861 (4100)\ttotal: 2m 3s\tremaining: 13m 1s\n",
      "4200:\tlearn: 242.4315166\ttest: 265.4716969\tbest: 265.4704383 (4193)\ttotal: 2m 6s\tremaining: 12m 57s\n",
      "4300:\tlearn: 241.5829915\ttest: 264.7305672\tbest: 264.7278797 (4286)\ttotal: 2m 9s\tremaining: 12m 54s\n",
      "4400:\tlearn: 240.7187545\ttest: 264.0659385\tbest: 264.0611221 (4393)\ttotal: 2m 12s\tremaining: 12m 51s\n",
      "4500:\tlearn: 239.9276720\ttest: 263.5983062\tbest: 263.5983062 (4500)\ttotal: 2m 15s\tremaining: 12m 48s\n",
      "4600:\tlearn: 239.1123614\ttest: 262.9205131\tbest: 262.9205131 (4600)\ttotal: 2m 18s\tremaining: 12m 46s\n",
      "4700:\tlearn: 238.2445516\ttest: 262.1596354\tbest: 262.1528262 (4687)\ttotal: 2m 22s\tremaining: 12m 44s\n",
      "4800:\tlearn: 237.5350660\ttest: 261.6113675\tbest: 261.6099917 (4799)\ttotal: 2m 24s\tremaining: 12m 40s\n",
      "4900:\tlearn: 236.9641399\ttest: 261.2485857\tbest: 261.2485857 (4900)\ttotal: 2m 27s\tremaining: 12m 37s\n",
      "5000:\tlearn: 236.3240229\ttest: 260.9224440\tbest: 260.9197329 (4997)\ttotal: 2m 30s\tremaining: 12m 34s\n",
      "5100:\tlearn: 235.6700633\ttest: 260.4266321\tbest: 260.4222892 (5085)\ttotal: 2m 34s\tremaining: 12m 32s\n",
      "5200:\tlearn: 234.9997555\ttest: 259.9574631\tbest: 259.9574631 (5200)\ttotal: 2m 36s\tremaining: 12m 28s\n",
      "5300:\tlearn: 234.5675136\ttest: 259.7641620\tbest: 259.7336322 (5260)\ttotal: 2m 39s\tremaining: 12m 23s\n",
      "5400:\tlearn: 234.0118012\ttest: 259.4007414\tbest: 259.3852397 (5393)\ttotal: 2m 42s\tremaining: 12m 20s\n",
      "5500:\tlearn: 233.4374921\ttest: 258.9505603\tbest: 258.9505603 (5500)\ttotal: 2m 45s\tremaining: 12m 17s\n",
      "5600:\tlearn: 233.1124222\ttest: 258.7968153\tbest: 258.7968153 (5600)\ttotal: 2m 48s\tremaining: 12m 13s\n",
      "5700:\tlearn: 232.3756343\ttest: 258.3259500\tbest: 258.3227215 (5698)\ttotal: 2m 51s\tremaining: 12m 9s\n",
      "5800:\tlearn: 232.0766469\ttest: 258.1718392\tbest: 258.1538405 (5793)\ttotal: 2m 53s\tremaining: 12m 5s\n",
      "5900:\tlearn: 231.6869978\ttest: 257.9550688\tbest: 257.9550688 (5900)\ttotal: 2m 56s\tremaining: 12m 1s\n",
      "6000:\tlearn: 231.3467849\ttest: 257.7267178\tbest: 257.7267178 (6000)\ttotal: 2m 59s\tremaining: 11m 57s\n",
      "6100:\tlearn: 231.1417721\ttest: 257.5338642\tbest: 257.5335324 (6099)\ttotal: 3m 1s\tremaining: 11m 52s\n",
      "6200:\tlearn: 230.8145209\ttest: 257.3195821\tbest: 257.3195821 (6200)\ttotal: 3m 4s\tremaining: 11m 48s\n",
      "6300:\tlearn: 230.4758284\ttest: 257.1291870\tbest: 257.1220865 (6289)\ttotal: 3m 7s\tremaining: 11m 44s\n",
      "6400:\tlearn: 230.1525158\ttest: 256.9886625\tbest: 256.9875911 (6376)\ttotal: 3m 9s\tremaining: 11m 40s\n",
      "6500:\tlearn: 229.8913198\ttest: 256.8641213\tbest: 256.8641213 (6500)\ttotal: 3m 12s\tremaining: 11m 36s\n",
      "6600:\tlearn: 229.6123688\ttest: 256.6492282\tbest: 256.6418285 (6597)\ttotal: 3m 15s\tremaining: 11m 33s\n",
      "6700:\tlearn: 229.2814463\ttest: 256.4617648\tbest: 256.4480218 (6678)\ttotal: 3m 18s\tremaining: 11m 30s\n",
      "6800:\tlearn: 228.9863387\ttest: 256.2849289\tbest: 256.2836840 (6798)\ttotal: 3m 21s\tremaining: 11m 27s\n",
      "6900:\tlearn: 228.6948496\ttest: 256.1839058\tbest: 256.1776193 (6898)\ttotal: 3m 24s\tremaining: 11m 24s\n",
      "7000:\tlearn: 228.3378749\ttest: 255.9458135\tbest: 255.9458135 (7000)\ttotal: 3m 27s\tremaining: 11m 21s\n",
      "7100:\tlearn: 227.8922160\ttest: 255.6534746\tbest: 255.6374104 (7083)\ttotal: 3m 30s\tremaining: 11m 17s\n",
      "7200:\tlearn: 227.4674461\ttest: 255.3204930\tbest: 255.3204930 (7200)\ttotal: 3m 32s\tremaining: 11m 13s\n",
      "7300:\tlearn: 227.0925888\ttest: 254.9336699\tbest: 254.9230570 (7296)\ttotal: 3m 35s\tremaining: 11m 9s\n",
      "7400:\tlearn: 226.7437285\ttest: 254.6688887\tbest: 254.6656086 (7398)\ttotal: 3m 38s\tremaining: 11m 6s\n",
      "7500:\tlearn: 226.4644526\ttest: 254.5648803\tbest: 254.5415770 (7483)\ttotal: 3m 41s\tremaining: 11m 3s\n",
      "7600:\tlearn: 226.1816915\ttest: 254.4007037\tbest: 254.3973512 (7590)\ttotal: 3m 44s\tremaining: 11m\n",
      "7700:\tlearn: 225.8164424\ttest: 254.2460972\tbest: 254.2241016 (7676)\ttotal: 3m 47s\tremaining: 10m 57s\n",
      "7800:\tlearn: 225.6476899\ttest: 254.0728912\tbest: 254.0728912 (7800)\ttotal: 3m 49s\tremaining: 10m 53s\n",
      "7900:\tlearn: 225.4848094\ttest: 253.9743516\tbest: 253.9743516 (7900)\ttotal: 3m 52s\tremaining: 10m 50s\n",
      "8000:\tlearn: 225.2426852\ttest: 253.8664310\tbest: 253.8664310 (8000)\ttotal: 3m 55s\tremaining: 10m 47s\n",
      "8100:\tlearn: 224.9215032\ttest: 253.7588000\tbest: 253.7516650 (8095)\ttotal: 3m 58s\tremaining: 10m 44s\n",
      "8200:\tlearn: 224.7986951\ttest: 253.7024653\tbest: 253.6989749 (8196)\ttotal: 4m 1s\tremaining: 10m 40s\n",
      "8300:\tlearn: 224.5261434\ttest: 253.5000755\tbest: 253.5000415 (8299)\ttotal: 4m 3s\tremaining: 10m 37s\n",
      "8400:\tlearn: 224.3504591\ttest: 253.3380635\tbest: 253.3380635 (8400)\ttotal: 4m 6s\tremaining: 10m 33s\n",
      "8500:\tlearn: 224.0050862\ttest: 253.1113631\tbest: 253.0911624 (8494)\ttotal: 4m 9s\tremaining: 10m 30s\n",
      "8600:\tlearn: 223.7741679\ttest: 253.0157114\tbest: 253.0102484 (8598)\ttotal: 4m 12s\tremaining: 10m 27s\n",
      "8700:\tlearn: 223.3135620\ttest: 252.7098376\tbest: 252.7098376 (8700)\ttotal: 4m 14s\tremaining: 10m 23s\n",
      "8800:\tlearn: 222.8349406\ttest: 252.4371252\tbest: 252.4371252 (8800)\ttotal: 4m 17s\tremaining: 10m 20s\n",
      "8900:\tlearn: 222.5538928\ttest: 252.3174283\tbest: 252.2967297 (8880)\ttotal: 4m 20s\tremaining: 10m 17s\n",
      "9000:\tlearn: 222.3422110\ttest: 252.2177179\tbest: 252.2095285 (8985)\ttotal: 4m 23s\tremaining: 10m 14s\n",
      "9100:\tlearn: 222.0372451\ttest: 252.0027203\tbest: 252.0027203 (9100)\ttotal: 4m 26s\tremaining: 10m 11s\n",
      "9200:\tlearn: 221.7298916\ttest: 251.6956762\tbest: 251.6844443 (9199)\ttotal: 4m 29s\tremaining: 10m 8s\n",
      "9300:\tlearn: 221.3785120\ttest: 251.3771098\tbest: 251.3771098 (9300)\ttotal: 4m 32s\tremaining: 10m 5s\n",
      "9400:\tlearn: 221.1574360\ttest: 251.3297163\tbest: 251.3297163 (9400)\ttotal: 4m 34s\tremaining: 10m 2s\n",
      "9500:\tlearn: 220.8586378\ttest: 251.1774346\tbest: 251.1743565 (9495)\ttotal: 4m 37s\tremaining: 9m 59s\n",
      "9600:\tlearn: 220.6640864\ttest: 251.0854521\tbest: 251.0854336 (9599)\ttotal: 4m 40s\tremaining: 9m 56s\n",
      "9700:\tlearn: 220.3102588\ttest: 250.8873430\tbest: 250.8873430 (9700)\ttotal: 4m 43s\tremaining: 9m 52s\n",
      "9800:\tlearn: 220.1463542\ttest: 250.7496367\tbest: 250.7469019 (9797)\ttotal: 4m 46s\tremaining: 9m 49s\n",
      "9900:\tlearn: 220.0721394\ttest: 250.7445802\tbest: 250.7358887 (9852)\ttotal: 4m 49s\tremaining: 9m 46s\n",
      "10000:\tlearn: 219.8909792\ttest: 250.6089615\tbest: 250.6087070 (9997)\ttotal: 4m 51s\tremaining: 9m 43s\n",
      "10100:\tlearn: 219.7372130\ttest: 250.4979049\tbest: 250.4979049 (10100)\ttotal: 4m 54s\tremaining: 9m 40s\n",
      "10200:\tlearn: 219.5300848\ttest: 250.4463525\tbest: 250.4396677 (10156)\ttotal: 4m 57s\tremaining: 9m 37s\n",
      "10300:\tlearn: 219.3040131\ttest: 250.2691979\tbest: 250.2676070 (10295)\ttotal: 5m\tremaining: 9m 34s\n",
      "10400:\tlearn: 219.1455184\ttest: 250.1555041\tbest: 250.1552955 (10396)\ttotal: 5m 3s\tremaining: 9m 31s\n",
      "10500:\tlearn: 218.8058170\ttest: 249.8587369\tbest: 249.8483087 (10492)\ttotal: 5m 5s\tremaining: 9m 28s\n",
      "10600:\tlearn: 218.2877506\ttest: 249.4570951\tbest: 249.4533769 (10599)\ttotal: 5m 9s\tremaining: 9m 25s\n",
      "10700:\tlearn: 218.0143466\ttest: 249.2766659\tbest: 249.2766659 (10700)\ttotal: 5m 11s\tremaining: 9m 22s\n",
      "10800:\tlearn: 217.6835294\ttest: 249.1527505\tbest: 249.1382544 (10789)\ttotal: 5m 15s\tremaining: 9m 20s\n",
      "10900:\tlearn: 217.4477666\ttest: 248.9814111\tbest: 248.9812044 (10898)\ttotal: 5m 17s\tremaining: 9m 16s\n",
      "11000:\tlearn: 217.2105695\ttest: 248.8063460\tbest: 248.8063040 (10999)\ttotal: 5m 20s\tremaining: 9m 13s\n",
      "11100:\tlearn: 216.9610992\ttest: 248.6500612\tbest: 248.6457821 (11088)\ttotal: 5m 23s\tremaining: 9m 11s\n",
      "11200:\tlearn: 216.8413332\ttest: 248.6057551\tbest: 248.6052584 (11186)\ttotal: 5m 26s\tremaining: 9m 7s\n",
      "11300:\tlearn: 216.5765534\ttest: 248.4500686\tbest: 248.4500686 (11300)\ttotal: 5m 29s\tremaining: 9m 4s\n",
      "11400:\tlearn: 216.4971101\ttest: 248.4173625\tbest: 248.4155358 (11329)\ttotal: 5m 31s\tremaining: 9m 1s\n",
      "11500:\tlearn: 216.4317628\ttest: 248.3497202\tbest: 248.3497202 (11500)\ttotal: 5m 34s\tremaining: 8m 58s\n",
      "11600:\tlearn: 216.1205267\ttest: 248.1347794\tbest: 248.1347794 (11600)\ttotal: 5m 37s\tremaining: 8m 55s\n",
      "11700:\tlearn: 215.9274375\ttest: 248.0040610\tbest: 248.0013989 (11691)\ttotal: 5m 40s\tremaining: 8m 52s\n",
      "11800:\tlearn: 215.7246369\ttest: 248.0068392\tbest: 247.9733767 (11746)\ttotal: 5m 43s\tremaining: 8m 49s\n",
      "11900:\tlearn: 215.4319459\ttest: 247.7974332\tbest: 247.7942001 (11894)\ttotal: 5m 46s\tremaining: 8m 46s\n",
      "12000:\tlearn: 215.0981835\ttest: 247.5979051\tbest: 247.5958864 (11997)\ttotal: 5m 49s\tremaining: 8m 44s\n",
      "12100:\tlearn: 214.9326056\ttest: 247.5345089\tbest: 247.5318354 (12070)\ttotal: 5m 52s\tremaining: 8m 41s\n",
      "12200:\tlearn: 214.7869262\ttest: 247.4388302\tbest: 247.4349875 (12195)\ttotal: 5m 55s\tremaining: 8m 38s\n",
      "12300:\tlearn: 214.5488680\ttest: 247.3362977\tbest: 247.3359224 (12297)\ttotal: 5m 58s\tremaining: 8m 35s\n",
      "12400:\tlearn: 214.3117133\ttest: 247.1456695\tbest: 247.1443241 (12393)\ttotal: 6m\tremaining: 8m 31s\n",
      "12500:\tlearn: 214.1452935\ttest: 247.1166472\tbest: 247.1159343 (12489)\ttotal: 6m 3s\tremaining: 8m 28s\n",
      "12600:\tlearn: 213.9687508\ttest: 247.0588441\tbest: 247.0570594 (12593)\ttotal: 6m 6s\tremaining: 8m 25s\n",
      "12700:\tlearn: 213.8555580\ttest: 246.9759878\tbest: 246.9737429 (12673)\ttotal: 6m 8s\tremaining: 8m 22s\n",
      "12800:\tlearn: 213.7658892\ttest: 246.9510145\tbest: 246.9509667 (12798)\ttotal: 6m 11s\tremaining: 8m 19s\n",
      "12900:\tlearn: 213.5611803\ttest: 246.8026798\tbest: 246.8026798 (12900)\ttotal: 6m 14s\tremaining: 8m 16s\n",
      "13000:\tlearn: 213.3593544\ttest: 246.6846918\tbest: 246.6777665 (12954)\ttotal: 6m 17s\tremaining: 8m 13s\n",
      "13100:\tlearn: 213.1327384\ttest: 246.5418219\tbest: 246.5418219 (13100)\ttotal: 6m 20s\tremaining: 8m 10s\n",
      "13200:\tlearn: 212.8822274\ttest: 246.4359991\tbest: 246.4290143 (13199)\ttotal: 6m 23s\tremaining: 8m 7s\n",
      "13300:\tlearn: 212.7393924\ttest: 246.3303029\tbest: 246.3301507 (13291)\ttotal: 6m 26s\tremaining: 8m 4s\n",
      "13400:\tlearn: 212.5890564\ttest: 246.2692303\tbest: 246.2692303 (13400)\ttotal: 6m 29s\tremaining: 8m 1s\n",
      "13500:\tlearn: 212.3915288\ttest: 246.1151883\tbest: 246.1146443 (13498)\ttotal: 6m 31s\tremaining: 7m 58s\n",
      "13600:\tlearn: 212.2538336\ttest: 246.0487979\tbest: 246.0448422 (13560)\ttotal: 6m 34s\tremaining: 7m 55s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 246.0448422\n",
      "bestIteration = 13560\n",
      "\n",
      "Shrink model to first 13561 iterations.",
      "\n",
      "0:\tlearn: 958.2339678\ttest: 1013.7209447\tbest: 1013.7209447 (0)\ttotal: 32.4ms\tremaining: 16m 11s\n",
      "100:\tlearn: 440.6903897\ttest: 484.5935735\tbest: 484.5935735 (100)\ttotal: 3.43s\tremaining: 16m 54s\n",
      "200:\tlearn: 392.8224148\ttest: 427.0473294\tbest: 427.0473294 (200)\ttotal: 6.53s\tremaining: 16m 8s\n",
      "300:\tlearn: 376.0226829\ttest: 406.7905996\tbest: 406.7905996 (300)\ttotal: 8.66s\tremaining: 14m 14s\n",
      "400:\tlearn: 354.1184694\ttest: 379.2622810\tbest: 379.2622810 (400)\ttotal: 11.3s\tremaining: 13m 54s\n",
      "500:\tlearn: 337.9545756\ttest: 359.6049088\tbest: 359.6049088 (500)\ttotal: 13.7s\tremaining: 13m 25s\n",
      "600:\tlearn: 325.8755473\ttest: 345.8758152\tbest: 345.8758152 (600)\ttotal: 16.4s\tremaining: 13m 21s\n",
      "700:\tlearn: 317.7483393\ttest: 336.7440484\tbest: 336.7440484 (700)\ttotal: 19s\tremaining: 13m 12s\n",
      "800:\tlearn: 310.8314425\ttest: 329.4585580\tbest: 329.4585580 (800)\ttotal: 21.6s\tremaining: 13m 8s\n",
      "900:\tlearn: 306.7188285\ttest: 324.9904501\tbest: 324.9904501 (900)\ttotal: 24s\tremaining: 12m 55s\n",
      "1000:\tlearn: 303.1847551\ttest: 321.4976397\tbest: 321.4976397 (1000)\ttotal: 26.4s\tremaining: 12m 44s\n",
      "1100:\tlearn: 299.0157040\ttest: 317.5171407\tbest: 317.5171407 (1100)\ttotal: 29s\tremaining: 12m 41s\n",
      "1200:\tlearn: 294.4440413\ttest: 312.4465735\tbest: 312.4465735 (1200)\ttotal: 31.8s\tremaining: 12m 42s\n",
      "1300:\tlearn: 289.1586226\ttest: 306.9404654\tbest: 306.9404654 (1300)\ttotal: 35s\tremaining: 12m 52s\n",
      "1400:\tlearn: 284.7131954\ttest: 302.5748423\tbest: 302.5748423 (1400)\ttotal: 38.1s\tremaining: 12m 58s\n",
      "1500:\tlearn: 281.4599828\ttest: 299.6324623\tbest: 299.6324623 (1500)\ttotal: 41s\tremaining: 12m 57s\n",
      "1600:\tlearn: 279.2368590\ttest: 297.7814321\tbest: 297.7749823 (1597)\ttotal: 43.6s\tremaining: 12m 53s\n",
      "1700:\tlearn: 276.1959631\ttest: 295.3114401\tbest: 295.3114401 (1700)\ttotal: 46.5s\tremaining: 12m 53s\n",
      "1800:\tlearn: 274.0514593\ttest: 293.5027088\tbest: 293.5016436 (1795)\ttotal: 49.3s\tremaining: 12m 51s\n",
      "1900:\tlearn: 272.1125472\ttest: 291.8850861\tbest: 291.8850861 (1900)\ttotal: 52.1s\tremaining: 12m 50s\n",
      "2000:\tlearn: 270.6973702\ttest: 290.9219304\tbest: 290.9207390 (1997)\ttotal: 54.9s\tremaining: 12m 48s\n",
      "2100:\tlearn: 269.5261948\ttest: 290.3185053\tbest: 290.3185053 (2100)\ttotal: 57.5s\tremaining: 12m 43s\n",
      "2200:\tlearn: 268.5127497\ttest: 289.3962325\tbest: 289.3962325 (2200)\ttotal: 60s\tremaining: 12m 37s\n",
      "2300:\tlearn: 267.2021725\ttest: 288.3101766\tbest: 288.3101766 (2300)\ttotal: 1m 2s\tremaining: 12m 33s\n",
      "2400:\tlearn: 266.2435974\ttest: 287.3902435\tbest: 287.3771067 (2396)\ttotal: 1m 5s\tremaining: 12m 30s\n",
      "2500:\tlearn: 265.3669499\ttest: 286.6536920\tbest: 286.6530175 (2497)\ttotal: 1m 7s\tremaining: 12m 27s\n",
      "2600:\tlearn: 264.0377729\ttest: 285.6361378\tbest: 285.6361378 (2600)\ttotal: 1m 10s\tremaining: 12m 25s\n",
      "2700:\tlearn: 263.0701514\ttest: 284.8165508\tbest: 284.8165071 (2699)\ttotal: 1m 13s\tremaining: 12m 24s\n",
      "2800:\tlearn: 261.8880226\ttest: 283.8705276\tbest: 283.8550346 (2795)\ttotal: 1m 16s\tremaining: 12m 24s\n",
      "2900:\tlearn: 261.1854658\ttest: 283.3713078\tbest: 283.3711752 (2899)\ttotal: 1m 19s\tremaining: 12m 22s\n",
      "3000:\tlearn: 259.7933231\ttest: 282.1983758\tbest: 282.1983613 (2999)\ttotal: 1m 22s\tremaining: 12m 20s\n",
      "3100:\tlearn: 258.8201787\ttest: 281.3305422\tbest: 281.3305422 (3100)\ttotal: 1m 25s\tremaining: 12m 18s\n",
      "3200:\tlearn: 257.7209760\ttest: 280.4046197\tbest: 280.4046197 (3200)\ttotal: 1m 27s\tremaining: 12m 14s\n",
      "3300:\tlearn: 256.6212076\ttest: 279.3915571\tbest: 279.3897492 (3295)\ttotal: 1m 30s\tremaining: 12m 9s\n",
      "3400:\tlearn: 255.8307565\ttest: 278.6753424\tbest: 278.6753424 (3400)\ttotal: 1m 32s\tremaining: 12m 7s\n",
      "3500:\tlearn: 254.4861413\ttest: 277.5582042\tbest: 277.5580923 (3498)\ttotal: 1m 35s\tremaining: 12m 5s\n",
      "3600:\tlearn: 253.7104223\ttest: 276.9277978\tbest: 276.9277978 (3600)\ttotal: 1m 38s\tremaining: 12m 3s\n",
      "3700:\tlearn: 252.4208458\ttest: 276.1053133\tbest: 276.1053133 (3700)\ttotal: 1m 41s\tremaining: 12m 1s\n",
      "3800:\tlearn: 251.1496970\ttest: 274.9703007\tbest: 274.9693851 (3798)\ttotal: 1m 44s\tremaining: 12m\n",
      "3900:\tlearn: 250.7516191\ttest: 274.7226659\tbest: 274.7202043 (3887)\ttotal: 1m 47s\tremaining: 11m 57s\n",
      "4000:\tlearn: 250.5186858\ttest: 274.4922497\tbest: 274.4916838 (3998)\ttotal: 1m 49s\tremaining: 11m 53s\n",
      "4100:\tlearn: 249.9019135\ttest: 273.9857320\tbest: 273.9857320 (4100)\ttotal: 1m 52s\tremaining: 11m 49s\n",
      "4200:\tlearn: 249.5752644\ttest: 273.7323418\tbest: 273.7322376 (4197)\ttotal: 1m 55s\tremaining: 11m 46s\n",
      "4300:\tlearn: 248.7435909\ttest: 273.0035193\tbest: 273.0035193 (4300)\ttotal: 1m 58s\tremaining: 11m 45s\n",
      "4400:\tlearn: 248.1835196\ttest: 272.5933460\tbest: 272.5933460 (4400)\ttotal: 2m\tremaining: 11m 42s\n",
      "4500:\tlearn: 247.4807126\ttest: 271.9370119\tbest: 271.9369992 (4495)\ttotal: 2m 3s\tremaining: 11m 39s\n",
      "4600:\tlearn: 246.8933699\ttest: 271.4174810\tbest: 271.4173116 (4598)\ttotal: 2m 6s\tremaining: 11m 36s\n",
      "4700:\tlearn: 246.7075391\ttest: 271.2808180\tbest: 271.2808180 (4700)\ttotal: 2m 8s\tremaining: 11m 31s\n",
      "4800:\tlearn: 246.3406465\ttest: 271.0846125\tbest: 271.0830310 (4797)\ttotal: 2m 11s\tremaining: 11m 28s\n",
      "4900:\tlearn: 245.6525683\ttest: 270.4786051\tbest: 270.4785730 (4899)\ttotal: 2m 14s\tremaining: 11m 26s\n",
      "5000:\tlearn: 244.9477325\ttest: 269.9114484\tbest: 269.9061581 (4999)\ttotal: 2m 16s\tremaining: 11m 24s\n",
      "5100:\tlearn: 244.2617195\ttest: 269.3815940\tbest: 269.3811839 (5096)\ttotal: 2m 19s\tremaining: 11m 21s\n",
      "5200:\tlearn: 244.0170832\ttest: 269.2775120\tbest: 269.2771714 (5198)\ttotal: 2m 22s\tremaining: 11m 17s\n",
      "5300:\tlearn: 243.6599787\ttest: 268.9399123\tbest: 268.9396834 (5284)\ttotal: 2m 24s\tremaining: 11m 13s\n",
      "5400:\tlearn: 243.5164973\ttest: 268.8343881\tbest: 268.8325980 (5398)\ttotal: 2m 26s\tremaining: 11m 9s\n",
      "5500:\tlearn: 243.1208002\ttest: 268.5324400\tbest: 268.5323896 (5499)\ttotal: 2m 29s\tremaining: 11m 5s\n",
      "5600:\tlearn: 242.7660544\ttest: 268.2247923\tbest: 268.2247923 (5600)\ttotal: 2m 32s\tremaining: 11m 2s\n",
      "5700:\tlearn: 242.4169380\ttest: 267.8929270\tbest: 267.8929270 (5700)\ttotal: 2m 34s\tremaining: 11m\n",
      "5800:\tlearn: 242.1985323\ttest: 267.7775621\tbest: 267.7775621 (5800)\ttotal: 2m 37s\tremaining: 10m 57s\n",
      "5900:\tlearn: 241.9036724\ttest: 267.5509896\tbest: 267.5500798 (5899)\ttotal: 2m 40s\tremaining: 10m 54s\n",
      "6000:\tlearn: 241.5163331\ttest: 267.1315537\tbest: 267.1315537 (6000)\ttotal: 2m 42s\tremaining: 10m 51s\n",
      "6100:\tlearn: 240.9496934\ttest: 266.7782158\tbest: 266.7782158 (6100)\ttotal: 2m 45s\tremaining: 10m 47s\n",
      "6200:\tlearn: 240.6892371\ttest: 266.6106685\tbest: 266.6106685 (6200)\ttotal: 2m 47s\tremaining: 10m 44s\n",
      "6300:\tlearn: 240.0313204\ttest: 266.1157431\tbest: 266.1157431 (6300)\ttotal: 2m 50s\tremaining: 10m 41s\n",
      "6400:\tlearn: 239.7033377\ttest: 265.7643378\tbest: 265.7643378 (6400)\ttotal: 2m 53s\tremaining: 10m 37s\n",
      "6500:\tlearn: 239.6252342\ttest: 265.6714068\tbest: 265.6713846 (6498)\ttotal: 2m 55s\tremaining: 10m 33s\n",
      "6600:\tlearn: 239.0160796\ttest: 265.1657532\tbest: 265.1656274 (6598)\ttotal: 2m 57s\tremaining: 10m 30s\n",
      "6700:\tlearn: 238.7179245\ttest: 264.9592704\tbest: 264.9592704 (6700)\ttotal: 3m\tremaining: 10m 27s\n",
      "6800:\tlearn: 238.5639689\ttest: 264.8674124\tbest: 264.8674124 (6800)\ttotal: 3m 3s\tremaining: 10m 24s\n",
      "6900:\tlearn: 238.3154034\ttest: 264.6601741\tbest: 264.6590035 (6887)\ttotal: 3m 5s\tremaining: 10m 20s\n",
      "7000:\tlearn: 238.1627542\ttest: 264.5947109\tbest: 264.5947109 (7000)\ttotal: 3m 7s\tremaining: 10m 17s\n",
      "7100:\tlearn: 238.0172972\ttest: 264.4266291\tbest: 264.4266291 (7100)\ttotal: 3m 10s\tremaining: 10m 13s\n",
      "7200:\tlearn: 237.7659929\ttest: 264.2251272\tbest: 264.2251263 (7197)\ttotal: 3m 12s\tremaining: 10m 10s\n",
      "7300:\tlearn: 237.1467553\ttest: 263.6890456\tbest: 263.6890456 (7300)\ttotal: 3m 15s\tremaining: 10m 7s\n",
      "7400:\tlearn: 236.7753872\ttest: 263.3668775\tbest: 263.3667726 (7399)\ttotal: 3m 17s\tremaining: 10m 3s\n",
      "7500:\tlearn: 236.4875490\ttest: 263.1357523\tbest: 263.1357523 (7500)\ttotal: 3m 20s\tremaining: 10m 1s\n",
      "7600:\tlearn: 235.7549146\ttest: 262.6873643\tbest: 262.6873414 (7597)\ttotal: 3m 23s\tremaining: 9m 58s\n",
      "7700:\tlearn: 235.3939921\ttest: 262.3507291\tbest: 262.3506891 (7695)\ttotal: 3m 25s\tremaining: 9m 55s\n",
      "7800:\tlearn: 235.2582429\ttest: 262.3089903\tbest: 262.3063847 (7793)\ttotal: 3m 27s\tremaining: 9m 51s\n",
      "7900:\tlearn: 234.9037739\ttest: 262.0193893\tbest: 262.0138892 (7898)\ttotal: 3m 30s\tremaining: 9m 49s\n",
      "8000:\tlearn: 234.4292647\ttest: 261.6231201\tbest: 261.6231201 (8000)\ttotal: 3m 33s\tremaining: 9m 47s\n",
      "8100:\tlearn: 234.0746472\ttest: 261.3874854\tbest: 261.3869777 (8096)\ttotal: 3m 36s\tremaining: 9m 44s\n",
      "8200:\tlearn: 233.8773316\ttest: 261.2613215\tbest: 261.2512336 (8188)\ttotal: 3m 38s\tremaining: 9m 41s\n",
      "8300:\tlearn: 233.6600619\ttest: 261.0290816\tbest: 261.0289940 (8288)\ttotal: 3m 41s\tremaining: 9m 39s\n",
      "8400:\tlearn: 233.6056907\ttest: 261.0094783\tbest: 261.0090725 (8392)\ttotal: 3m 44s\tremaining: 9m 36s\n",
      "8500:\tlearn: 233.5025062\ttest: 260.9616215\tbest: 260.9616215 (8500)\ttotal: 3m 46s\tremaining: 9m 33s\n",
      "8600:\tlearn: 233.1916137\ttest: 260.6464209\tbest: 260.6451138 (8569)\ttotal: 3m 49s\tremaining: 9m 31s\n",
      "8700:\tlearn: 233.0722698\ttest: 260.5848568\tbest: 260.5847453 (8697)\ttotal: 3m 52s\tremaining: 9m 29s\n",
      "8800:\tlearn: 232.5738478\ttest: 260.2007460\tbest: 260.2007460 (8800)\ttotal: 3m 55s\tremaining: 9m 26s\n",
      "8900:\tlearn: 231.8733302\ttest: 259.6056345\tbest: 259.6056345 (8900)\ttotal: 3m 58s\tremaining: 9m 24s\n",
      "9000:\tlearn: 231.2875463\ttest: 259.1718116\tbest: 259.1708137 (8995)\ttotal: 4m 1s\tremaining: 9m 22s\n",
      "9100:\tlearn: 231.0061283\ttest: 258.9773525\tbest: 258.9771835 (9099)\ttotal: 4m 3s\tremaining: 9m 20s\n",
      "9200:\tlearn: 230.8195543\ttest: 258.8096278\tbest: 258.8094038 (9197)\ttotal: 4m 6s\tremaining: 9m 17s\n",
      "9300:\tlearn: 230.5622646\ttest: 258.6585254\tbest: 258.6585251 (9299)\ttotal: 4m 9s\tremaining: 9m 15s\n",
      "9400:\tlearn: 230.3822888\ttest: 258.4708436\tbest: 258.4708436 (9400)\ttotal: 4m 12s\tremaining: 9m 12s\n",
      "9500:\tlearn: 230.1216620\ttest: 258.2839156\tbest: 258.2839156 (9500)\ttotal: 4m 14s\tremaining: 9m 8s\n",
      "9600:\tlearn: 229.7877573\ttest: 258.0545607\tbest: 258.0476730 (9593)\ttotal: 4m 17s\tremaining: 9m 6s\n",
      "9700:\tlearn: 229.6170912\ttest: 257.8981141\tbest: 257.8976436 (9699)\ttotal: 4m 19s\tremaining: 9m 3s\n",
      "9800:\tlearn: 229.5413713\ttest: 257.8750602\tbest: 257.8750602 (9800)\ttotal: 4m 22s\tremaining: 9m\n",
      "9900:\tlearn: 229.5223648\ttest: 257.8670157\tbest: 257.8665554 (9888)\ttotal: 4m 24s\tremaining: 8m 57s\n",
      "10000:\tlearn: 229.3809702\ttest: 257.7667621\tbest: 257.7643880 (9985)\ttotal: 4m 27s\tremaining: 8m 54s\n",
      "10100:\tlearn: 229.2913317\ttest: 257.7353381\tbest: 257.7316884 (10058)\ttotal: 4m 29s\tremaining: 8m 51s\n",
      "10200:\tlearn: 229.0859336\ttest: 257.5852786\tbest: 257.5852786 (10200)\ttotal: 4m 32s\tremaining: 8m 48s\n",
      "10300:\tlearn: 228.9169262\ttest: 257.4723202\tbest: 257.4723202 (10300)\ttotal: 4m 34s\tremaining: 8m 45s\n",
      "10400:\tlearn: 228.5643272\ttest: 257.2357511\tbest: 257.2320398 (10396)\ttotal: 4m 37s\tremaining: 8m 43s\n",
      "10500:\tlearn: 228.1704797\ttest: 257.0112947\tbest: 257.0105970 (10498)\ttotal: 4m 39s\tremaining: 8m 39s\n",
      "10600:\tlearn: 227.8975959\ttest: 256.7887508\tbest: 256.7881641 (10585)\ttotal: 4m 42s\tremaining: 8m 36s\n",
      "10700:\tlearn: 227.5162285\ttest: 256.5548967\tbest: 256.5548423 (10690)\ttotal: 4m 44s\tremaining: 8m 32s\n",
      "10800:\tlearn: 227.0421735\ttest: 256.2146031\tbest: 256.2005092 (10782)\ttotal: 4m 46s\tremaining: 8m 29s\n",
      "10900:\tlearn: 226.5895659\ttest: 255.8731113\tbest: 255.8611561 (10887)\ttotal: 4m 49s\tremaining: 8m 26s\n",
      "11000:\tlearn: 226.2365619\ttest: 255.6504262\tbest: 255.6504262 (11000)\ttotal: 4m 51s\tremaining: 8m 24s\n",
      "11100:\tlearn: 225.7568713\ttest: 255.3951119\tbest: 255.3951119 (11100)\ttotal: 4m 54s\tremaining: 8m 21s\n",
      "11200:\tlearn: 225.6275435\ttest: 255.2871503\tbest: 255.2871503 (11200)\ttotal: 4m 56s\tremaining: 8m 18s\n",
      "11300:\tlearn: 225.4967288\ttest: 255.2039877\tbest: 255.2007374 (11294)\ttotal: 4m 59s\tremaining: 8m 15s\n",
      "11400:\tlearn: 225.3645830\ttest: 255.0963234\tbest: 255.0963209 (11398)\ttotal: 5m 1s\tremaining: 8m 12s\n",
      "11500:\tlearn: 225.2606377\ttest: 255.0197434\tbest: 255.0197434 (11500)\ttotal: 5m 3s\tremaining: 8m 8s\n",
      "11600:\tlearn: 225.1590053\ttest: 254.9247436\tbest: 254.9245266 (11590)\ttotal: 5m 6s\tremaining: 8m 5s\n",
      "11700:\tlearn: 224.9768604\ttest: 254.7993250\tbest: 254.7988531 (11685)\ttotal: 5m 8s\tremaining: 8m 2s\n",
      "11800:\tlearn: 224.8722777\ttest: 254.7389583\tbest: 254.7389554 (11798)\ttotal: 5m 11s\tremaining: 7m 59s\n",
      "11900:\tlearn: 224.7054112\ttest: 254.7280982\tbest: 254.7017124 (11830)\ttotal: 5m 13s\tremaining: 7m 57s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 254.7017124\n",
      "bestIteration = 11830\n",
      "\n",
      "Shrink model to first 11831 iterations.",
      "\n",
      "0:\tlearn: 980.7419929\ttest: 933.1318354\tbest: 933.1318354 (0)\ttotal: 29.1ms\tremaining: 14m 34s\n",
      "100:\tlearn: 444.8224202\ttest: 407.9383121\tbest: 407.9383121 (100)\ttotal: 3.27s\tremaining: 16m 8s\n",
      "200:\tlearn: 392.3882548\ttest: 363.6417713\tbest: 363.6417713 (200)\ttotal: 6.48s\tremaining: 16m 1s\n",
      "300:\tlearn: 362.6371610\ttest: 341.3637948\tbest: 341.3637948 (300)\ttotal: 9.79s\tremaining: 16m 6s\n",
      "400:\tlearn: 344.9241213\ttest: 326.3050863\tbest: 326.3050863 (400)\ttotal: 12.9s\tremaining: 15m 53s\n",
      "500:\tlearn: 325.9343862\ttest: 311.3030781\tbest: 311.2877112 (499)\ttotal: 16.5s\tremaining: 16m 12s\n",
      "600:\tlearn: 314.6487252\ttest: 301.4592154\tbest: 301.4592154 (600)\ttotal: 19.9s\tremaining: 16m 11s\n",
      "700:\tlearn: 303.9392644\ttest: 293.1933368\tbest: 293.1933368 (700)\ttotal: 23s\tremaining: 16m 1s\n",
      "800:\tlearn: 297.7057091\ttest: 288.8477930\tbest: 288.8360428 (799)\ttotal: 26.2s\tremaining: 15m 54s\n",
      "900:\tlearn: 293.7443270\ttest: 286.1564022\tbest: 286.1564022 (900)\ttotal: 29.2s\tremaining: 15m 44s\n",
      "1000:\tlearn: 290.8467048\ttest: 284.3686991\tbest: 284.3657627 (998)\ttotal: 32.1s\tremaining: 15m 30s\n",
      "1100:\tlearn: 287.1849767\ttest: 281.5913548\tbest: 281.5913548 (1100)\ttotal: 35.1s\tremaining: 15m 20s\n",
      "1200:\tlearn: 285.3856438\ttest: 280.2531412\tbest: 280.2429883 (1196)\ttotal: 37.9s\tremaining: 15m 9s\n",
      "1300:\tlearn: 283.8179419\ttest: 279.1481938\tbest: 279.1481938 (1300)\ttotal: 40.6s\tremaining: 14m 54s\n",
      "1400:\tlearn: 281.3960502\ttest: 277.3105905\tbest: 277.3104088 (1399)\ttotal: 43.5s\tremaining: 14m 48s\n",
      "1500:\tlearn: 279.7204640\ttest: 276.1537022\tbest: 276.1537022 (1500)\ttotal: 46.3s\tremaining: 14m 39s\n",
      "1600:\tlearn: 277.6887802\ttest: 274.8944963\tbest: 274.8892787 (1593)\ttotal: 49s\tremaining: 14m 29s\n",
      "1700:\tlearn: 276.2422302\ttest: 273.9667463\tbest: 273.9661144 (1699)\ttotal: 52s\tremaining: 14m 24s\n",
      "1800:\tlearn: 274.1222124\ttest: 272.5993628\tbest: 272.5993628 (1800)\ttotal: 54.8s\tremaining: 14m 18s\n",
      "1900:\tlearn: 271.3094629\ttest: 270.6563514\tbest: 270.6563514 (1900)\ttotal: 57.6s\tremaining: 14m 10s\n",
      "2000:\tlearn: 269.3418374\ttest: 269.1853886\tbest: 269.1853886 (2000)\ttotal: 1m\tremaining: 14m 6s\n",
      "2100:\tlearn: 267.1605968\ttest: 267.8519849\tbest: 267.8519849 (2100)\ttotal: 1m 3s\tremaining: 14m 2s\n",
      "2200:\tlearn: 264.5997951\ttest: 266.3020594\tbest: 266.2976442 (2198)\ttotal: 1m 6s\tremaining: 14m 1s\n",
      "2300:\tlearn: 263.0886271\ttest: 265.3875063\tbest: 265.3875063 (2300)\ttotal: 1m 9s\tremaining: 13m 57s\n",
      "2400:\tlearn: 260.9568622\ttest: 263.6332338\tbest: 263.6332338 (2400)\ttotal: 1m 12s\tremaining: 13m 55s\n",
      "2500:\tlearn: 259.6378904\ttest: 262.6139626\tbest: 262.6074448 (2499)\ttotal: 1m 15s\tremaining: 13m 51s\n",
      "2600:\tlearn: 258.1421669\ttest: 261.6561486\tbest: 261.6258858 (2594)\ttotal: 1m 18s\tremaining: 13m 49s\n",
      "2700:\tlearn: 257.1442313\ttest: 261.3896388\tbest: 261.3636523 (2697)\ttotal: 1m 21s\tremaining: 13m 47s\n",
      "2800:\tlearn: 255.8164289\ttest: 260.5024804\tbest: 260.5024804 (2800)\ttotal: 1m 24s\tremaining: 13m 42s\n",
      "2900:\tlearn: 254.4667702\ttest: 259.5314869\tbest: 259.5312084 (2899)\ttotal: 1m 27s\tremaining: 13m 36s\n",
      "3000:\tlearn: 253.3176237\ttest: 258.8485379\tbest: 258.8485379 (3000)\ttotal: 1m 30s\tremaining: 13m 33s\n",
      "3100:\tlearn: 252.6978271\ttest: 258.4518507\tbest: 258.4518507 (3100)\ttotal: 1m 33s\tremaining: 13m 28s\n",
      "3200:\tlearn: 251.5098797\ttest: 257.5994157\tbest: 257.5831252 (3189)\ttotal: 1m 36s\tremaining: 13m 26s\n",
      "3300:\tlearn: 250.3679571\ttest: 256.8221573\tbest: 256.8221573 (3300)\ttotal: 1m 39s\tremaining: 13m 22s\n",
      "3400:\tlearn: 249.5925368\ttest: 256.1315860\tbest: 256.1315860 (3400)\ttotal: 1m 42s\tremaining: 13m 20s\n",
      "3500:\tlearn: 248.8867326\ttest: 255.6672074\tbest: 255.6664541 (3499)\ttotal: 1m 45s\tremaining: 13m 15s\n",
      "3600:\tlearn: 248.4505981\ttest: 255.4286846\tbest: 255.4282372 (3599)\ttotal: 1m 47s\tremaining: 13m 10s\n",
      "3700:\tlearn: 247.7665542\ttest: 255.0270672\tbest: 255.0265692 (3699)\ttotal: 1m 50s\tremaining: 13m 6s\n",
      "3800:\tlearn: 247.0229393\ttest: 254.6196844\tbest: 254.6095624 (3787)\ttotal: 1m 53s\tremaining: 13m 2s\n",
      "3900:\tlearn: 246.3339223\ttest: 254.2378653\tbest: 254.2378653 (3900)\ttotal: 1m 56s\tremaining: 12m 58s\n",
      "4000:\tlearn: 245.3849813\ttest: 253.7341396\tbest: 253.7341396 (4000)\ttotal: 1m 59s\tremaining: 12m 54s\n",
      "4100:\tlearn: 244.3997392\ttest: 253.1584834\tbest: 253.1514028 (4084)\ttotal: 2m 1s\tremaining: 12m 50s\n",
      "4200:\tlearn: 243.6827857\ttest: 252.8054390\tbest: 252.8032621 (4195)\ttotal: 2m 4s\tremaining: 12m 46s\n",
      "4300:\tlearn: 242.6522319\ttest: 252.1309790\tbest: 252.1159302 (4286)\ttotal: 2m 7s\tremaining: 12m 43s\n",
      "4400:\tlearn: 241.7037764\ttest: 251.5657920\tbest: 251.5657920 (4400)\ttotal: 2m 10s\tremaining: 12m 41s\n",
      "4500:\tlearn: 240.9979046\ttest: 251.1994368\tbest: 251.1994368 (4500)\ttotal: 2m 13s\tremaining: 12m 37s\n",
      "4600:\tlearn: 240.2569953\ttest: 250.6712165\tbest: 250.6695484 (4587)\ttotal: 2m 16s\tremaining: 12m 33s\n",
      "4700:\tlearn: 239.5340605\ttest: 250.1974875\tbest: 250.1974875 (4700)\ttotal: 2m 19s\tremaining: 12m 30s\n",
      "4800:\tlearn: 238.4926038\ttest: 249.7839031\tbest: 249.7839031 (4800)\ttotal: 2m 22s\tremaining: 12m 28s\n",
      "4900:\tlearn: 237.8179487\ttest: 249.3921730\tbest: 249.3886452 (4880)\ttotal: 2m 26s\tremaining: 12m 27s\n",
      "5000:\tlearn: 237.0941901\ttest: 248.8701069\tbest: 248.8700341 (4999)\ttotal: 2m 28s\tremaining: 12m 24s\n",
      "5100:\tlearn: 235.9889870\ttest: 248.2074188\tbest: 248.2074188 (5100)\ttotal: 2m 31s\tremaining: 12m 21s\n",
      "5200:\tlearn: 235.2623831\ttest: 247.6956690\tbest: 247.6956690 (5200)\ttotal: 2m 34s\tremaining: 12m 16s\n",
      "5300:\tlearn: 234.8386628\ttest: 247.4641612\tbest: 247.4639833 (5299)\ttotal: 2m 37s\tremaining: 12m 12s\n",
      "5400:\tlearn: 234.5554439\ttest: 247.3538803\tbest: 247.3533280 (5397)\ttotal: 2m 40s\tremaining: 12m 8s\n",
      "5500:\tlearn: 233.8532663\ttest: 246.9082644\tbest: 246.9064312 (5493)\ttotal: 2m 43s\tremaining: 12m 6s\n",
      "5600:\tlearn: 233.4035631\ttest: 246.7682267\tbest: 246.7679263 (5599)\ttotal: 2m 45s\tremaining: 12m 2s\n",
      "5700:\tlearn: 232.7654724\ttest: 246.2891612\tbest: 246.2876939 (5695)\ttotal: 2m 48s\tremaining: 11m 59s\n",
      "5800:\tlearn: 231.9629844\ttest: 245.8836463\tbest: 245.8836463 (5800)\ttotal: 2m 51s\tremaining: 11m 56s\n",
      "5900:\tlearn: 231.4581968\ttest: 245.5824773\tbest: 245.5824773 (5900)\ttotal: 2m 54s\tremaining: 11m 52s\n",
      "6000:\tlearn: 231.0713110\ttest: 245.3970519\tbest: 245.3970519 (6000)\ttotal: 2m 57s\tremaining: 11m 49s\n",
      "6100:\tlearn: 230.6727697\ttest: 245.1274614\tbest: 245.1256524 (6095)\ttotal: 3m\tremaining: 11m 45s\n",
      "6200:\tlearn: 230.0444421\ttest: 244.7147602\tbest: 244.7142364 (6198)\ttotal: 3m 3s\tremaining: 11m 43s\n",
      "6300:\tlearn: 229.6532825\ttest: 244.4737256\tbest: 244.4492012 (6288)\ttotal: 3m 6s\tremaining: 11m 40s\n",
      "6400:\tlearn: 229.1738028\ttest: 244.2307220\tbest: 244.2307220 (6400)\ttotal: 3m 9s\tremaining: 11m 37s\n",
      "6500:\tlearn: 228.5354037\ttest: 243.8166425\tbest: 243.8151173 (6496)\ttotal: 3m 12s\tremaining: 11m 34s\n",
      "6600:\tlearn: 228.0134410\ttest: 243.5793061\tbest: 243.5793061 (6600)\ttotal: 3m 15s\tremaining: 11m 31s\n",
      "6700:\tlearn: 227.6027870\ttest: 243.3606624\tbest: 243.3546751 (6696)\ttotal: 3m 18s\tremaining: 11m 28s\n",
      "6800:\tlearn: 227.2892904\ttest: 243.2094901\tbest: 243.2094901 (6800)\ttotal: 3m 21s\tremaining: 11m 25s\n",
      "6900:\tlearn: 226.7501498\ttest: 242.8981682\tbest: 242.8981682 (6900)\ttotal: 3m 23s\tremaining: 11m 22s\n",
      "7000:\tlearn: 226.3961674\ttest: 242.7418410\tbest: 242.7349328 (6993)\ttotal: 3m 26s\tremaining: 11m 18s\n",
      "7100:\tlearn: 226.0935826\ttest: 242.5329556\tbest: 242.5329556 (7100)\ttotal: 3m 29s\tremaining: 11m 15s\n",
      "7200:\tlearn: 225.6558065\ttest: 242.2491175\tbest: 242.2478293 (7193)\ttotal: 3m 32s\tremaining: 11m 12s\n",
      "7300:\tlearn: 225.2683025\ttest: 241.9495023\tbest: 241.9429715 (7298)\ttotal: 3m 35s\tremaining: 11m 9s\n",
      "7400:\tlearn: 224.8670985\ttest: 241.6606808\tbest: 241.6606808 (7400)\ttotal: 3m 38s\tremaining: 11m 5s\n",
      "7500:\tlearn: 224.6776610\ttest: 241.5158762\tbest: 241.5158762 (7500)\ttotal: 3m 40s\tremaining: 11m 2s\n",
      "7600:\tlearn: 224.4013749\ttest: 241.3593046\tbest: 241.3585640 (7597)\ttotal: 3m 43s\tremaining: 10m 59s\n",
      "7700:\tlearn: 224.0771624\ttest: 241.1404099\tbest: 241.1404099 (7700)\ttotal: 3m 46s\tremaining: 10m 56s\n",
      "7800:\tlearn: 223.8890001\ttest: 241.0008055\tbest: 241.0008055 (7800)\ttotal: 3m 49s\tremaining: 10m 54s\n",
      "7900:\tlearn: 223.4997169\ttest: 240.8063882\tbest: 240.8063853 (7899)\ttotal: 3m 52s\tremaining: 10m 51s\n",
      "8000:\tlearn: 223.1301229\ttest: 240.5421990\tbest: 240.5402251 (7996)\ttotal: 3m 56s\tremaining: 10m 49s\n",
      "8100:\tlearn: 222.7190554\ttest: 240.3247257\tbest: 240.3247257 (8100)\ttotal: 3m 59s\tremaining: 10m 46s\n",
      "8200:\tlearn: 222.4684986\ttest: 240.0853463\tbest: 240.0816727 (8181)\ttotal: 4m 2s\tremaining: 10m 43s\n",
      "8300:\tlearn: 222.2828093\ttest: 240.0091631\tbest: 240.0091631 (8300)\ttotal: 4m 4s\tremaining: 10m 40s\n",
      "8400:\tlearn: 221.9351875\ttest: 239.7989334\tbest: 239.7989334 (8400)\ttotal: 4m 7s\tremaining: 10m 37s\n",
      "8500:\tlearn: 221.6094863\ttest: 239.6336250\tbest: 239.6333325 (8497)\ttotal: 4m 11s\tremaining: 10m 34s\n",
      "8600:\tlearn: 221.2120601\ttest: 239.4773813\tbest: 239.4761746 (8599)\ttotal: 4m 14s\tremaining: 10m 32s\n",
      "8700:\tlearn: 220.8435929\ttest: 239.3010161\tbest: 239.2988323 (8695)\ttotal: 4m 17s\tremaining: 10m 29s\n",
      "8800:\tlearn: 220.5897174\ttest: 239.1816946\tbest: 239.1816946 (8800)\ttotal: 4m 20s\tremaining: 10m 26s\n",
      "8900:\tlearn: 220.3054242\ttest: 239.1010902\tbest: 239.0860060 (8888)\ttotal: 4m 23s\tremaining: 10m 24s\n",
      "9000:\tlearn: 219.9734979\ttest: 238.9739196\tbest: 238.9733004 (8999)\ttotal: 4m 26s\tremaining: 10m 21s\n",
      "9100:\tlearn: 219.6458194\ttest: 238.8594619\tbest: 238.8574004 (9094)\ttotal: 4m 29s\tremaining: 10m 19s\n",
      "9200:\tlearn: 219.3071270\ttest: 238.6061999\tbest: 238.6061999 (9200)\ttotal: 4m 32s\tremaining: 10m 16s\n",
      "9300:\tlearn: 219.0140275\ttest: 238.4781763\tbest: 238.4764210 (9293)\ttotal: 4m 35s\tremaining: 10m 13s\n",
      "9400:\tlearn: 218.7811202\ttest: 238.3706728\tbest: 238.3705193 (9399)\ttotal: 4m 38s\tremaining: 10m 10s\n",
      "9500:\tlearn: 218.5941683\ttest: 238.2913045\tbest: 238.2901869 (9494)\ttotal: 4m 41s\tremaining: 10m 7s\n",
      "9600:\tlearn: 218.4874460\ttest: 238.2082632\tbest: 238.2081860 (9597)\ttotal: 4m 44s\tremaining: 10m 4s\n",
      "9700:\tlearn: 218.3715618\ttest: 238.1104838\tbest: 238.1102814 (9697)\ttotal: 4m 47s\tremaining: 10m 1s\n",
      "9800:\tlearn: 218.1530109\ttest: 238.0523074\tbest: 238.0518093 (9747)\ttotal: 4m 50s\tremaining: 9m 58s\n",
      "9900:\tlearn: 217.8723094\ttest: 237.9208282\tbest: 237.9117446 (9886)\ttotal: 4m 53s\tremaining: 9m 55s\n",
      "10000:\tlearn: 217.7079341\ttest: 237.8333294\tbest: 237.8333292 (9999)\ttotal: 4m 56s\tremaining: 9m 52s\n",
      "10100:\tlearn: 217.5075217\ttest: 237.7449613\tbest: 237.7400212 (10094)\ttotal: 4m 59s\tremaining: 9m 50s\n",
      "10200:\tlearn: 217.2145520\ttest: 237.6237538\tbest: 237.6237538 (10200)\ttotal: 5m 2s\tremaining: 9m 47s\n",
      "10300:\tlearn: 216.9880153\ttest: 237.5642899\tbest: 237.5642899 (10300)\ttotal: 5m 5s\tremaining: 9m 44s\n",
      "10400:\tlearn: 216.5993395\ttest: 237.3208469\tbest: 237.3173907 (10399)\ttotal: 5m 8s\tremaining: 9m 42s\n",
      "10500:\tlearn: 216.3447822\ttest: 237.2344643\tbest: 237.2169877 (10478)\ttotal: 5m 11s\tremaining: 9m 39s\n",
      "10600:\tlearn: 216.1477892\ttest: 237.1595408\tbest: 237.1478789 (10558)\ttotal: 5m 14s\tremaining: 9m 36s\n",
      "10700:\tlearn: 215.9381699\ttest: 236.9920956\tbest: 236.9919056 (10695)\ttotal: 5m 18s\tremaining: 9m 33s\n",
      "10800:\tlearn: 215.6227925\ttest: 236.9092683\tbest: 236.9092683 (10800)\ttotal: 5m 21s\tremaining: 9m 31s\n",
      "10900:\tlearn: 215.5529025\ttest: 236.8831527\tbest: 236.8674888 (10857)\ttotal: 5m 24s\tremaining: 9m 27s\n",
      "11000:\tlearn: 215.2986052\ttest: 236.7071282\tbest: 236.7070351 (10999)\ttotal: 5m 27s\tremaining: 9m 24s\n",
      "11100:\tlearn: 215.1352225\ttest: 236.7202505\tbest: 236.6994549 (11008)\ttotal: 5m 30s\tremaining: 9m 22s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 236.6994549\n",
      "bestIteration = 11008\n",
      "\n",
      "Shrink model to first 11009 iterations.",
      "\n",
      "0:\tlearn: 962.2432986\ttest: 1008.0529273\tbest: 1008.0529273 (0)\ttotal: 29.1ms\tremaining: 14m 31s\n",
      "100:\tlearn: 438.3646610\ttest: 461.3779278\tbest: 461.3779278 (100)\ttotal: 3.2s\tremaining: 15m 47s\n",
      "200:\tlearn: 386.0087184\ttest: 390.5307516\tbest: 390.5307516 (200)\ttotal: 6.41s\tremaining: 15m 50s\n",
      "300:\tlearn: 359.4538888\ttest: 356.7384134\tbest: 356.7384134 (300)\ttotal: 9.58s\tremaining: 15m 45s\n",
      "400:\tlearn: 341.5187881\ttest: 336.5230080\tbest: 336.5230080 (400)\ttotal: 12.8s\tremaining: 15m 42s\n",
      "500:\tlearn: 329.5128659\ttest: 323.7799853\tbest: 323.7799853 (500)\ttotal: 16s\tremaining: 15m 39s\n",
      "600:\tlearn: 318.8578315\ttest: 313.9046187\tbest: 313.9046187 (600)\ttotal: 19.2s\tremaining: 15m 40s\n",
      "700:\tlearn: 310.3870082\ttest: 306.7252684\tbest: 306.7252684 (700)\ttotal: 22.4s\tremaining: 15m 36s\n",
      "800:\tlearn: 304.3799080\ttest: 301.4812602\tbest: 301.4812602 (800)\ttotal: 25.7s\tremaining: 15m 35s\n",
      "900:\tlearn: 297.9054754\ttest: 295.8074849\tbest: 295.8074849 (900)\ttotal: 28.7s\tremaining: 15m 26s\n",
      "1000:\tlearn: 294.2791514\ttest: 292.8698317\tbest: 292.8698317 (1000)\ttotal: 31.7s\tremaining: 15m 17s\n",
      "1100:\tlearn: 290.8037585\ttest: 289.8335597\tbest: 289.8324296 (1098)\ttotal: 34.3s\tremaining: 15m 1s\n",
      "1200:\tlearn: 287.7806340\ttest: 287.9445098\tbest: 287.9411030 (1195)\ttotal: 37s\tremaining: 14m 46s\n",
      "1300:\tlearn: 285.1633695\ttest: 286.1727717\tbest: 286.1727717 (1300)\ttotal: 39.7s\tremaining: 14m 35s\n",
      "1400:\tlearn: 282.4011174\ttest: 283.9474943\tbest: 283.9474943 (1400)\ttotal: 42.3s\tremaining: 14m 24s\n",
      "1500:\tlearn: 280.3762127\ttest: 282.5039452\tbest: 282.5039452 (1500)\ttotal: 44.7s\tremaining: 14m 9s\n",
      "1600:\tlearn: 277.6347758\ttest: 280.1615328\tbest: 280.1553100 (1599)\ttotal: 47.4s\tremaining: 14m 1s\n",
      "1700:\tlearn: 276.3805071\ttest: 279.0653294\tbest: 279.0653168 (1699)\ttotal: 49.8s\tremaining: 13m 48s\n",
      "1800:\tlearn: 274.5917528\ttest: 277.7425821\tbest: 277.7425821 (1800)\ttotal: 52.4s\tremaining: 13m 40s\n",
      "1900:\tlearn: 273.4940726\ttest: 277.0778194\tbest: 277.0778194 (1900)\ttotal: 54.7s\tremaining: 13m 28s\n",
      "2000:\tlearn: 270.9226563\ttest: 274.9309998\tbest: 274.9306715 (1999)\ttotal: 57.4s\tremaining: 13m 23s\n",
      "2100:\tlearn: 269.4981512\ttest: 273.9834881\tbest: 273.9822303 (2098)\ttotal: 1m\tremaining: 13m 17s\n",
      "2200:\tlearn: 267.7441987\ttest: 272.7389558\tbest: 272.7389558 (2200)\ttotal: 1m 2s\tremaining: 13m 13s\n",
      "2300:\tlearn: 265.8509418\ttest: 271.5522323\tbest: 271.5522323 (2300)\ttotal: 1m 5s\tremaining: 13m 8s\n",
      "2400:\tlearn: 264.2265301\ttest: 270.5351881\tbest: 270.5316266 (2391)\ttotal: 1m 8s\tremaining: 13m 5s\n",
      "2500:\tlearn: 263.0224476\ttest: 269.7178154\tbest: 269.7102095 (2499)\ttotal: 1m 11s\tremaining: 13m 1s\n",
      "2600:\tlearn: 261.0761096\ttest: 268.4780152\tbest: 268.4768605 (2599)\ttotal: 1m 13s\tremaining: 12m 58s\n",
      "2700:\tlearn: 259.6271604\ttest: 267.5620263\tbest: 267.5541942 (2689)\ttotal: 1m 16s\tremaining: 12m 53s\n",
      "2800:\tlearn: 258.0986644\ttest: 266.3942031\tbest: 266.3942031 (2800)\ttotal: 1m 19s\tremaining: 12m 50s\n",
      "2900:\tlearn: 256.5793661\ttest: 265.3726408\tbest: 265.3726408 (2900)\ttotal: 1m 21s\tremaining: 12m 45s\n",
      "3000:\tlearn: 255.7492121\ttest: 264.7955451\tbest: 264.7955451 (3000)\ttotal: 1m 24s\tremaining: 12m 40s\n",
      "3100:\tlearn: 254.8612176\ttest: 264.0251263\tbest: 264.0251263 (3100)\ttotal: 1m 27s\tremaining: 12m 35s\n",
      "3200:\tlearn: 254.0132787\ttest: 263.5637089\tbest: 263.5637089 (3200)\ttotal: 1m 29s\tremaining: 12m 29s\n",
      "3300:\tlearn: 253.2375559\ttest: 263.1024861\tbest: 263.1024861 (3300)\ttotal: 1m 32s\tremaining: 12m 25s\n",
      "3400:\tlearn: 252.2840834\ttest: 262.5379494\tbest: 262.5320293 (3399)\ttotal: 1m 34s\tremaining: 12m 21s\n",
      "3500:\tlearn: 251.3515848\ttest: 261.8377636\tbest: 261.8373275 (3499)\ttotal: 1m 37s\tremaining: 12m 17s\n",
      "3600:\tlearn: 250.6148540\ttest: 261.3851682\tbest: 261.3851682 (3600)\ttotal: 1m 39s\tremaining: 12m 12s\n",
      "3700:\tlearn: 249.7867933\ttest: 260.7603521\tbest: 260.7603521 (3700)\ttotal: 1m 42s\tremaining: 12m 10s\n",
      "3800:\tlearn: 249.3694326\ttest: 260.5827488\tbest: 260.5785768 (3790)\ttotal: 1m 45s\tremaining: 12m 5s\n",
      "3900:\tlearn: 249.0147667\ttest: 260.4724913\tbest: 260.4654330 (3893)\ttotal: 1m 47s\tremaining: 12m 1s\n",
      "4000:\tlearn: 248.3047323\ttest: 260.0106358\tbest: 260.0106358 (4000)\ttotal: 1m 50s\tremaining: 11m 58s\n",
      "4100:\tlearn: 247.6121130\ttest: 259.4698252\tbest: 259.4691816 (4099)\ttotal: 1m 52s\tremaining: 11m 53s\n",
      "4200:\tlearn: 246.2443611\ttest: 258.5716814\tbest: 258.5716814 (4200)\ttotal: 1m 55s\tremaining: 11m 49s\n",
      "4300:\tlearn: 245.2106421\ttest: 257.8189670\tbest: 257.8174723 (4294)\ttotal: 1m 57s\tremaining: 11m 44s\n",
      "4400:\tlearn: 244.7103250\ttest: 257.6300912\tbest: 257.6300912 (4400)\ttotal: 2m\tremaining: 11m 41s\n",
      "4500:\tlearn: 244.2129513\ttest: 257.2962106\tbest: 257.2962106 (4500)\ttotal: 2m 3s\tremaining: 11m 37s\n",
      "4600:\tlearn: 243.6083921\ttest: 256.9626362\tbest: 256.9626362 (4600)\ttotal: 2m 5s\tremaining: 11m 33s\n",
      "4700:\tlearn: 243.0068164\ttest: 256.5018182\tbest: 256.5018182 (4700)\ttotal: 2m 8s\tremaining: 11m 30s\n",
      "4800:\tlearn: 242.4910940\ttest: 256.2558342\tbest: 256.2558342 (4800)\ttotal: 2m 11s\tremaining: 11m 28s\n",
      "4900:\tlearn: 241.8324852\ttest: 255.9646376\tbest: 255.9609346 (4898)\ttotal: 2m 13s\tremaining: 11m 25s\n",
      "5000:\tlearn: 241.0168008\ttest: 255.3098701\tbest: 255.3098701 (5000)\ttotal: 2m 16s\tremaining: 11m 23s\n",
      "5100:\tlearn: 240.5600770\ttest: 255.0194285\tbest: 255.0194285 (5100)\ttotal: 2m 19s\tremaining: 11m 20s\n",
      "5200:\tlearn: 240.0513901\ttest: 254.7367171\tbest: 254.7367171 (5200)\ttotal: 2m 22s\tremaining: 11m 17s\n",
      "5300:\tlearn: 239.6331037\ttest: 254.5311727\tbest: 254.5267082 (5286)\ttotal: 2m 25s\tremaining: 11m 16s\n",
      "5400:\tlearn: 239.3252406\ttest: 254.3111041\tbest: 254.3105781 (5399)\ttotal: 2m 28s\tremaining: 11m 15s\n",
      "5500:\tlearn: 239.0337052\ttest: 254.1537060\tbest: 254.1454541 (5489)\ttotal: 2m 31s\tremaining: 11m 13s\n",
      "5600:\tlearn: 238.8167590\ttest: 253.9779039\tbest: 253.9761868 (5592)\ttotal: 2m 34s\tremaining: 11m 12s\n",
      "5700:\tlearn: 238.6675196\ttest: 253.7680892\tbest: 253.7680892 (5700)\ttotal: 2m 37s\tremaining: 11m 10s\n",
      "5800:\tlearn: 238.4022678\ttest: 253.5056382\tbest: 253.5043544 (5785)\ttotal: 2m 40s\tremaining: 11m 8s\n",
      "5900:\tlearn: 238.1701915\ttest: 253.3891157\tbest: 253.3891157 (5900)\ttotal: 2m 42s\tremaining: 11m 5s\n",
      "6000:\tlearn: 237.9819645\ttest: 253.2796133\tbest: 253.2796133 (6000)\ttotal: 2m 45s\tremaining: 11m 2s\n",
      "6100:\tlearn: 237.8549812\ttest: 253.2133153\tbest: 253.1931958 (6073)\ttotal: 2m 48s\tremaining: 11m\n",
      "6200:\tlearn: 237.7708041\ttest: 253.1779417\tbest: 253.1602503 (6170)\ttotal: 2m 51s\tremaining: 10m 58s\n",
      "6300:\tlearn: 237.5708405\ttest: 253.0255103\tbest: 253.0255095 (6299)\ttotal: 2m 54s\tremaining: 10m 56s\n",
      "6400:\tlearn: 237.3529775\ttest: 252.8061303\tbest: 252.8058549 (6395)\ttotal: 2m 57s\tremaining: 10m 54s\n",
      "6500:\tlearn: 237.2715689\ttest: 252.7873811\tbest: 252.7796832 (6482)\ttotal: 3m\tremaining: 10m 51s\n",
      "6600:\tlearn: 237.1910213\ttest: 252.7449233\tbest: 252.7449233 (6600)\ttotal: 3m 3s\tremaining: 10m 49s\n",
      "6700:\tlearn: 237.1101549\ttest: 252.7055468\tbest: 252.6941774 (6678)\ttotal: 3m 6s\tremaining: 10m 47s\n",
      "6800:\tlearn: 237.0258717\ttest: 252.6631542\tbest: 252.6471817 (6785)\ttotal: 3m 9s\tremaining: 10m 44s\n",
      "6900:\tlearn: 236.9255321\ttest: 252.5691383\tbest: 252.5655097 (6881)\ttotal: 3m 11s\tremaining: 10m 42s\n",
      "7000:\tlearn: 236.7593707\ttest: 252.4341390\tbest: 252.4341390 (7000)\ttotal: 3m 14s\tremaining: 10m 39s\n",
      "7100:\tlearn: 236.6422360\ttest: 252.3469562\tbest: 252.3469562 (7100)\ttotal: 3m 17s\tremaining: 10m 37s\n",
      "7200:\tlearn: 236.4786579\ttest: 252.1489376\tbest: 252.1489376 (7200)\ttotal: 3m 20s\tremaining: 10m 35s\n",
      "7300:\tlearn: 236.0572621\ttest: 251.8488110\tbest: 251.8474194 (7296)\ttotal: 3m 23s\tremaining: 10m 33s\n",
      "7400:\tlearn: 235.8373385\ttest: 251.6015341\tbest: 251.6002160 (7399)\ttotal: 3m 26s\tremaining: 10m 30s\n",
      "7500:\tlearn: 235.5474844\ttest: 251.3957584\tbest: 251.3957584 (7500)\ttotal: 3m 29s\tremaining: 10m 28s\n",
      "7600:\tlearn: 235.3515188\ttest: 251.2564726\tbest: 251.2564726 (7600)\ttotal: 3m 32s\tremaining: 10m 26s\n",
      "7700:\tlearn: 235.0594328\ttest: 251.0623081\tbest: 251.0623081 (7700)\ttotal: 3m 35s\tremaining: 10m 23s\n",
      "7800:\tlearn: 234.7496999\ttest: 250.7868379\tbest: 250.7841872 (7787)\ttotal: 3m 38s\tremaining: 10m 20s\n",
      "7900:\tlearn: 234.6232431\ttest: 250.6994487\tbest: 250.6994487 (7900)\ttotal: 3m 41s\tremaining: 10m 18s\n",
      "8000:\tlearn: 234.4526429\ttest: 250.5806213\tbest: 250.5801304 (7998)\ttotal: 3m 43s\tremaining: 10m 15s\n",
      "8100:\tlearn: 234.1317715\ttest: 250.3515979\tbest: 250.3511421 (8094)\ttotal: 3m 46s\tremaining: 10m 13s\n",
      "8200:\tlearn: 233.9839673\ttest: 250.2349325\tbest: 250.2258662 (8183)\ttotal: 3m 49s\tremaining: 10m 11s\n",
      "8300:\tlearn: 233.7192771\ttest: 249.9565837\tbest: 249.9564663 (8298)\ttotal: 3m 52s\tremaining: 10m 8s\n",
      "8400:\tlearn: 233.5130201\ttest: 249.7310555\tbest: 249.7297730 (8399)\ttotal: 3m 55s\tremaining: 10m 5s\n",
      "8500:\tlearn: 233.1375554\ttest: 249.3927954\tbest: 249.3865939 (8494)\ttotal: 3m 58s\tremaining: 10m 2s\n",
      "8600:\tlearn: 232.9937037\ttest: 249.2283556\tbest: 249.2237227 (8591)\ttotal: 4m 1s\tremaining: 10m\n",
      "8700:\tlearn: 232.7677415\ttest: 249.0267098\tbest: 249.0264747 (8698)\ttotal: 4m 3s\tremaining: 9m 56s\n",
      "8800:\tlearn: 232.6558036\ttest: 248.9079467\tbest: 248.9079172 (8799)\ttotal: 4m 6s\tremaining: 9m 53s\n",
      "8900:\tlearn: 232.5648730\ttest: 248.8000469\tbest: 248.7999110 (8896)\ttotal: 4m 9s\tremaining: 9m 50s\n",
      "9000:\tlearn: 232.4921280\ttest: 248.7449470\tbest: 248.7439136 (8977)\ttotal: 4m 11s\tremaining: 9m 47s\n",
      "9100:\tlearn: 232.3775320\ttest: 248.5967287\tbest: 248.5870977 (9093)\ttotal: 4m 14s\tremaining: 9m 44s\n",
      "9200:\tlearn: 232.2208904\ttest: 248.5069187\tbest: 248.4911513 (9136)\ttotal: 4m 17s\tremaining: 9m 41s\n",
      "9300:\tlearn: 232.1699323\ttest: 248.4448122\tbest: 248.4431996 (9289)\ttotal: 4m 19s\tremaining: 9m 38s\n",
      "9400:\tlearn: 232.1391638\ttest: 248.4413810\tbest: 248.4403214 (9388)\ttotal: 4m 22s\tremaining: 9m 34s\n",
      "9500:\tlearn: 231.7339119\ttest: 248.3563036\tbest: 248.3562931 (9499)\ttotal: 4m 24s\tremaining: 9m 31s\n",
      "9600:\tlearn: 231.3804017\ttest: 248.2172553\tbest: 248.2079622 (9579)\ttotal: 4m 27s\tremaining: 9m 28s\n",
      "9700:\tlearn: 231.1878018\ttest: 248.0099241\tbest: 248.0078265 (9693)\ttotal: 4m 30s\tremaining: 9m 25s\n",
      "9800:\tlearn: 231.0608372\ttest: 247.9301978\tbest: 247.9202601 (9781)\ttotal: 4m 33s\tremaining: 9m 22s\n",
      "9900:\tlearn: 230.9724869\ttest: 247.8694797\tbest: 247.8669117 (9890)\ttotal: 4m 35s\tremaining: 9m 19s\n",
      "10000:\tlearn: 230.8538435\ttest: 247.8176369\tbest: 247.7988588 (9994)\ttotal: 4m 38s\tremaining: 9m 16s\n",
      "10100:\tlearn: 230.7490721\ttest: 247.7493449\tbest: 247.7493449 (10100)\ttotal: 4m 40s\tremaining: 9m 13s\n",
      "10200:\tlearn: 230.6961306\ttest: 247.7002062\tbest: 247.7001503 (10199)\ttotal: 4m 43s\tremaining: 9m 9s\n",
      "10300:\tlearn: 230.5871344\ttest: 247.6453909\tbest: 247.6449952 (10296)\ttotal: 4m 45s\tremaining: 9m 6s\n",
      "10400:\tlearn: 230.4921669\ttest: 247.6073418\tbest: 247.6073418 (10400)\ttotal: 4m 48s\tremaining: 9m 3s\n",
      "10500:\tlearn: 230.4286972\ttest: 247.5387878\tbest: 247.5294565 (10494)\ttotal: 4m 51s\tremaining: 9m\n",
      "10600:\tlearn: 230.2931131\ttest: 247.4793558\tbest: 247.4793558 (10600)\ttotal: 4m 54s\tremaining: 8m 58s\n",
      "10700:\tlearn: 230.2547151\ttest: 247.4237743\tbest: 247.4205830 (10697)\ttotal: 4m 56s\tremaining: 8m 54s\n",
      "10800:\tlearn: 230.1795826\ttest: 247.3361643\tbest: 247.3361643 (10800)\ttotal: 4m 59s\tremaining: 8m 51s\n",
      "10900:\tlearn: 230.1302681\ttest: 247.2875128\tbest: 247.2871796 (10893)\ttotal: 5m 1s\tremaining: 8m 48s\n",
      "11000:\tlearn: 230.0698799\ttest: 247.2650170\tbest: 247.2614962 (10957)\ttotal: 5m 4s\tremaining: 8m 45s\n",
      "11100:\tlearn: 229.9432534\ttest: 247.1356095\tbest: 247.1356095 (11100)\ttotal: 5m 7s\tremaining: 8m 42s\n",
      "11200:\tlearn: 229.8764135\ttest: 247.1269607\tbest: 247.0937303 (11134)\ttotal: 5m 9s\tremaining: 8m 39s\n",
      "11300:\tlearn: 229.5721408\ttest: 246.9514848\tbest: 246.9446035 (11297)\ttotal: 5m 12s\tremaining: 8m 37s\n",
      "11400:\tlearn: 229.1809993\ttest: 246.8083014\tbest: 246.8081976 (11399)\ttotal: 5m 15s\tremaining: 8m 35s\n",
      "11500:\tlearn: 228.7627762\ttest: 246.6156268\tbest: 246.6143935 (11495)\ttotal: 5m 18s\tremaining: 8m 32s\n",
      "11600:\tlearn: 228.4787654\ttest: 246.4145294\tbest: 246.4117839 (11599)\ttotal: 5m 21s\tremaining: 8m 30s\n",
      "11700:\tlearn: 228.0993920\ttest: 246.2058060\tbest: 246.2056028 (11699)\ttotal: 5m 24s\tremaining: 8m 27s\n",
      "11800:\tlearn: 227.5988346\ttest: 245.9776908\tbest: 245.9728988 (11793)\ttotal: 5m 27s\tremaining: 8m 25s\n",
      "11900:\tlearn: 227.3972208\ttest: 245.8845625\tbest: 245.8785127 (11893)\ttotal: 5m 30s\tremaining: 8m 22s\n",
      "12000:\tlearn: 227.0616669\ttest: 245.6317688\tbest: 245.6317688 (12000)\ttotal: 5m 33s\tremaining: 8m 20s\n",
      "12100:\tlearn: 226.6063495\ttest: 245.3423608\tbest: 245.3178676 (12074)\ttotal: 5m 37s\tremaining: 8m 18s\n",
      "12200:\tlearn: 226.3457723\ttest: 245.1447281\tbest: 245.1404826 (12192)\ttotal: 5m 39s\tremaining: 8m 15s\n",
      "12300:\tlearn: 226.1667600\ttest: 245.0647849\tbest: 245.0582221 (12292)\ttotal: 5m 42s\tremaining: 8m 13s\n",
      "12400:\tlearn: 225.9437073\ttest: 244.8837982\tbest: 244.8837982 (12400)\ttotal: 5m 45s\tremaining: 8m 10s\n",
      "12500:\tlearn: 225.8228990\ttest: 244.8524797\tbest: 244.8435681 (12465)\ttotal: 5m 48s\tremaining: 8m 7s\n",
      "12600:\tlearn: 225.6680025\ttest: 244.7895847\tbest: 244.7814869 (12591)\ttotal: 5m 51s\tremaining: 8m 4s\n",
      "12700:\tlearn: 225.5296425\ttest: 244.7497232\tbest: 244.7497220 (12663)\ttotal: 5m 53s\tremaining: 8m 2s\n",
      "12800:\tlearn: 225.1189717\ttest: 244.5639721\tbest: 244.5497707 (12791)\ttotal: 5m 57s\tremaining: 7m 59s\n",
      "12900:\tlearn: 224.7999864\ttest: 244.3828500\tbest: 244.3783157 (12888)\ttotal: 6m\tremaining: 7m 57s\n",
      "13000:\tlearn: 224.3096291\ttest: 244.1512254\tbest: 244.1473333 (12993)\ttotal: 6m 2s\tremaining: 7m 54s\n",
      "13100:\tlearn: 224.1549298\ttest: 244.0514427\tbest: 244.0514427 (13100)\ttotal: 6m 5s\tremaining: 7m 51s\n",
      "13200:\tlearn: 223.8122974\ttest: 243.8697966\tbest: 243.8697966 (13200)\ttotal: 6m 8s\tremaining: 7m 49s\n",
      "13300:\tlearn: 223.4366493\ttest: 243.7512445\tbest: 243.7511821 (13299)\ttotal: 6m 11s\tremaining: 7m 46s\n",
      "13400:\tlearn: 223.2776435\ttest: 243.6800722\tbest: 243.6574099 (13364)\ttotal: 6m 14s\tremaining: 7m 44s\n",
      "13500:\tlearn: 222.7358954\ttest: 243.2879958\tbest: 243.2879958 (13500)\ttotal: 6m 17s\tremaining: 7m 41s\n",
      "13600:\tlearn: 222.0729777\ttest: 242.9764280\tbest: 242.9764280 (13600)\ttotal: 6m 20s\tremaining: 7m 38s\n",
      "13700:\tlearn: 221.4600359\ttest: 242.6560840\tbest: 242.6550286 (13685)\ttotal: 6m 23s\tremaining: 7m 35s\n",
      "13800:\tlearn: 220.9888788\ttest: 242.5285749\tbest: 242.5251349 (13793)\ttotal: 6m 26s\tremaining: 7m 33s\n",
      "13900:\tlearn: 220.5747571\ttest: 242.1886830\tbest: 242.1839466 (13893)\ttotal: 6m 29s\tremaining: 7m 30s\n",
      "14000:\tlearn: 220.2650732\ttest: 241.9980917\tbest: 241.9977012 (13999)\ttotal: 6m 31s\tremaining: 7m 27s\n",
      "14100:\tlearn: 220.0075764\ttest: 241.8228603\tbest: 241.8202218 (14097)\ttotal: 6m 34s\tremaining: 7m 25s\n",
      "14200:\tlearn: 219.7007401\ttest: 241.6813848\tbest: 241.6813848 (14200)\ttotal: 6m 37s\tremaining: 7m 22s\n",
      "14300:\tlearn: 219.4409568\ttest: 241.5211712\tbest: 241.5211712 (14300)\ttotal: 6m 40s\tremaining: 7m 19s\n",
      "14400:\tlearn: 219.2899887\ttest: 241.3733674\tbest: 241.3733674 (14400)\ttotal: 6m 43s\tremaining: 7m 16s\n",
      "14500:\tlearn: 218.9260922\ttest: 241.2495232\tbest: 241.2495232 (14500)\ttotal: 6m 46s\tremaining: 7m 14s\n",
      "14600:\tlearn: 218.6950115\ttest: 241.1820966\tbest: 241.1820966 (14600)\ttotal: 6m 49s\tremaining: 7m 11s\n",
      "14700:\tlearn: 218.4738446\ttest: 241.0572968\tbest: 241.0569613 (14698)\ttotal: 6m 52s\tremaining: 7m 9s\n",
      "14800:\tlearn: 218.0313954\ttest: 240.8919356\tbest: 240.8919356 (14800)\ttotal: 6m 55s\tremaining: 7m 6s\n",
      "14900:\tlearn: 217.5781295\ttest: 240.6278715\tbest: 240.6278715 (14900)\ttotal: 6m 58s\tremaining: 7m 3s\n",
      "15000:\tlearn: 217.2542428\ttest: 240.4050259\tbest: 240.4050259 (15000)\ttotal: 7m 1s\tremaining: 7m 1s\n",
      "15100:\tlearn: 216.9844581\ttest: 240.2084670\tbest: 240.2084670 (15100)\ttotal: 7m 4s\tremaining: 6m 58s\n",
      "15200:\tlearn: 216.8027336\ttest: 240.1111781\tbest: 240.1054657 (15194)\ttotal: 7m 7s\tremaining: 6m 56s\n",
      "15300:\tlearn: 216.5850226\ttest: 239.9455299\tbest: 239.9455299 (15300)\ttotal: 7m 10s\tremaining: 6m 53s\n",
      "15400:\tlearn: 216.4653998\ttest: 239.8823720\tbest: 239.8823720 (15400)\ttotal: 7m 12s\tremaining: 6m 50s\n",
      "15500:\tlearn: 216.3010415\ttest: 239.7787018\tbest: 239.7787018 (15500)\ttotal: 7m 15s\tremaining: 6m 47s\n",
      "15600:\tlearn: 216.0704334\ttest: 239.6383913\tbest: 239.6377900 (15598)\ttotal: 7m 18s\tremaining: 6m 44s\n",
      "15700:\tlearn: 215.7955540\ttest: 239.4712936\tbest: 239.4706467 (15699)\ttotal: 7m 21s\tremaining: 6m 42s\n",
      "15800:\tlearn: 215.5132154\ttest: 239.3397192\tbest: 239.3325430 (15793)\ttotal: 7m 24s\tremaining: 6m 39s\n",
      "15900:\tlearn: 215.3657185\ttest: 239.2830882\tbest: 239.2798834 (15895)\ttotal: 7m 27s\tremaining: 6m 36s\n",
      "16000:\tlearn: 215.2703516\ttest: 239.2373492\tbest: 239.2168592 (15976)\ttotal: 7m 30s\tremaining: 6m 34s\n",
      "16100:\tlearn: 215.1738168\ttest: 239.1817016\tbest: 239.1817016 (16100)\ttotal: 7m 33s\tremaining: 6m 31s\n",
      "16200:\tlearn: 214.6964124\ttest: 238.8881360\tbest: 238.8881360 (16200)\ttotal: 7m 36s\tremaining: 6m 29s\n",
      "16300:\tlearn: 214.2727602\ttest: 238.5762461\tbest: 238.5742259 (16299)\ttotal: 7m 39s\tremaining: 6m 26s\n",
      "16400:\tlearn: 214.0485027\ttest: 238.4489402\tbest: 238.4489402 (16400)\ttotal: 7m 42s\tremaining: 6m 23s\n",
      "16500:\tlearn: 213.8796079\ttest: 238.3165761\tbest: 238.3165761 (16500)\ttotal: 7m 45s\tremaining: 6m 21s\n",
      "16600:\tlearn: 213.5405055\ttest: 238.1371567\tbest: 238.1371567 (16600)\ttotal: 7m 48s\tremaining: 6m 18s\n",
      "16700:\tlearn: 213.3603269\ttest: 238.0772469\tbest: 238.0763220 (16693)\ttotal: 7m 51s\tremaining: 6m 15s\n",
      "16800:\tlearn: 213.2485124\ttest: 238.0154132\tbest: 238.0153421 (16799)\ttotal: 7m 54s\tremaining: 6m 12s\n",
      "16900:\tlearn: 213.1548361\ttest: 237.9434612\tbest: 237.9396818 (16894)\ttotal: 7m 56s\tremaining: 6m 9s\n",
      "17000:\tlearn: 213.0762993\ttest: 237.9288966\tbest: 237.9056961 (16960)\ttotal: 7m 59s\tremaining: 6m 6s\n",
      "17100:\tlearn: 212.8852009\ttest: 237.8355738\tbest: 237.8345070 (17098)\ttotal: 8m 2s\tremaining: 6m 4s\n",
      "17200:\tlearn: 212.7595365\ttest: 237.7424887\tbest: 237.7379488 (17169)\ttotal: 8m 5s\tremaining: 6m 1s\n",
      "17300:\tlearn: 212.6305263\ttest: 237.6886965\tbest: 237.6870354 (17296)\ttotal: 8m 8s\tremaining: 5m 58s\n",
      "17400:\tlearn: 212.5867977\ttest: 237.6452439\tbest: 237.6419092 (17399)\ttotal: 8m 11s\tremaining: 5m 55s\n",
      "17500:\tlearn: 212.4788173\ttest: 237.5669546\tbest: 237.5669546 (17500)\ttotal: 8m 14s\tremaining: 5m 53s\n",
      "17600:\tlearn: 212.4386422\ttest: 237.5543878\tbest: 237.5388773 (17550)\ttotal: 8m 17s\tremaining: 5m 50s\n",
      "17700:\tlearn: 212.2467427\ttest: 237.4620821\tbest: 237.4620821 (17700)\ttotal: 8m 20s\tremaining: 5m 47s\n",
      "17800:\tlearn: 212.1244472\ttest: 237.3942344\tbest: 237.3862081 (17729)\ttotal: 8m 23s\tremaining: 5m 44s\n",
      "17900:\tlearn: 212.0142839\ttest: 237.3716134\tbest: 237.3403589 (17849)\ttotal: 8m 25s\tremaining: 5m 41s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 237.3403589\n",
      "bestIteration = 17849\n",
      "\n",
      "Shrink model to first 17850 iterations.",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "ctb_model = CatBoostRegressor(iterations=30000,learning_rate=0.03,loss_function=\"RMSE\")\n",
    "data_ctb_03, predict_label_03 = get_predict_w(ctb_model, data, label='label',\n",
    "                                    feature=features, cate_feature=cate_feat,\n",
    "                                    random_state=2019,model_type='ctb')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "   adcode  carCommentVolum  label             model  newsReplyVolum  \\\n0  310000             11.0  292.0  3c974920a76ac9c1           106.0   \n1  530000             11.0  466.0  3c974920a76ac9c1           106.0   \n2  150000             11.0  257.0  3c974920a76ac9c1           106.0   \n3  110000             11.0  408.0  3c974920a76ac9c1           106.0   \n4  510000             11.0  610.0  3c974920a76ac9c1           106.0   \n\n   popularity  predict_label  regMonth  regYear  sample_weight  \n0      1479.0     322.079223         1     2016              1  \n1      1594.0     376.656707         1     2016              1  \n2      1479.0     253.657893         1     2016              1  \n3      2370.0     522.136991         1     2016              1  \n4      3562.0     663.364711         1     2016              1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>adcode</th>\n      <th>carCommentVolum</th>\n      <th>label</th>\n      <th>model</th>\n      <th>newsReplyVolum</th>\n      <th>popularity</th>\n      <th>predict_label</th>\n      <th>regMonth</th>\n      <th>regYear</th>\n      <th>sample_weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>310000</td>\n      <td>11.0</td>\n      <td>292.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1479.0</td>\n      <td>322.079223</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>530000</td>\n      <td>11.0</td>\n      <td>466.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1594.0</td>\n      <td>376.656707</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150000</td>\n      <td>11.0</td>\n      <td>257.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>1479.0</td>\n      <td>253.657893</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>110000</td>\n      <td>11.0</td>\n      <td>408.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>2370.0</td>\n      <td>522.136991</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>510000</td>\n      <td>11.0</td>\n      <td>610.0</td>\n      <td>3c974920a76ac9c1</td>\n      <td>106.0</td>\n      <td>3562.0</td>\n      <td>663.364711</td>\n      <td>1</td>\n      <td>2016</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 32
    }
   ],
   "source": [
    "data_ctb_03.head()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "'predict_label'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 34
    }
   ],
   "source": [
    "predict_label_03\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "data_ctb_03.to_csv(\"ctb03.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}